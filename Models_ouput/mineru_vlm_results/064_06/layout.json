{
    "pdf_info": [
        {
            "para_blocks": [
                {
                    "bbox": [
                        226,
                        280,
                        678,
                        330
                    ],
                    "type": "title",
                    "lines": [
                        {
                            "bbox": [
                                226,
                                280,
                                678,
                                330
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        226,
                                        280,
                                        678,
                                        330
                                    ],
                                    "type": "text",
                                    "content": "4.2. Comparative Results"
                                }
                            ]
                        }
                    ],
                    "index": 0,
                    "level": 1
                },
                {
                    "bbox": [
                        226,
                        359,
                        1208,
                        656
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                226,
                                359,
                                1208,
                                656
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        226,
                                        359,
                                        1208,
                                        656
                                    ],
                                    "type": "text",
                                    "content": "Location Reasoning. We compare the results of our QRCLIP with other methods for location reasoning in Tab. 1. QR- CLIP, achieves accuracy of "
                                },
                                {
                                    "bbox": [
                                        226,
                                        359,
                                        1208,
                                        656
                                    ],
                                    "type": "inline_equation",
                                    "content": "19.31\\%"
                                },
                                {
                                    "bbox": [
                                        226,
                                        359,
                                        1208,
                                        656
                                    ],
                                    "type": "text",
                                    "content": " Accuracy "
                                },
                                {
                                    "bbox": [
                                        226,
                                        359,
                                        1208,
                                        656
                                    ],
                                    "type": "inline_equation",
                                    "content": "(\\mathrm{R}\\@ 1)"
                                },
                                {
                                    "bbox": [
                                        226,
                                        359,
                                        1208,
                                        656
                                    ],
                                    "type": "text",
                                    "content": " Meanwhile, its Example- F1 score for the hierarchical labels is "
                                },
                                {
                                    "bbox": [
                                        226,
                                        359,
                                        1208,
                                        656
                                    ],
                                    "type": "inline_equation",
                                    "content": "50.96\\%"
                                },
                                {
                                    "bbox": [
                                        226,
                                        359,
                                        1208,
                                        656
                                    ],
                                    "type": "text",
                                    "content": " .All the results clearly show that our method outperforms other methods."
                                }
                            ]
                        }
                    ],
                    "index": 1
                },
                {
                    "bbox": [
                        226,
                        683,
                        1208,
                        1379
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                226,
                                683,
                                1208,
                                1379
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        226,
                                        683,
                                        1208,
                                        1379
                                    ],
                                    "type": "text",
                                    "content": "(1) Compared with ResNet-50 (He et al., 2016) and SwinT (Liu et al., 2021), vanilla CLIP achieves "
                                },
                                {
                                    "bbox": [
                                        226,
                                        683,
                                        1208,
                                        1379
                                    ],
                                    "type": "inline_equation",
                                    "content": "7.93\\%"
                                },
                                {
                                    "bbox": [
                                        226,
                                        683,
                                        1208,
                                        1379
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        226,
                                        683,
                                        1208,
                                        1379
                                    ],
                                    "type": "inline_equation",
                                    "content": "4.41\\%"
                                },
                                {
                                    "bbox": [
                                        226,
                                        683,
                                        1208,
                                        1379
                                    ],
                                    "type": "text",
                                    "content": " absolute improvement in location prediction accuracy (ID: 1,2,3). It indicates that compared with the vision model only trained on ImageNet (Deng et al., 2009), CLIP already possesses some knowledge for reasoning. Meanwhile, our QR-CLIP achieves a more significant advantage with "
                                },
                                {
                                    "bbox": [
                                        226,
                                        683,
                                        1208,
                                        1379
                                    ],
                                    "type": "inline_equation",
                                    "content": "16.13\\%"
                                },
                                {
                                    "bbox": [
                                        226,
                                        683,
                                        1208,
                                        1379
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        226,
                                        683,
                                        1208,
                                        1379
                                    ],
                                    "type": "inline_equation",
                                    "content": "12.61\\%"
                                },
                                {
                                    "bbox": [
                                        226,
                                        683,
                                        1208,
                                        1379
                                    ],
                                    "type": "text",
                                    "content": " absolute improvements in terms of accuracy (ID: 1,2,6). These results show that traditional image classification methods cannot accomplish inference of the abstract information behind the images. While the CLIP model trained on large-scale internet data have the ability to identify locations based on image data, and QR-CLIP significantly enhances this capability."
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "bbox": [
                        226,
                        1405,
                        1208,
                        2250
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                226,
                                1405,
                                1208,
                                2250
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        226,
                                        1405,
                                        1208,
                                        2250
                                    ],
                                    "type": "text",
                                    "content": "(2) Besides, compared to "
                                },
                                {
                                    "bbox": [
                                        226,
                                        1405,
                                        1208,
                                        2250
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\mathrm{CLIP\\dagger}"
                                },
                                {
                                    "bbox": [
                                        226,
                                        1405,
                                        1208,
                                        2250
                                    ],
                                    "type": "text",
                                    "content": " and the state-of-the-art method "
                                },
                                {
                                    "bbox": [
                                        226,
                                        1405,
                                        1208,
                                        2250
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\mathrm{CLIP + Seg}"
                                },
                                {
                                    "bbox": [
                                        226,
                                        1405,
                                        1208,
                                        2250
                                    ],
                                    "type": "text",
                                    "content": " QR-CLIP improves the accuracy by "
                                },
                                {
                                    "bbox": [
                                        226,
                                        1405,
                                        1208,
                                        2250
                                    ],
                                    "type": "inline_equation",
                                    "content": "3.59\\%"
                                },
                                {
                                    "bbox": [
                                        226,
                                        1405,
                                        1208,
                                        2250
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        226,
                                        1405,
                                        1208,
                                        2250
                                    ],
                                    "type": "inline_equation",
                                    "content": "2.85\\%"
                                },
                                {
                                    "bbox": [
                                        226,
                                        1405,
                                        1208,
                                        2250
                                    ],
                                    "type": "text",
                                    "content": " absolute improvement, the F1-Score has increased by "
                                },
                                {
                                    "bbox": [
                                        226,
                                        1405,
                                        1208,
                                        2250
                                    ],
                                    "type": "inline_equation",
                                    "content": "3.88\\%"
                                },
                                {
                                    "bbox": [
                                        226,
                                        1405,
                                        1208,
                                        2250
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        226,
                                        1405,
                                        1208,
                                        2250
                                    ],
                                    "type": "inline_equation",
                                    "content": "3.07\\%"
                                },
                                {
                                    "bbox": [
                                        226,
                                        1405,
                                        1208,
                                        2250
                                    ],
                                    "type": "text",
                                    "content": " respectively (ID:4,5,6). Other evaluation metrics also improved. The results show that QR-CLIP can effectively utilize open-world knowledge to establish a closer connection between image and location information through fine-tuning CLIP. However, we also find that the improvement in Example-F1 is not as obvious. We argue that this is because the mechanism of Example-F1: take the image of Fig. 1 as an example-the picture show many Arabia elements (turban and Arabic). It is not difficult for many models to recognize that this image was captured in the Middle East and to predict its hierarchical label as "
                                },
                                {
                                    "bbox": [
                                        226,
                                        1405,
                                        1208,
                                        2250
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\{\\mathrm{^{\\circ}A s i a^{\\circ}}\\}"
                                },
                                {
                                    "bbox": [
                                        226,
                                        1405,
                                        1208,
                                        2250
                                    ],
                                    "type": "text",
                                    "content": " .However, they failed when asked to predict the entire label { Riyadh, Saudi Arabia, Asia\"). Therefore, the discrepancy in other metrics may be more noticeable."
                                }
                            ]
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        226,
                        2277,
                        1208,
                        2973
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                226,
                                2277,
                                1208,
                                2973
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        226,
                                        2277,
                                        1208,
                                        2973
                                    ],
                                    "type": "text",
                                    "content": "Time Reasoning. Tab. 1 also presents the performance of our method and existing techniques for time reasoning. The Accuracy "
                                },
                                {
                                    "bbox": [
                                        226,
                                        2277,
                                        1208,
                                        2973
                                    ],
                                    "type": "inline_equation",
                                    "content": "(\\mathrm{R}\\@ 1)"
                                },
                                {
                                    "bbox": [
                                        226,
                                        2277,
                                        1208,
                                        2973
                                    ],
                                    "type": "text",
                                    "content": " of QR- CLIP is "
                                },
                                {
                                    "bbox": [
                                        226,
                                        2277,
                                        1208,
                                        2973
                                    ],
                                    "type": "inline_equation",
                                    "content": "3.53\\%"
                                },
                                {
                                    "bbox": [
                                        226,
                                        2277,
                                        1208,
                                        2973
                                    ],
                                    "type": "text",
                                    "content": " and Example- F1 is "
                                },
                                {
                                    "bbox": [
                                        226,
                                        2277,
                                        1208,
                                        2973
                                    ],
                                    "type": "inline_equation",
                                    "content": "47.89\\%"
                                },
                                {
                                    "bbox": [
                                        226,
                                        2277,
                                        1208,
                                        2973
                                    ],
                                    "type": "text",
                                    "content": " compared to the CLIP model, the two metrics have been absolutely improved by "
                                },
                                {
                                    "bbox": [
                                        226,
                                        2277,
                                        1208,
                                        2973
                                    ],
                                    "type": "inline_equation",
                                    "content": "3.07\\%"
                                },
                                {
                                    "bbox": [
                                        226,
                                        2277,
                                        1208,
                                        2973
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        226,
                                        2277,
                                        1208,
                                        2973
                                    ],
                                    "type": "inline_equation",
                                    "content": "7.99\\%"
                                },
                                {
                                    "bbox": [
                                        226,
                                        2277,
                                        1208,
                                        2973
                                    ],
                                    "type": "text",
                                    "content": " ,respectively (ID: 9,12).Compared with "
                                },
                                {
                                    "bbox": [
                                        226,
                                        2277,
                                        1208,
                                        2973
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\mathrm{CLIP\\dagger}"
                                },
                                {
                                    "bbox": [
                                        226,
                                        2277,
                                        1208,
                                        2973
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        226,
                                        2277,
                                        1208,
                                        2973
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\mathrm{CLIP + Seg}"
                                },
                                {
                                    "bbox": [
                                        226,
                                        2277,
                                        1208,
                                        2973
                                    ],
                                    "type": "text",
                                    "content": " ,which are also based on CLIP fine- tuning, our method obtains "
                                },
                                {
                                    "bbox": [
                                        226,
                                        2277,
                                        1208,
                                        2973
                                    ],
                                    "type": "inline_equation",
                                    "content": "2.53\\%"
                                },
                                {
                                    "bbox": [
                                        226,
                                        2277,
                                        1208,
                                        2973
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        226,
                                        2277,
                                        1208,
                                        2973
                                    ],
                                    "type": "inline_equation",
                                    "content": "2.61\\%"
                                },
                                {
                                    "bbox": [
                                        226,
                                        2277,
                                        1208,
                                        2973
                                    ],
                                    "type": "text",
                                    "content": " improvement in the accuracy of prediction time, respectively. Compared with traditional image classification methods, QR- CLIP has achieved absolute advantages in all metrics (ID: 7,8,12).In addition, due to the lack of timerelated information in the image, the prediction accuracy of fine- tuning CLIP methods for image time can only reach about "
                                },
                                {
                                    "bbox": [
                                        226,
                                        2277,
                                        1208,
                                        2973
                                    ],
                                    "type": "inline_equation",
                                    "content": "1\\%"
                                },
                                {
                                    "bbox": [
                                        226,
                                        2277,
                                        1208,
                                        2973
                                    ],
                                    "type": "text",
                                    "content": " , which is significantly lower than the accuracy of "
                                }
                            ]
                        },
                        {
                            "bbox": [
                                1277,
                                1435,
                                2261,
                                1834
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        1277,
                                        1435,
                                        2261,
                                        1834
                                    ],
                                    "type": "text",
                                    "content": "location prediction (ID: 10,11). This is not surprising, also take the image on Fig. 1 as sample: even for humans, it is difficult to determine that "
                                },
                                {
                                    "bbox": [
                                        1277,
                                        1435,
                                        2261,
                                        1834
                                    ],
                                    "type": "inline_equation",
                                    "content": "\\{^{\\circ}O3 - O1 - 2O23^{\\circ}\\}"
                                },
                                {
                                    "bbox": [
                                        1277,
                                        1435,
                                        2261,
                                        1834
                                    ],
                                    "type": "text",
                                    "content": " is the time when this photograph was taken, if they are unfamiliar with Cristiano Ronaldo or some specific knowledge. Nevertheless, the method proposed in this paper is still effective (that our model achieves "
                                },
                                {
                                    "bbox": [
                                        1277,
                                        1435,
                                        2261,
                                        1834
                                    ],
                                    "type": "inline_equation",
                                    "content": "+253.00\\%"
                                },
                                {
                                    "bbox": [
                                        1277,
                                        1435,
                                        2261,
                                        1834
                                    ],
                                    "type": "text",
                                    "content": " relative lift) for predicting time and significantly closes the gap with location prediction."
                                }
                            ]
                        }
                    ],
                    "index": 4
                },
                {
                    "type": "table",
                    "bbox": [
                        1277,
                        273,
                        2251,
                        1013
                    ],
                    "blocks": [
                        {
                            "bbox": [
                                1277,
                                273,
                                2251,
                                1013
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        1277,
                                        273,
                                        2251,
                                        1013
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                1277,
                                                273,
                                                2251,
                                                1013
                                            ],
                                            "type": "table",
                                            "html": "<table><tr><td>ID Method</td><td>Accuracy (≈ Rank@1)</td><td>Rank@5</td><td>Example-F1</td></tr><tr><td colspan=\"4\">Location Reasoning</td></tr><tr><td>13 CLIP+ [CLS*]y(n=2)</td><td>9.69%</td><td>27.17%</td><td>44.37%</td></tr><tr><td>14 CLIP+ [CLS*]y(n=4)</td><td>9.53%</td><td>26.25%</td><td>43.23%</td></tr><tr><td>15 CLIP+ [CLS*]y(n=6)</td><td>9.21%</td><td>27.05%</td><td>43.69%</td></tr><tr><td>16 CLIP+ [CLS]y(n=2)</td><td>16.84%</td><td>37.47%</td><td>49.22%</td></tr><tr><td>17 CLIP+ [CLS]y(n=4)</td><td>17.11%</td><td>37.60%</td><td>49.51%</td></tr><tr><td>18 CLIP+ [CLS]y(n=6)</td><td>17.25%</td><td>37.80%</td><td>49.98%</td></tr><tr><td>19 CLIP+ [CLS]y(n=8)</td><td>17.03%</td><td>37.62%</td><td>48.93%</td></tr><tr><td colspan=\"4\">Time Reasoning</td></tr><tr><td>20 CLIP+ [CLS*]y(n=2)</td><td>0.98%</td><td>3.03%</td><td>42.18%</td></tr><tr><td>21 CLIP+ [CLS*]y(n=4)</td><td>1.03%</td><td>2.99%</td><td>43.98%</td></tr><tr><td>22 CLIP+ [CLS*]y(n=6)</td><td>1.08%</td><td>3.15%</td><td>43.62%</td></tr><tr><td>23 CLIP+ [CLS]y(n=2)</td><td>1.84%</td><td>5.14%</td><td>45.57%</td></tr><tr><td>24 CLIP+ [CLS]y(n=4)</td><td>1.92%</td><td>5.21%</td><td>45.63%</td></tr><tr><td>25 CLIP+ [CLS]y(n=6)</td><td>2.00%</td><td>5.37%</td><td>45.60%</td></tr><tr><td>26 CLIP+ [CLS]y(n=8)</td><td>1.53%</td><td>5.06%</td><td>45.15%</td></tr></table>",
                                            "image_path": "0bbb1fe483ad9ca0cd0abf38ce5ec7a942097507918c333d20e7437c1f8154df.jpg"
                                        }
                                    ]
                                }
                            ],
                            "index": 6,
                            "type": "table_body"
                        },
                        {
                            "bbox": [
                                1277,
                                1026,
                                2261,
                                1343
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        1277,
                                        1026,
                                        2261,
                                        1343
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                1277,
                                                1026,
                                                2261,
                                                1343
                                            ],
                                            "type": "text",
                                            "content": "Table 2.Performance of additional [CLS] in QR-CLIP with different number and prediction methods. Whereas "
                                        },
                                        {
                                            "bbox": [
                                                1277,
                                                1026,
                                                2261,
                                                1343
                                            ],
                                            "type": "inline_equation",
                                            "content": "[\\mathsf{CLS}^* ]_i^v"
                                        },
                                        {
                                            "bbox": [
                                                1277,
                                                1026,
                                                2261,
                                                1343
                                            ],
                                            "type": "text",
                                            "content": " refers to fusing all additional [CLS] by MLPs and then calculating the similarity with location and time labels, "
                                        },
                                        {
                                            "bbox": [
                                                1277,
                                                1026,
                                                2261,
                                                1343
                                            ],
                                            "type": "inline_equation",
                                            "content": "[\\mathsf{CLS}]_i^v"
                                        },
                                        {
                                            "bbox": [
                                                1277,
                                                1026,
                                                2261,
                                                1343
                                            ],
                                            "type": "text",
                                            "content": " refers to calculating the similarity between each additional [CLS] with labels separately, and then using the "
                                        },
                                        {
                                            "bbox": [
                                                1277,
                                                1026,
                                                2261,
                                                1343
                                            ],
                                            "type": "inline_equation",
                                            "content": "([\\mathsf{CLS}]_i^v"
                                        },
                                        {
                                            "bbox": [
                                                1277,
                                                1026,
                                                2261,
                                                1343
                                            ],
                                            "type": "text",
                                            "content": " -label) pair with the greatest similarity as the prediction. "
                                        },
                                        {
                                            "bbox": [
                                                1277,
                                                1026,
                                                2261,
                                                1343
                                            ],
                                            "type": "inline_equation",
                                            "content": "n"
                                        },
                                        {
                                            "bbox": [
                                                1277,
                                                1026,
                                                2261,
                                                1343
                                            ],
                                            "type": "text",
                                            "content": " represents the number of [CLS]."
                                        }
                                    ]
                                }
                            ],
                            "index": 5,
                            "type": "table_caption"
                        }
                    ],
                    "index": 6
                },
                {
                    "bbox": [
                        1277,
                        1435,
                        2261,
                        1834
                    ],
                    "type": "text",
                    "lines": [],
                    "index": 7,
                    "lines_deleted": true
                },
                {
                    "bbox": [
                        1277,
                        1890,
                        1619,
                        1940
                    ],
                    "type": "title",
                    "lines": [
                        {
                            "bbox": [
                                1277,
                                1890,
                                1619,
                                1940
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        1277,
                                        1890,
                                        1619,
                                        1940
                                    ],
                                    "type": "text",
                                    "content": "4.3.Ablation Study"
                                }
                            ]
                        }
                    ],
                    "index": 8,
                    "level": 1
                },
                {
                    "bbox": [
                        1275,
                        1970,
                        2261,
                        2115
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                1275,
                                1970,
                                2261,
                                2115
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        1275,
                                        1970,
                                        2261,
                                        2115
                                    ],
                                    "type": "text",
                                    "content": "Analysis on Additional [CLS].Following the network design process, all experiments of this part were conducted on the setting with only the step 1 in Quantity module (Sec 3.2)."
                                }
                            ]
                        }
                    ],
                    "index": 9
                },
                {
                    "bbox": [
                        1277,
                        2145,
                        2261,
                        2989
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                1277,
                                2145,
                                2261,
                                2989
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        1277,
                                        2145,
                                        2261,
                                        2989
                                    ],
                                    "type": "text",
                                    "content": "As shown in Tab. 2, both of different [CLS] aggregation methods and different numbers of [CLS] can affect network performance. Comparing "
                                },
                                {
                                    "bbox": [
                                        1277,
                                        2145,
                                        2261,
                                        2989
                                    ],
                                    "type": "inline_equation",
                                    "content": "[\\mathsf{CLS}_i^* ]"
                                },
                                {
                                    "bbox": [
                                        1277,
                                        2145,
                                        2261,
                                        2989
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        1277,
                                        2145,
                                        2261,
                                        2989
                                    ],
                                    "type": "inline_equation",
                                    "content": "[\\mathsf{CLS}]_i^v"
                                },
                                {
                                    "bbox": [
                                        1277,
                                        2145,
                                        2261,
                                        2989
                                    ],
                                    "type": "text",
                                    "content": " with the same number (i.e., "
                                },
                                {
                                    "bbox": [
                                        1277,
                                        2145,
                                        2261,
                                        2989
                                    ],
                                    "type": "inline_equation",
                                    "content": "n = 2"
                                },
                                {
                                    "bbox": [
                                        1277,
                                        2145,
                                        2261,
                                        2989
                                    ],
                                    "type": "text",
                                    "content": " of [CLS], the latter has "
                                },
                                {
                                    "bbox": [
                                        1277,
                                        2145,
                                        2261,
                                        2989
                                    ],
                                    "type": "inline_equation",
                                    "content": "7.15\\%"
                                },
                                {
                                    "bbox": [
                                        1277,
                                        2145,
                                        2261,
                                        2989
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        1277,
                                        2145,
                                        2261,
                                        2989
                                    ],
                                    "type": "inline_equation",
                                    "content": "0.86\\%"
                                },
                                {
                                    "bbox": [
                                        1277,
                                        2145,
                                        2261,
                                        2989
                                    ],
                                    "type": "text",
                                    "content": " higher location and time prediction accuracy (ID: 13,16,20,23). Besides, the performance of "
                                },
                                {
                                    "bbox": [
                                        1277,
                                        2145,
                                        2261,
                                        2989
                                    ],
                                    "type": "inline_equation",
                                    "content": "[\\mathsf{CLS}_i^* ]"
                                },
                                {
                                    "bbox": [
                                        1277,
                                        2145,
                                        2261,
                                        2989
                                    ],
                                    "type": "text",
                                    "content": " is not significantly affected by the number of [CLS] (ID: 13- 15,20- 22). We argue that using MLP to aggregate the embeddings may destroy CLIP's original representation. It is better to separately calculate the similarities across each "
                                },
                                {
                                    "bbox": [
                                        1277,
                                        2145,
                                        2261,
                                        2989
                                    ],
                                    "type": "inline_equation",
                                    "content": "[\\mathsf{CLS}]_i^v"
                                },
                                {
                                    "bbox": [
                                        1277,
                                        2145,
                                        2261,
                                        2989
                                    ],
                                    "type": "text",
                                    "content": " with the location and time labels and then select the one with the most significant value as the prediction. Then we analyze how different numbers of [CLS] affect the model performance. When "
                                },
                                {
                                    "bbox": [
                                        1277,
                                        2145,
                                        2261,
                                        2989
                                    ],
                                    "type": "inline_equation",
                                    "content": "n"
                                },
                                {
                                    "bbox": [
                                        1277,
                                        2145,
                                        2261,
                                        2989
                                    ],
                                    "type": "text",
                                    "content": " was increased to 8, no significant performance difference was observed, so we finally chose "
                                },
                                {
                                    "bbox": [
                                        1277,
                                        2145,
                                        2261,
                                        2989
                                    ],
                                    "type": "inline_equation",
                                    "content": "n = 6"
                                },
                                {
                                    "bbox": [
                                        1277,
                                        2145,
                                        2261,
                                        2989
                                    ],
                                    "type": "text",
                                    "content": " in the following experiments (ID: 17- 19, 24- 26). The results indicate that the additional [CLS] effectively"
                                }
                            ]
                        }
                    ],
                    "index": 10
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                2550,
                3300
            ],
            "page_idx": 0
        }
    ],
    "_backend": "vlm",
    "_version_name": "2.1.9"
}