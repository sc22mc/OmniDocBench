{
    "pdf_info": [
        {
            "para_blocks": [
                {
                    "type": "table",
                    "bbox": [
                        344,
                        267,
                        2208,
                        735
                    ],
                    "blocks": [
                        {
                            "bbox": [
                                344,
                                267,
                                2208,
                                735
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        344,
                                        267,
                                        2208,
                                        735
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                344,
                                                267,
                                                2208,
                                                735
                                            ],
                                            "type": "table",
                                            "html": "<table><tr><td rowspan=\"2\">Model Type</td><td rowspan=\"2\">Model</td><td colspan=\"3\">Language</td><td colspan=\"3\">Text background</td><td colspan=\"3\">Text Rotate</td><td></td></tr><tr><td>EN</td><td>ZH</td><td>Mixed</td><td>White</td><td>Single</td><td>Multi</td><td>Normal</td><td>Rotate90</td><td>Rotate270</td><td>Horizontal</td></tr><tr><td rowspan=\"5\">Expert Vision Models</td><td>PaddleOCR [23]</td><td>0.071</td><td>0.055</td><td>0.118</td><td>0.060</td><td>0.038</td><td>0.085</td><td>0.060</td><td>0.015</td><td>0.285</td><td>0.021</td></tr><tr><td>Tesseract OCR 5</td><td>0.179</td><td>0.553</td><td>0.553</td><td>0.453</td><td>0.463</td><td>0.394</td><td>0.448</td><td>0.369</td><td>0.979</td><td>0.982</td></tr><tr><td>Surya 6</td><td>0.057</td><td>0.123</td><td>0.164</td><td>0.093</td><td>0.186</td><td>0.235</td><td>0.104</td><td>0.634</td><td>0.767</td><td>0.255</td></tr><tr><td>GOT-OCR [45]</td><td>0.041</td><td>0.112</td><td>0.135</td><td>0.092</td><td>0.052</td><td>0.155</td><td>0.091</td><td>0.562</td><td>0.966</td><td>0.097</td></tr><tr><td>Mathpix 4</td><td>0.033</td><td>0.240</td><td>0.261</td><td>0.185</td><td>0.121</td><td>0.166</td><td>0.180</td><td>0.038</td><td>0.185</td><td>0.638</td></tr><tr><td rowspan=\"3\">Vision Language Models</td><td>Qwen2-VL-72B [44]</td><td>0.072</td><td>0.274</td><td>0.286</td><td>0.234</td><td>0.155</td><td>0.148</td><td>0.223</td><td>0.273</td><td>0.771</td><td>0.067</td></tr><tr><td>InternVL2-76B [8]</td><td>0.074</td><td>0.155</td><td>0.242</td><td>0.113</td><td>0.352</td><td>0.269</td><td>0.132</td><td>0.610</td><td>0.907</td><td>0.595</td></tr><tr><td>GPT4o [2]</td><td>0.020</td><td>0.224</td><td>0.125</td><td>0.167</td><td>0.140</td><td>0.220</td><td>0.168</td><td>0.115</td><td>0.718</td><td>0.132</td></tr></table>",
                                            "image_path": "fb89ce7123df97bcf3a1966210960f41de6cb179acd63eaa5690e9d074f17fb4.jpg"
                                        }
                                    ]
                                }
                            ],
                            "index": 1,
                            "type": "table_body"
                        },
                        {
                            "bbox": [
                                270,
                                772,
                                2277,
                                818
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        270,
                                        772,
                                        2277,
                                        818
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                270,
                                                772,
                                                2277,
                                                818
                                            ],
                                            "type": "text",
                                            "content": "Table 8. Component-level evaluation on OmniDocBench OCR subset: results grouped by text attributes using the edit distance metric."
                                        }
                                    ]
                                }
                            ],
                            "index": 0,
                            "type": "table_caption"
                        }
                    ],
                    "index": 1
                },
                {
                    "type": "table",
                    "bbox": [
                        249,
                        884,
                        1224,
                        1290
                    ],
                    "blocks": [
                        {
                            "bbox": [
                                249,
                                884,
                                1224,
                                1290
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        249,
                                        884,
                                        1224,
                                        1290
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                249,
                                                884,
                                                1224,
                                                1290
                                            ],
                                            "type": "table",
                                            "html": "<table><tr><td>Models</td><td>CDM</td><td>ExpRate@CDM</td><td>BLEU</td><td>Norm Edit</td></tr><tr><td>GOT-OCR [45]</td><td>74.1</td><td>28.0</td><td>55.07</td><td>0.290</td></tr><tr><td>Mathpix 4</td><td>86.6</td><td>2.8</td><td>66.56</td><td>0.322</td></tr><tr><td>Pix2Tex 7</td><td>73.9</td><td>39.5</td><td>46.00</td><td>0.337</td></tr><tr><td>UniMERNet-B [40]</td><td>85.0</td><td>60.2</td><td>60.84</td><td>0.238</td></tr><tr><td>GPT4o [2]</td><td>86.8</td><td>65.5</td><td>45.17</td><td>0.282</td></tr><tr><td>InternVL2-76B [8]</td><td>67.4</td><td>54.5</td><td>47.63</td><td>0.308</td></tr><tr><td>Qwen2-VL-72B [44]</td><td>83.8</td><td>55.4</td><td>53.71</td><td>0.285</td></tr></table>",
                                            "image_path": "7fdec318d98bc77f9b2f8b933994995195c792c52591b5f4605412e809513d2d.jpg"
                                        }
                                    ]
                                }
                            ],
                            "index": 3,
                            "type": "table_body"
                        },
                        {
                            "bbox": [
                                239,
                                1316,
                                1226,
                                1409
                            ],
                            "lines": [
                                {
                                    "bbox": [
                                        239,
                                        1316,
                                        1226,
                                        1409
                                    ],
                                    "spans": [
                                        {
                                            "bbox": [
                                                239,
                                                1316,
                                                1226,
                                                1409
                                            ],
                                            "type": "text",
                                            "content": "Table 9. Component-level formula recognition evaluation on OmniDocBench formula subset."
                                        }
                                    ]
                                }
                            ],
                            "index": 2,
                            "type": "table_caption"
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        239,
                        1448,
                        1226,
                        1947
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                239,
                                1448,
                                1226,
                                1947
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        239,
                                        1448,
                                        1226,
                                        1947
                                    ],
                                    "type": "text",
                                    "content": "ever, struggle with high- density documents like newspapers due to limitations in input resolution and token length. In contrast, pipeline tools leverage layout- based segmentation to process components individually, maintaining accuracy in complex layouts. Enhancing VLMs with layout- aware designs and domain- specific fine- tuning offers a promising path forward. OmniDocBench facilitates this by providing detailed annotations for layout, text, formulas, and tables, enabling comprehensive benchmarking and modular tool development for diverse document parsing tasks."
                                }
                            ]
                        }
                    ],
                    "index": 4
                },
                {
                    "bbox": [
                        242,
                        1993,
                        925,
                        2046
                    ],
                    "type": "title",
                    "lines": [
                        {
                            "bbox": [
                                242,
                                1993,
                                925,
                                2046
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        242,
                                        1993,
                                        925,
                                        2046
                                    ],
                                    "type": "text",
                                    "content": "5.2. Single Task Evaluation Results"
                                }
                            ]
                        }
                    ],
                    "index": 5,
                    "level": 1
                },
                {
                    "bbox": [
                        239,
                        2075,
                        1231,
                        2666
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                239,
                                2075,
                                1231,
                                2666
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        239,
                                        2075,
                                        1231,
                                        2666
                                    ],
                                    "type": "text",
                                    "content": "Layout Detection Results. Layout detection is the first step in document parsing using pipeline tools. A robust layout detection algorithm should perform well across a variety of document types. Table 6 presents an evaluation of leading layout detection models. The DocLayout- YOLO method, which is pre- trained on diverse synthetic document data, significantly outperforms other approaches. This superiority is a key factor in MinerU's integration of DocLayout- YOLO, contributing to its outstanding overall performance. Other methods perform well on books and academic literature but struggle with more diverse formats due to limited training data."
                                }
                            ]
                        }
                    ],
                    "index": 6
                },
                {
                    "bbox": [
                        239,
                        2676,
                        1226,
                        2973
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                239,
                                2676,
                                1226,
                                2973
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        239,
                                        2676,
                                        1226,
                                        2973
                                    ],
                                    "type": "text",
                                    "content": "Table Recognition Results. In Table 7, We evaluate table recognition models across three dimensions on our OmniDocBench table subset: language diversity, table frame types, and special situations. Among all models, OCRbased models demonstrate superior overall performance, with RapidTable achieving the highest scores in language "
                                }
                            ]
                        },
                        {
                            "bbox": [
                                1315,
                                891,
                                2305,
                                1290
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        1315,
                                        891,
                                        2305,
                                        1290
                                    ],
                                    "type": "text",
                                    "content": "diversity and maintaining stable performance across different frame types. Expert VLMs show competitive results in specific scenarios, with StructEqTable [55] excelling in no- frame tables and showing better rotation robustness. General VLMs (Qwen2- VL- 7B and InternVL2- 8B) exhibit relatively lower but consistent performance, suggesting that while general- purpose VLMs have made progress in table understanding, they still lag behind specialized solutions."
                                }
                            ]
                        }
                    ],
                    "index": 7
                },
                {
                    "bbox": [
                        1315,
                        891,
                        2305,
                        1290
                    ],
                    "type": "text",
                    "lines": [],
                    "index": 8,
                    "lines_deleted": true
                },
                {
                    "bbox": [
                        1315,
                        1290,
                        2307,
                        1541
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                1315,
                                1290,
                                2307,
                                1541
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        1315,
                                        1290,
                                        2307,
                                        1541
                                    ],
                                    "type": "text",
                                    "content": "Text Recognition Results. Table 8 compares OCR tools across languages, backgrounds, and rotations using Edit Distance. PaddleOCR outperforms all competitors, followed by GOT- OCR and Mathpix. General VLMs struggle to handle text rotation or mixed- language scenarios."
                                }
                            ]
                        }
                    ],
                    "index": 9
                },
                {
                    "bbox": [
                        1315,
                        1547,
                        2307,
                        2039
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                1315,
                                1547,
                                2307,
                                2039
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        1315,
                                        1547,
                                        2307,
                                        2039
                                    ],
                                    "type": "text",
                                    "content": "Formula Recognition Results. Table 9 presents results on formula parsing, using CDM, BLEU, and normalized Edit Distance. GPT- 4o, Mathpix, and UniMERNet achieve results of "
                                },
                                {
                                    "bbox": [
                                        1315,
                                        1547,
                                        2307,
                                        2039
                                    ],
                                    "type": "inline_equation",
                                    "content": "86.8\\%"
                                },
                                {
                                    "bbox": [
                                        1315,
                                        1547,
                                        2307,
                                        2039
                                    ],
                                    "type": "inline_equation",
                                    "content": "86.6\\%"
                                },
                                {
                                    "bbox": [
                                        1315,
                                        1547,
                                        2307,
                                        2039
                                    ],
                                    "type": "text",
                                    "content": " and "
                                },
                                {
                                    "bbox": [
                                        1315,
                                        1547,
                                        2307,
                                        2039
                                    ],
                                    "type": "inline_equation",
                                    "content": "85.0\\%"
                                },
                                {
                                    "bbox": [
                                        1315,
                                        1547,
                                        2307,
                                        2039
                                    ],
                                    "type": "text",
                                    "content": " respectively.Notably, GPT- 4o excels with a recall rate of "
                                },
                                {
                                    "bbox": [
                                        1315,
                                        1547,
                                        2307,
                                        2039
                                    ],
                                    "type": "inline_equation",
                                    "content": "65.5\\%"
                                },
                                {
                                    "bbox": [
                                        1315,
                                        1547,
                                        2307,
                                        2039
                                    ],
                                    "type": "text",
                                    "content": " under strict conditions requiring perfect character accuracy. Although Mathpix shows high character- level precision, it occasionally omits punctuation, such as commas, leading to a lower overall correctness rate. Nonetheless, all three models are strong candidates for formula recognition tasks."
                                }
                            ]
                        }
                    ],
                    "index": 10
                },
                {
                    "bbox": [
                        1318,
                        2098,
                        1609,
                        2151
                    ],
                    "type": "title",
                    "lines": [
                        {
                            "bbox": [
                                1318,
                                2098,
                                1609,
                                2151
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        1318,
                                        2098,
                                        1609,
                                        2151
                                    ],
                                    "type": "text",
                                    "content": "6.Conclusion"
                                }
                            ]
                        }
                    ],
                    "index": 11,
                    "level": 1
                },
                {
                    "bbox": [
                        1315,
                        2184,
                        2305,
                        2679
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                1315,
                                2184,
                                2305,
                                2679
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        1315,
                                        2184,
                                        2305,
                                        2679
                                    ],
                                    "type": "text",
                                    "content": "6. ConclusionThis paper addresses the lack of diverse and realistic benchmarks in document parsing research by introducing OmniDocBench, a dataset featuring a variety of page types with comprehensive annotations, along with a flexible and reliable evaluation framework. OmniDocBench enables systematic and fair assessments of document parsing methods, providing crucial insights for advancing the field. Its task-specific and attribute-level evaluations facilitate targeted model optimization, promoting more robust and effective parsing solutions."
                                }
                            ]
                        }
                    ],
                    "index": 12
                },
                {
                    "bbox": [
                        1318,
                        2739,
                        1762,
                        2791
                    ],
                    "type": "title",
                    "lines": [
                        {
                            "bbox": [
                                1318,
                                2739,
                                1762,
                                2791
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        1318,
                                        2739,
                                        1762,
                                        2791
                                    ],
                                    "type": "text",
                                    "content": "7. Acknowledgments"
                                }
                            ]
                        }
                    ],
                    "index": 13,
                    "level": 1
                },
                {
                    "bbox": [
                        1315,
                        2824,
                        2305,
                        2973
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                1315,
                                2824,
                                2305,
                                2973
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        1315,
                                        2824,
                                        2305,
                                        2973
                                    ],
                                    "type": "text",
                                    "content": "7. AcknowledgmentsThis project was supported by National Key R&D Program of China (NO.2022ZD0160102) and Shanghai Artificial Intelligence Laboratory."
                                }
                            ]
                        }
                    ],
                    "index": 14
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                2550,
                3300
            ],
            "page_idx": 0
        }
    ],
    "_backend": "vlm",
    "_version_name": "2.1.9"
}