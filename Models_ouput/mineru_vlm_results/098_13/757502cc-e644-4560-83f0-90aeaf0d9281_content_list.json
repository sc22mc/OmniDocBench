[
    {
        "type": "image",
        "img_path": "images/ae7bf735c7d8009fa3acaea19669ea4bdcf3e55ff31733015eb6272b2f6b3a6a.jpg",
        "image_caption": [
            "Figure 7: Pretraining with the text continuation objective to predict next tokens"
        ],
        "image_footnote": [],
        "page_idx": 0
    },
    {
        "type": "image",
        "img_path": "images/343c3c347966c9055bfdb81d763e71ec9b528a175b50f687012b6b957fdff2a7.jpg",
        "image_caption": [
            "Figure 8: Instruct fine-tuning of the ICAE to make its produced memory slots interact with prompts for accomplishing various purposes in the target LLM. In this figure,  $(p_{1},\\ldots ,p_{m})$  denotes the prompt tokens and  $(r_{1},\\ldots ,r_{n})$  denotes the response tokens."
        ],
        "image_footnote": [],
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "B PROFILING SETUP",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "We test the latency (Section 3.3.2) on 1 Nvidia A 100 GPU (80GB). The test machine has the CPU of AMD EPYCTM 7413 with 24 cores and 216GB RAM. The runtime configuration is python  $= 3.9$ , pytorch  $= 2.0.1$ , cuda  $= 11.7$ , cudnn  $= 8.5$ .",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "C PROMPT-WITH-CONTEXT DATASET",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "We introduce the PROMPT- WITH- CONTEXT (PwC) dataset where each sample entry is a triple (text, prompt, answer), as depicted in Figure 9. To construct this dataset, we first sample 20k texts from the Pile dataset. Then, for each text, we employ the GPT- 4 to provide 15 prompts (10 specific prompts and 5 general prompts) about the text and give the corresponding answers. The prompt instructing the GPT- 4 is outlined in Listing 1.",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "The dataset is composed of 240k examples for training purposes, with an additional 18k examples for testing. The context length distribution of test samples is presented in Table 10.",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Listing 1: Prompt used by GPT4 API to generate the PwC dataset.",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Design 10 prompts specified to the above text to test understanding of the above text. These prompts should be diverse and cover as many",
        "page_idx": 0
    }
]