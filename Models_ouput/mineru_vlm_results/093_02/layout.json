{
    "pdf_info": [
        {
            "para_blocks": [
                {
                    "bbox": [
                        249,
                        264,
                        1202,
                        458
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                249,
                                264,
                                1202,
                                458
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        249,
                                        264,
                                        1202,
                                        458
                                    ],
                                    "type": "text",
                                    "content": "access databases between 2022 and 2023. The largest dataset of insect images from the orchard was obtained through autonomous missions conducted by unmanned aerial vehicles (UAVs), commonly known as drones."
                                }
                            ]
                        }
                    ],
                    "index": 0
                },
                {
                    "bbox": [
                        195,
                        465,
                        1202,
                        709
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                195,
                                465,
                                1202,
                                709
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        195,
                                        465,
                                        1202,
                                        709
                                    ],
                                    "type": "text",
                                    "content": "2) We evaluated the performance of different ML models to achieve accurate BMSB detection, with a focus on the single shot multibox detector (SSD), detection transformer (DETR), YOLOv5, YOLOv9, and YOLOv10 architectures."
                                }
                            ]
                        }
                    ],
                    "index": 1
                },
                {
                    "bbox": [
                        195,
                        716,
                        1202,
                        1059
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                195,
                                716,
                                1202,
                                1059
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        195,
                                        716,
                                        1202,
                                        1059
                                    ],
                                    "type": "text",
                                    "content": "3) We explored alternatives to RGB, such as shortwave infrared hyperspectral imaging (SWIR-HSI) and visible near infrared (Vis-NIR) multispectral imaging (MSI) systems, identifying spectral regions for affordable and rapid multispectral sensors to use with RGB cameras and drones. However, our research was limited to the lab due to the lack of commercially available solutions."
                                }
                            ]
                        }
                    ],
                    "index": 2
                },
                {
                    "bbox": [
                        195,
                        1062,
                        1202,
                        1458
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                195,
                                1062,
                                1202,
                                1458
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        195,
                                        1062,
                                        1202,
                                        1458
                                    ],
                                    "type": "text",
                                    "content": "4) We developed an intelligent sticky trap with integrated cameras and edge-based convolutional neural networks (CNNs) for image classification on resource constrained Internet of Things (IoT) systems. Despite the drawbacks associated with traps using aggregation pheromones (attracting the insect of interest to the trap location), they are generally accepted by field operators as the primary source of data for insect population identification."
                                }
                            ]
                        }
                    ],
                    "index": 3
                },
                {
                    "bbox": [
                        195,
                        1461,
                        1205,
                        1808
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                195,
                                1461,
                                1205,
                                1808
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        195,
                                        1461,
                                        1205,
                                        1808
                                    ],
                                    "type": "text",
                                    "content": "5) We developed a versatile client-server application with the primary goal of integrating any trained model and making it accessible to end-users. The ultimate aim of this application is to engage farmers in a decision support system. In addition, the application enables UAVs to plan their routes within orchards to capture images at specific waypoints for the RGB image dataset."
                                }
                            ]
                        }
                    ],
                    "index": 4
                },
                {
                    "bbox": [
                        195,
                        1815,
                        1205,
                        2508
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                195,
                                1815,
                                1205,
                                2508
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        195,
                                        1815,
                                        1205,
                                        2508
                                    ],
                                    "type": "text",
                                    "content": "6) We proposed postharvest strategies crucial for maintaining fruit quality in the market. Fruits that are punctured at an early stage develop significant deformities, making them clearly unmarketable. On the other hand, fruits punctured just before harvesting may present internal damages not visible to the naked eye at the time of harvest and transfer to the marketplace. Besides compromising the safety of healthy fruit and facilitating the outbreak of other diseases, their presence in the market can undermine consumer confidence in fruit quality. Hence, we recommended integrating nondestructive techniques, such as SWIR, into the fruit sorting system to enhance the quality of marketable fruits by identifying previously undetectable damage at an early stage."
                                }
                            ]
                        }
                    ],
                    "index": 5
                },
                {
                    "bbox": [
                        153,
                        2511,
                        1205,
                        2950
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                153,
                                2511,
                                1205,
                                2950
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        153,
                                        2511,
                                        1205,
                                        2950
                                    ],
                                    "type": "text",
                                    "content": "In this article, we delineate the methodologies, findings, and implications derived from our comprehensive endeavor aimed at advancing BMSB monitoring techniques, amalgamating cutting- edge technologies with practical surveillance strategies to mitigate agricultural threats effectively. So, our objective was to develop information and communication technology enabled strategies for implementing the most effective, most cost- efficient, autonomous and adatable monitoring of the BMSB with minimal human intervention."
                                }
                            ]
                        }
                    ],
                    "index": 6
                },
                {
                    "bbox": [
                        153,
                        2956,
                        1202,
                        3105
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                153,
                                2956,
                                1202,
                                3105
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        153,
                                        2956,
                                        1202,
                                        3105
                                    ],
                                    "type": "text",
                                    "content": "The rest of this article is organized as follows. Section II discusses related works. Sections III and IV present ML techniques that work with RGB and spectral imaging, respectively."
                                }
                            ]
                        }
                    ],
                    "index": 7
                },
                {
                    "bbox": [
                        1252,
                        264,
                        2301,
                        511
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                1252,
                                264,
                                2301,
                                511
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        1252,
                                        264,
                                        2301,
                                        511
                                    ],
                                    "type": "text",
                                    "content": "Section V presents the sticky trap imaging system, which was developed. Section VI showcases the client- server application. Section VII proposes a technique for fruit puncture detection. Finally, Section VIII concludes this article and future research directions."
                                }
                            ]
                        }
                    ],
                    "index": 8
                },
                {
                    "bbox": [
                        1608,
                        567,
                        1942,
                        613
                    ],
                    "type": "title",
                    "lines": [
                        {
                            "bbox": [
                                1608,
                                567,
                                1942,
                                613
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        1608,
                                        567,
                                        1942,
                                        613
                                    ],
                                    "type": "text",
                                    "content": "II. RELATED WORK"
                                }
                            ]
                        }
                    ],
                    "index": 9,
                    "level": 1
                },
                {
                    "bbox": [
                        1252,
                        640,
                        2299,
                        735
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                1252,
                                640,
                                2299,
                                735
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        1252,
                                        640,
                                        2299,
                                        735
                                    ],
                                    "type": "text",
                                    "content": "In this section, we review the literature on computer vision, focusing on its applications in insect and puncture detection."
                                }
                            ]
                        }
                    ],
                    "index": 10
                },
                {
                    "bbox": [
                        1252,
                        795,
                        1584,
                        838
                    ],
                    "type": "title",
                    "lines": [
                        {
                            "bbox": [
                                1252,
                                795,
                                1584,
                                838
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        1252,
                                        795,
                                        1584,
                                        838
                                    ],
                                    "type": "text",
                                    "content": "A. Insect Detection"
                                }
                            ]
                        }
                    ],
                    "index": 11,
                    "level": 1
                },
                {
                    "bbox": [
                        1252,
                        864,
                        2301,
                        1656
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                1252,
                                864,
                                2301,
                                1656
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        1252,
                                        864,
                                        2301,
                                        1656
                                    ],
                                    "type": "text",
                                    "content": "Nowadays, there has been a growing trend toward leveraging ML techniques for insect species monitoring. Traditional methods, such as support vector machines, adaptive boosting, and neural networks (NNs) [5], [6], [7], have been widely utilized alongside deep learning techniques based on CNNs [8], [9], [10] to achieve optimal results in insect monitoring. For instance, a novel approach for early detection and continuous monitoring of adult- stage whitefly and thrip in greenhouses has been proposed in [5]. Their approach, based on an image- processing algorithm and artificial NNs, yielded highly satisfactory results in whitefly and thrips identification [5]. Such approaches hold significant promise in enhancing integrated pest management strategies and in reducing the dependence on harmful chemicals in greenhouse agriculture. In addition, the use of pheromone loaded sticky traps is a common and effective method for autonomously detecting pest infestations [11]."
                                }
                            ]
                        }
                    ],
                    "index": 12
                },
                {
                    "bbox": [
                        1252,
                        1663,
                        2301,
                        2603
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                1252,
                                1663,
                                2301,
                                2603
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        1252,
                                        1663,
                                        2301,
                                        2603
                                    ],
                                    "type": "text",
                                    "content": "In the literature, apart from the results of HALy.ID, there are some results on the Pentatomidae family to which BMSB belongs [12], [13], [14]. However, all these results did not evaluate their models on datasets built from in- field images as we do. Trufelea et al. [12] proposed training a CNN to classify four different kinds of Pentatomidae insects, including BMSB adult/nymph, Pyrrhocoris apterus, and Nezara viridula. Many images are from the Maryland Biodiversity database [15], and others are from a custom dataset collected by professional cameras. Ichim et al. [13] investigated the identification of BMSB insects with four CNNs, namely, GoogLeNet, ResNet101, DenseNet201, and VGG19. One dataset is built on two public datasets with many different insects, and a custom dataset is collected with a mini- drone containing images with adults and nymphs of BMSB. Transfer learning and data augmentation are used to reduce computational effort during the learning phase, and statistical indicators (such as precision and recall) derived from confusion matrices are employed to evaluate the performance of each CNN."
                                }
                            ]
                        }
                    ],
                    "index": 13
                },
                {
                    "bbox": [
                        1252,
                        2610,
                        2301,
                        3102
                    ],
                    "type": "text",
                    "lines": [
                        {
                            "bbox": [
                                1252,
                                2610,
                                2301,
                                3102
                            ],
                            "spans": [
                                {
                                    "bbox": [
                                        1252,
                                        2610,
                                        2301,
                                        3102
                                    ],
                                    "type": "text",
                                    "content": "Very recently, the YOLO model [16], [17] has been used to detect harmful insects in ecological orchards by Sava et al. [14]. The authors evaluated YOLO with region- based CNNs, and several YOLO models have been trained, validated, and tested on the Maryland dataset [15], which contains professional macroimages of BMSB in different poses, from different short distances, and at different stages of evolution. Betti Sorbelli et al. [18], [19], [20] explored the use of RGB cameras, drones, and computer vision algorithms to monitor and detect the BMSB in orchards using a drone in first person view. While these"
                                }
                            ]
                        }
                    ],
                    "index": 14
                }
            ],
            "discarded_blocks": [],
            "page_size": [
                2475,
                3300
            ],
            "page_idx": 0
        }
    ],
    "_backend": "vlm",
    "_version_name": "2.1.9"
}