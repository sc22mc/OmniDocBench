[
    {
        "type": "text",
        "text": "are limited compared to the more substantial enhancements observed in simpler problem categories. After directly adding 5 correct CoT examples into the prompt, GPT- 4 BoT + CoT demonstrates a significant performance boost, surpassing GPT- 4 BoT by  $7.7\\%$  and  $11.5\\%$  in Precalculus and Intermediate Algebra domains, respectively. This basic conclusion from these observations is that to guarantee the top performance of BoT in complex mathematical problems, relying on trial- and- error analysis to learn how to reason is not sufficient; instead, the correct answers should also be provided in the prompt for LLMs.",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "While GPT3.5 with BoT may initially fall behind GPT- 4 CoT, leveraging GPT- 4 as the evaluator and analyzer to generate experience allows GPT- 3.5 BoT (GPT- 4) to outperform GPT- 4 Complex CoT. With the GPT3.5, which has less capacity than GPT4, as the LLM, the solving rate obtained by BoT is at least  $7.7\\%$  (on Algebra) lower than GPT4 ComplexCoT. It is evident that when less powerful LLMs produce lower- quality trial- and- error analyses, the BoT is unable to outperform GPT4 ComplexCoT. Thus, after using the GPT4 in the experience generation part while GPT3.5 is only used to generate reasoning steps, GPT3.5 BoT (GPT4) shows a significant improvement in all categories, leading to a solving rate of  $55.8\\%$ , which outperforms GPT4 ComplexCoT by  $5.5\\%$  and is even  $1.9\\%$  higher than the current state- of- the- art GPT4 PHP+ComplexCoT. These observations further demonstrate that the accumulation of experience over iterations in the prompt constitutes the primary factor contributing to the success of the BoT framework.",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "G REASONING RESULTS OF \"GAME OF 24\"",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "First, in Table 5 - Table 9 we present the detailed prompts that BoT used during the reasoning process, thus providing a comprehensive understanding of what BoT does within each iteration. Then, starting from Table 10 we show some exact examples containing the whole reasoning process of BoT. Following the basic settings shown in the experiment section, these experiments are obtained using BoT with the GPT- 3.5- turbo model.",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Table 5: Reasoning steps generated by gpt- 3.5- turbo when no experience is included in the input prompt. We first let the model generate one step of reasoning five times to check the diversity and then present the final reasoning chain after finishing the first iteration of BoT.",
        "page_idx": 0
    },
    {
        "type": "table",
        "img_path": "images/aa60a68a5a7c05ea6fc8e72bdc4415074090d640148d2c69432d7e02a7ae5931.jpg",
        "table_caption": [],
        "table_footnote": [],
        "table_body": "<table><tr><td>Prompt of Game of 24 without experience</td></tr><tr><td>In the game of 24, you are given four numbers, and the goal is to use basic arithmetic operations (+,-,*,/ ) to combine these numbers and obtain a result of 24. You can only use each number once, step, parentheses can be used to change the order of operations.</td></tr><tr><td>Analysis format of each step: Step, Current set: , Selected two numbers: , Operation: , Computed new number: , Remaining numbers: , New set: .</td></tr><tr><td>The given four numbers are: 1 1 4 6.</td></tr><tr><td>Let&#x27;s think step by step.</td></tr><tr><td>Recall historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical Historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical historical Historical H R E A S O N I N G R E S U L T S O F &quot;G S M 8 K&quot;</td></tr><tr><td>Five responses from the gpt-3.5-turbo</td></tr><tr><td>Step 1, Current set: 1 1 4 6, Selected two numbers: 1 1, Operation: +, Computed new number: 2, Remaining numbers: 4 6, New set: 2 4 6.,</td></tr><tr><td>Step 1, Current set: 1 1 4 6, Selected two numbers: 1 1, Operation: +, Computed new number: 2, Remaining numbers: 4 6, New set: 2 4 6.,</td></tr><tr><td>Step 1, Current set: 1 1 4 6, Selected two numbers: 1 1, Operation: +, Computed new numbers: 2, Remaining numbers: 4 6, New set: 2 4 6.,</td></tr><tr><td>Step 1, Current set: 1 1 4 6, Selected two numbers: 1 1, Operation: +, Computed new number: 2, Remaining numbers: 4 6, New set: 2 4 6.,</td></tr><tr><td>Step 1, Current set: 1 4 6, Selected two numbers: 1 1, Operation: +, Computed new number: 2, Remaining numbers: 4 6, New set: 2 4 6.,</td></tr><tr><td>Obtained reasoning chain after aggregation</td></tr><tr><td>Step 1, Current set: 1 1 4 6, Selected two numbers: 1 1, Operation: +, Computed new number: 2, Remaining numbers: 4 6, New set: 2 4 6., Evaluate Score: 0.7</td></tr><tr><td>Step 2, Current set: 1 1 4 6, Selected two numbers: 1 4, Operation: *, Computed new number: 4, Remaining numbers: 1 6, New set: 4 1 6., Evaluate Score: 0.7</td></tr><tr><td>Step 1, Current set: 1 1 4 6, Selected two numbers: 1 1, Operation: *, Computed new number: 1, Remaining numbers: 4 6, New set: 1 4 6., Evaluate Score: 0.7</td></tr></table>",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "H REASONING RESULTS OF \"GSM8K\"",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "BoT uses similar basic prompts and the specific format as shown in Table 5 - Table 9 Only the task prompt will be changed, as shown in Table 15 Then, starting from Table 16 we show some exact examples containing the whole reasoning process of BoT. Following the basic settings shown in the experiment section, these experiments are obtained using BoT with the GPT- 3.5- turbo model.",
        "page_idx": 0
    }
]