[
    {
        "type": "text",
        "text": "amount of coefficients but reducing the necessary steps and computational complexity with respect to the MFCC as follows. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "1）Division of the audio into windows ranging from 256 to 4096 audio samples without overlapping.   \n2）Application of the Hann windowing function for signal smoothingatthe window edges.   \n3）Application of DFT to each window for signal frequency domain conversion.   \n4）Computation of the magnitude of the spectrogram.   \n5） Calculation of the mean value for each frequency bin across all chunk duration.This step results in a number of input values for the classifier that depends on the window size $\\begin{array} { r } { n _ { \\mathrm { b i n s } } = \\frac { m } { 2 } + 1 } \\end{array}$ ,where $m$ represents the window size. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "D. Classifers ",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "In this study,we conducted a comparison between two distinct classifiers for the binary classification task:one isa NN implemented through the Keras library [35],and the other isa SVM implemented using the scikit-learn (sklearn) library [36]. We focused on these two algorithms without considering convolutional networks that are used in other works [21],[29] because our intention is to keep the complexity of these algorithms low, with the aim of deploying them in microcontroller systems with lowhardware resources. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "1） NN Classifier:Represents a powerful and adaptable machine learning model with the capability to identify intricate patterns in data. The presented approach involved constructing amultilayer perceptron architecture with fullyconnected layers.There are two hidden layers,the first with eight neurons and the second with four neurons.This architecture isused in all the experiments except for the one in which different NN sizesare compared (Section II-B).Each node is implemented with rectified linear unit (ReLU) activation function,while the output layers employ a sigmoid function. The final step involved converting the output to a binary value usinga threshold of 0.5. During the training process,we implemented early stopping with a patience of 5 to prevent overfiting and identify the optimal number of epochs necessry for the training. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "2）SVM Classifer: It is a widely adopted and powerful supervised learning algorithm designed forclassification tasks.Its functionality involves identifying an optimal hyperplane that maximizes the separation between data points associated with distinct classes.In our implementation of SVM,we employed the sklearn library[36],which offers a robust set of tools for machine learningin Python.During our experimentation,we specificallyworked with the radial basis functionkernelfunction and fine-tuned the $C$ parameter for optimal performance. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Theseclassifier parameters are chosen in order to replicate the architecture used in [29],but reducing the complexity of the models removing the convolution layers and scaling down the architecture size and obtaininga lighter model. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "E.Evaluation Metrics ",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "At the end of each experiment,obtaining aset of parameters is crucial to compare different characteristics and provide a good estimation of which model performs better in detecting the presence of the queen bee.In particular, thiswork adopts the technique of crossvalidation by dividing the training set into tenfolds.The metrics extracted include both the mean value and the standard deviation,which are extracted across ten models. Thesemodels are trained with nine foldsand tested with the remaining fold,with a variation in the selected folders for each iteration. The metrics presented are the most common and widely used forbinary classifiers considering true positive (TP) and true negative (TN) the correctly predicted values that can be positive (queen presence) or negative (queen absence),and the false positive (FP) and false negative (FN) the wrong predicted samples as follows. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "1）Precision[positivepredicted value $( P P V ) J$ : It is the ratio of correctly predicted positive observations to the total predicted positives. It provides insights into the accuracy of positive predictions ",
        "page_idx": 0
    },
    {
        "type": "equation",
        "img_path": "images/7f5bc70f8ba7f3fb10b0b3e94ed71886660001b98d4ea95208812525e77750ec.jpg",
        "text": "$$\n\\mathrm { P P V } = { \\frac { \\mathrm { T P } } { \\mathrm { T P } + \\mathrm { F P } } } .\n$$",
        "text_format": "latex",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "2)Recall [truepositive rate $( T P R ) J$ : It is the ratio ofcorrectly predicted positive observations to the total actual positives. It assesses the ability of the model to capture all the relevant instances ",
        "page_idx": 0
    },
    {
        "type": "equation",
        "img_path": "images/961d2dd27b1f6af17b87838b06395edbaf3e4bfeef86cb455da95abe63dd86e4.jpg",
        "text": "$$\n\\mathrm { T P R } = { \\frac { \\mathrm { T P } } { \\mathrm { T P } + \\mathrm { F N } } } .\n$$",
        "text_format": "latex",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "3）Accuracy: Measures the overall correctness of the classifcation model.Itis the ratio of correctly predicted instances to the total instances ",
        "page_idx": 0
    },
    {
        "type": "equation",
        "img_path": "images/40075260b0d9ef561dfc1aaf9154bf67367b2185fc2ef7f579578092ce9f077f.jpg",
        "text": "$$\n\\mathrm { A C C } = { \\frac { \\mathrm { T P } + \\mathrm { T N } } { \\mathrm { T P } + \\mathrm { F N } + \\mathrm { F P } + \\mathrm { T N } } } .\n$$",
        "text_format": "latex",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "4）Fl score: TheF1 score is the harmonic mean of precision and recall.It provides a balance between precision and recall,consideringbothFPand FN ",
        "page_idx": 0
    },
    {
        "type": "equation",
        "img_path": "images/05b40bedbbf8eed12260e43535126e0e9f04e33fa809ac069101b7a61d1c0de7.jpg",
        "text": "$$\nF _ { 1 } \\mathrm { s c o r e } = { \\frac { 2 \\cdot \\mathrm { T P } } { 2 \\cdot \\mathrm { T P } + \\mathrm { F P } + \\mathrm { F N } } } .\n$$",
        "text_format": "latex",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "5）Receiver operating characteristic area under the curve (ROCAUC):ROC AUC represents the area under the ROC curve,which is a plot of the TRP against the FP rate.It evaluates the model’sability to distinguish between classes.   \n6 Confusion matrix:Provides a detailed breakdown of TP, TN,FP,and FN predictions.It is especially useful for understanding the model's performance on the final test. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "By evaluating these metrics,it becomes possible to comprehensively assess the classification performance of different models,considering various aspects.The use of cross-validation ensures a robust evaluation,and reporting both mean values and standard deviations addsa measure of the stability of the model's performanceacrossdifferent folds. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "F.Framework Improvements ",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "In this work,we enriched our Python framework introduced in [25].Specifically，,we integrated the possibility of managingadditional datasets,and in particular the dataset presented ",
        "page_idx": 0
    }
]