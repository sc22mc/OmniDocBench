[
    {
        "type": "table",
        "img_path": "images/a2f2a8f486d4ad375ab3de3afaff7e14c356a3c0f3d15beb37409402e4bd97a5.jpg",
        "table_caption": [
            "TABLE III COMPARISON OFMODEL'SCOMPUTATIONDEMANDS "
        ],
        "table_footnote": [],
        "table_body": "<table><tr><td></td><td></td><td></td><td></td><td></td><td></td><td>DETRSDDYOLOV5-XYOLOV9-TYOLOV9-EYOLOV10-NYOLOV10-X</td><td></td></tr><tr><td>#parameters[M]</td><td>46</td><td>35</td><td>86.7</td><td>2.0</td><td>57.3</td><td>2.3</td><td>29.5</td></tr><tr><td>GFLOPs</td><td>127</td><td>34.5</td><td>205.7</td><td>7.7</td><td>189.0</td><td>6.7</td><td>160.4</td></tr></table>",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "characterizing a more precise detection overall. Conversely, the YOLOv5-X model was able to detect the largest number of BMSB reaching the highest recall. Despite achieving particularly notable metrics scores in the ONLY set, the model has depicted the least robustness against background-only patches, namely, in the ALL set. So,YOLOv5-X was prone to recognize $\\ge 5 5 \\%$ of BMSB instances with a particularly promising precisionwhen a BMSB appears inside the frame.However, this latter capability deteriorates dramatically( $\\ P = 5 3 . 5 \\%$ ）when images without BMSB are considered.Itis noteworthy that each network tends to achieve alarger $P$ than $R$ .Thisphenomenonis strictly related to the poses experienced during the acquisition, compounded by the noise surrounding the BMSB pixels,such as blur or overexposure.Despite the dataset comprisinga diverse range of BMSB samples,certain poses and lighting/blurriness conditions are more frequent than others.Also,since the dataset consists of images captured by a drone operating according to an autonomous protocol, characterizing the entire range of possibilities is extremely challenging.As a result, the networks were ableto detect BMSB instances that presented limited variation in pose and color appearance,thereby minimizing FP.However, instances significantly affected by noise were occasionally missed.Both YOLOv9 and YOLOv10-X achieve interesting performance representing a true step ahead of the predecessor,YOLOv5.Although YOLOv10-X obtained the largest $R$ ， YOLOv9-T achieves the best performance overall. Specifically, it reachesa satisfactorily $R$ $( \\approx 6 0 \\%$ ）and almost thelargest $P$ with both the thresholds, $9 5 . 0 \\%$ and $9 4 . 0 \\%$ ,respectively. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Looking at $\\mathrm { m A P _ { 0 . 5 } }$ ，all the NNs have achieved $\\ge 4 5 \\%$ of BMSB,establishinga satisfactory confidence level overall.On theother hand,the NNs have developed limited abilities in contouringtheBMSBaccordingto $\\mathrm { m A P _ { 0 . 5 } ^ { 0 . 9 5 } }$ because they are less robust when the IoU increases.In other words,the majority of predictions overlap partially with the ground truth. This represents a predictable outcome due to the limited size of the BMSB with respect to the entire image.For monitoringpurposes,recognizing all instances inside the frame,i.e., achieving high recall,is more important than accurately contouringabug,i.e.,achieving highIoU.However, itnoteworthy that both YOLOv9 and YOLOv10 demonstrate improved IoU values between prediction and ground truth, suggesting a clear enhancement with previous releases.Moreover,in comparison with the results in [2O] where entire images are simply resized and fed to the model, the current implementation of the slicing mechanism allows a boost in the performance,specifically in the recall. Indeed, image slicing prevents information losses since it retains every pixel of the original image. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Table III summarizes model's computation demands listing the number of parameters and the number of giga floating point operationsper second (GFLOPs),respectively.We can observe thatYOLOv5-X,YOLOv9-E,YOLOv10-X,SSD,and DETR are more“desktop oriented”due to their requirements,rather than YOLOv9-T and YOLOv10-N that appear compatible with current state-of-the-art embedding system boards.According to thecomputation footprint,both YOLOv9-T and YOLOv10-N are,evenmore so,the bestNNsoverall. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "IV.BMSB DETECTION USING SPECTRAL IMAGING ",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "In the HALY.ID project,alongside a comprehensive analysis of RGB images primarily captured by UAVs,we also conducted an assessmentofspectral imagingasapotential method for field monitoring to detect the presence of BMSB.To this purpose, SWIR-HSIand Vis-NIR MSI systems were evaluated both in the laboratoryand in the field,respectively.In fact,unlike cameras operating exclusively within the visible spectrum,they may mitigate misclassifications caused byBMSB'sresemblance to vegetal backgroundswith similarcolors,such as bark or brown leaves. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "A.Evaluation ofSWIR-HSI ",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "We captured 35 hyperspectral images of BMSB specimens positioned against various vegetal backgrounds (including bark, branches,grass,soil,green/brown leaves) within the 980-1660 nmspectral range,aiming to replicate real field conditions.We acquired the hyperspectral images usinga HSI line-scan system equipped with a desktop NIR Spectral Scanner (DV Optic) incorporatinga SpecimN17E reflectance imaging spectrometer, coupledwitha XenicsXEVA1.7-320camera( $3 2 0 \\times 2 5 6$ pixels) and aSpecim Oles 31 $f / 2 . 0$ optical lens. The acquisition software conducted an automatic calibration of the images based on the dark current signal and ahigh-reflectance standard signal.We excluded pixelsunrelated to either bugs or vegetal backgrounds based onareflectance threshold measured at $1 0 0 0 \\ \\mathrm { n m }$ Inaddition,we preprocessed the images using standard normal variate (SNV)and mean center techniques. Subsequently,we applied principal component analysis (PCA) to each image to implement amasking procedure,thereby separating the pixels belonging to the bugs from those belonging to the vegetal backgrounds.1 ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "To develop classification models capable of distinguishing between BSBM specimens and vegetal backgrounds based on spectral signatures,we assembleda library comprising14000 reference spectra from both classes.We employed the KennardStone algorithm [37] on principal component (PC） scores to select these spectra. Then, we divided the images into training and test sets for model development and validation,respectively. Our classification approach focused on modeling the spectral information contained in the HSI images and identifying the relevant spectral regions to discriminate BMSB from vegetal backgrounds. To do this,we used the soft partial least squaresdiscriminant analysis (Soft PLS-DA）algorithm,coupled with sparse-based methods for spectral variable selection (s-Soft PLS-DA) [38]. This allowed us to build effective classification modelstailored to ourdataset. ",
        "page_idx": 0
    }
]