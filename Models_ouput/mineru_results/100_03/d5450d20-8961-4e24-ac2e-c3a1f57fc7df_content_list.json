[
    {
        "type": "text",
        "text": "ToT performs well on problems that even challenge GPT-4OpenAI (2023) Considering its high ability,thebase thought structure of BoTlargelyutilizes this tree thought structure ToT.And,thanks to the boosting framework,the tree structure generated in each iteration ofBoTis binary and shallow instead of the ToT's complex tree,in which each node corresponds to massive child nodes.However, the base structure is not restricted to ToT.In contrast, BoT is fexible as the base thought structure can be either ToT, GoTBesta et al.(2023), or $\\mathrm { C R } \\lfloor \\mathrm { Z h a n g e t a l . } \\vert ( \\mathbb { 2 0 } 2 3 \\mathrm { b } )$ ,where Graph of Thoughts (GoT) Besta et al. (2023) is the most recent work that expands the thought structure into a graph format. This paper will only focus on the ToT as the base thought structure and leave the usage of GoT for future work. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Automatic Prompting. Releasing humans from task-specific prompts attracts much attention Shin $\\mathbb { E } ^ { \\mathrm { t } \\mathrm { a l . } } \\mathbb { \\textcircled { 2 0 2 0 } }$ .To guarantee the reasoning ability of LLMs, conventional $\\mathrm { C o T } [ \\mathrm { W e i \\ e t \\ a l . } ] ( 2 0 2 2 )$ relies on human priors to manually generate task-specific demonstrations as the prompt.However, the zero-shot $\\dot { \\mathrm { C o T } } [ \\mathrm { K o j i m a e t a l . } ] ( \\dot { 2 } 0 2 2 )$ shows that even without hand-crafted examples,by simply adding â€œLet's think step by step\" to the prompt,LLMs are able to perform step-by-step reasoning toward accurate answers. These insights have spurred a series of subsequent studies. Auto-CoT Zhang et al. $\\textcircled { 2 0 2 2 }$ eliminates manual efforts by retrieving usable reasoning chains generated by zero-shot CoT. Active-PromptDiao et al. $\\textcircled { 1 2 0 2 3 }$ first measures the uncertainty of a set of questions and thus selects only the uncertain ones to be annotated by humans. ToT Yao et al.(2O24) can also reduce manual efforts,but for each task,it stillrequires experts to provide possible next-step thoughts in the prompt. Our paper introduces a novel boosting approach for manual-free prompting. Starting with a simple prompt,BoT iteratively enhances it based on the analysis ofLLMs on thoughts. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "Prompt Engineering via Fedback.Utilizing responses from LLMs to the input prompt as feedback for further prompt revisions has garnered much attention. Those who continuously revise the given prompt based on evaluation descriptions from LLMs aim to gain an accurate answer Weng et al. $\\hat { ( 2 0 2 3 ) }$ Using a similar higher-level idea of our paper, SELF-REFINEMadaan et al.(2023) proposes an iterative self-refinement algorithm to let the LLM produce fedback for its output for further refinement. $\\mathrm { P H P } [ \\mathrm { Z h e n g ~ e t ~ a l . } ] ( \\mathbb { Z } 0 2 3 )$ simplifies this process by directly adding a solution from the previous answer as a hint to the subsequent prompt. REFINER Paul et al.(2O23) is also related to our paper as it evaluates each reasoning step as feedback to produce a more reasonable one. Another line of research explores ensembles,particularly leveraging the boosting mechanism Freund et al.(1996) to refine the prompt using feedback from a set of examples. They adjust the prompt to focus on the unsolved problems in the previous iteration by either adding a few shot examples uncertain in the previous Pitis et al.(2023) or relying on a fedback-reflect-refine process Zhang et al.(2023a). APO Pryzant et al.(2O23) iteratively refines a prompt, using the performance of the prior prompt to form a natural language for optimization. These works prove the effectiveness of the boosting mechanism in prompt engineering.However,our work is the first to highlight the importance of error analysis in enhancing the prompt toward generating effective reasoning chains. The proposed BoT extends this insight to implement an automated prompting framework by iteratively accumulatingan ensemble of trial-and-error reasoning experiences in the prompt. ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "3BOOSTING OF THOUGHTS ",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "3.1BACKGROUND ",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "The objective of prompt engineering is to design a prompt $\\mathbb { I }$ containing multiple language sequences, such that with this prompt as input, a pre-trained large language model (LLM) denoted as $p _ { \\theta }$ parameterized by $\\theta$ ,can obtain the desired language sequence $y$ Thus,the standard Input-Output (IO) can be formulated as $y \\sim p _ { \\theta } \\left( y | \\mathbb { I } \\left( X , Q \\right) \\right)$ in which $\\mathbb { I } \\left( \\cdot \\right)$ means that the prompt wraps task instructions $X$ and the corresponding question $Q$ ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "The prompt can be designed in a more delicate way to guide the LLM toward solving a problem in a step-by-step manner. Each intermediate reasoning step is denoted as $z _ { i }$ (a.k.a thought). CoTWei et al. $\\pm \\overbrace { ( 2 0 2 2 ) } ^ { \\mathbf { \\alpha } }$ provides few-shot examples with the answer of each example containing a chain of thought $z _ { 1 \\dots n }$ This leads to $y \\sim p _ { \\theta } \\left( y | \\mathbb { I } \\left( \\left[ z _ { 1 . . . n } \\right] ^ { N } , X , Q \\right) \\right)$ where $N$ is the number of examples included in the prompt. ",
        "page_idx": 0
    }
]