[
    {
        "type": "text",
        "text": "References   \n[1] Edward H Adelson and John YA Wang.Single lens stereo withaplenoptic camera. IEEE transactions on pattern analysis and machine intelligence,14(2):99-106,1992.2,7   \n[2]Jun Arai,Fumio Okano,Haruo Hoshino,and Ichiro Yuyama. Gradient-indexlens-array method based onreal-time integral photography for three-dimensional images. Applied optics, 37(11):2034-2045,1998. 2,7   \n[3] Christian Brändli,Raphael Berner,Minhao Yang,Shih-Chii Liu,and Tobi Delbruck. A $2 4 0 \\times 1 8 0$ 130 dB 3μs latency global shuttr spatiotemporal vision sensor. IEEE Journal of Solid-State Circuits,49:2333-2341,2014.1,2   \n[4]Michael Broxton, John Flynn,Ryan Overbeck,Daniel Erickson,PeterHedman,MatthewDuVall,Jason Dourgarian, JayBusch,Matt Whalen,and Paul Debevec.Immersive light field video with a layered mesh representation. In ACM Transactions on Graphics (Proc. SIGGRAPH),2020. 1   \n[5]Eric R.Chan,Marco Monteiro,PetrKellnhofer, Jiajun Wu, and Gordon Wetzstein.Pi-GAN: Periodic implicit generative adversarial networks for 3D-Aware image synthesis. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),2021.2   \n[6]EricR.Chan,Koki Nagano,MatthewA.Chan,AlexanderW. Bergman,JeongJoonPark,AxelLevy,MiikaAittala,Shalini DeMello,Tero Karras,and Gordon Wetzstein.Generative novel view synthesis with 3D-aware diffusion models.In Proceedingsof the IEEE/CVF International Conference on Computer Vision (ICCV),pages 4217-4229,2023.   \n[7]Bin Chen,Lingyan Ruan,and Miu-LingLam.LFGAN: 4D light field synthesis from a single RGB image. ACM Trans. Multimedia Comput. Commun. Appl.,16(1),2020.2   \n[8] Toshiaki Fujii,Kensaku Mori, Kazuya Takeda,Kenji Mase, Masayuki Tanimoto,and Yasuhito Suenaga.Multipoint measuring system for video and sound -10o-camera and microphone system. In IEEE International Conference on Multimedia and Expo,pages 437-440,2006.1,2   \n[9] Guillermo Gallego,Tobi Delbruick,Garrick Orchard,Chiara Bartolozzi,Brian Taba,Andrea Censi,Stefan Leutenegger, AndrewJ.Davison,Jiirg Conradt,Kostas Daniidis,and Davide Scaramuzza. Event-based vision:A survey.IEEE Transactions on Pattern Analysis and Machine Intelligence, 44(1):154-180,2022.1,2   \n[10] Mantang Guo,Junhui Hou,Jing Jin,Jie Chen,and LapPui Chau. Deep spatial-angular regularization for light field imaging,denoising,and super-resolution. IEEE Transactions on Pattern Analysis and Machine Intelligence,44(10): 6094-6110,2022.1,2,3,6   \n11]Katrin Honauer,Ole Johannsen,Daniel Kondermann,and Bastian Goldluecke.A dataset and evaluation methodology for depth estimation on 4D light fields.In Asian Conference on Computer Vision,2016.1   \n12] Fu-Chung Huang,Kevin Chen,and Gordon Wetzstein.The light field stereoscope: immersive computer graphics via factored near-eye light field displays with focus cues.ACM Transactions on Graphics,34(4):60,2015.1   \n13] Michael Iliadis,Leonidas Spinoulas,and Aggelos K.Katsaggelos.Deepbinarymask:Learning a binary mask for video compressive sensing,2016.2,4   \n[14]Yasutaka Inagaki,Yuto Kobayashi,Keita Takahashi,Toshiaki Fujii,and Hajime Nagahara.Learning to capture light fields through a coded aperture camera. In European Conference on Computer Vision, pages 418-434, 2018.1,2,3, 4,5,6   \n[15] Nima Khademi Kalantari, Ting-Chun Wang,and Ravi Ramamoorthi.Learning-based view synthesis for light field cameras. ACM Transactions on Graphics,35(6),2016.1   \n[16] Numair Khan,Min H.Kim,and James Tompkin.Edgeaware bidirectional diffusion for dense depth estimation from light fields.In British Machine Vision Conference (BMVC), 2021.1   \n[17]HKim,SLeutenegger,and AJ Davison. Real-time 3D reconstruction and 6-DoF tracking with an event camera. In European Conference on Computer Vision (ECCV), pages 349-364,2016.2   \n[18] Seungjae Lee, Changwon Jang,Seokil Moon, Jaebum Cho, and Byoungho Lee.Additive light field displays:realizationof augmented reality with holographic optical elements. ACM Transactions on Graphics,35(4):1-13,2016.1   \n[19] Jiaxin Li,Zijian Feng,Qi She,Henghui Ding,Changhu Wang,and Gim Hee Lee.MINE: Towards continuous depth MPI with NeRF for novel view synthesis. In International Conference on Computer Vision,2021.2   \n[20] Qinbo Li and Nima Khademi Kalantari. Synthesizing light field froma single image with variableMPI and two network fusion.ACM Transactions on Graphics,2020.2   \n[21] Yuqi Li,Miao Qi,Rahul Gulve,MianWei,Roman Genov, KiriakosN.Kutulakos,and WolfgangHeidrich.End-to-end video compressive sensing using anderson-accelerated unrolled networks. In International Conference on ComputationalPhotography,pages137-148,2020.2,4   \n[22]Chia-Kai Liang,Tai-Hsu Lin,Bing-YiWong,ChiLiu,and Homer H Chen. Programmable aperture photography: multiplexed light fieldacquisition.ACMTransactionson Graphics,27(3):1-10,2008. 1,2,3,6   \n[23] Zhengyu Liang. BasicLFSR (open source light field toolbox for super-resolution). https ://github.com/ ZhengyuLiang24/BasicLFSR,2021. 5,6   \n[24]Qi Ma,Danda Pani Paudel，Ajad Chhatkuli，and Luc Van Gool.Deformable neural radiance fields using RGB and event cameras. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 3590-3600,2023.2   \n[25] Kazuki Maeno,Hajime Nagahara,Atsushi Shimada,and Rin-Ichiro Taniguchi.Light field distortion feature for transparent object recognition. In IEEE Conference on Computer Vision and Pattern Recognition,pages 2786-2793,2013.1   \n[26] Kshitij Marwah，Gordon Wetzstein，Yosuke Bando，and Ramesh Raskar. Compressive light field photography using overcomplete dictionaries and optimized projections.ACM Transactions on Graphics,32(4):1-12,2013.2,4   \n[27]BenMildenhall,Pratul P.Srinivasan,Rodrigo Ortiz-Cayon, Nima Khademi Kalantari, Ravi Ramamoorthi, Ren Ng,and ",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "",
        "page_idx": 0
    }
]