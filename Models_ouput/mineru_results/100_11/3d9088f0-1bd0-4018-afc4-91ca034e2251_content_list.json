[
    {
        "type": "text",
        "text": "Aman Madaan,Niket Tandon,Prakhar Gupta,Skyler Halinan,Luyu Gao,Sarah Wiegreffe,Uri Alon,Nouha Dziri, Shrimai Prabhumoye,Yiming Yang,et al. Self-refine: Iterative refinement with self-feedback. arXiv preprint arXiv:2303.17651,2023.   \nOpenAI. Gpt-4 technical report. arXiv preprint arXiv:2303.08774,2023.   \nArkil Patel,Satwik Bhattamishra,and Navin Goyal.Are nlp models really able to solve simple math word problems? arXiv preprint arXiv:2103.07191, 2021.   \nDebjitPaul,MeteIsmayilzada,aximePeyrard,eatrizorges,Antoineosselut,obertWest, and Boi Faltings. Refiner: Reasoning feedback on intermediate representations. arXiv preprint arXiv:2304.01904,2023.   \nSilviu Pitis, Michael R Zhang, Andrew Wang,and Jimmy Ba. Boosted prompt ensembles for large language models. arXiv preprint arXiv:2304.05970,2023.   \nReid Pryzant, Dan Iter, JerryLi, Yin Tat Lee, Chenguang Zhu,and Michael Zeng. Automatic prompt optimization with\"gradient descent” and beam search. arXiv preprint arXiv:2305.03495,2023.   \nTaylor Shin, Yasaman Razeghi, RobertL Logan IV, Eric Wallce,and Sameer Singh. Autoprompt: Eliciting knowledge_from languagemodelswith automatically generated prompts.In Proc.Conference on Empirical Methods in Natural Language Processing, pp. 4222-4235,2020.   \nHugo Touvron,Louis Martin,Kevin Stone,Peter Albert,AmjadAlmahairi,YasmineBabaei,Nikolay Bashlykov, Soumya Batra,Prajjwal Bhargava,Shruti Bhosale,etal. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288,2023.   \nXuezhi Wang，Jason Wei,Dale Schuurmans,Quoc Le,Ed Chi,Sharan Narang，Aakanksha Chowdhery,and Denny Zhou. Self-consistency improves chain ofthought reasoning inlanguage models. In Proc.International Conference onLearning Representations,2022.   \nJason Wei, Xuezhi Wang,Dale Schuurmans,Maarten Bosma,Fei Xia, EdChi, Quoc VLe,Denny Zhou,et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems,35:24824-24837,2022.   \nYixuanWeng,MinjunZhu,FeiXia,BinLi,ShizhuHe,ShengpingLiu,BinSun,KangLiu,andJun Zhao.Large language modelsare better reasoners with self-verification. In Proc. Conference on Empirical Methods in Natural Language Processing,pp.2550-2575,2023.   \nShunyu Yao,DianYu,Jeffrey Zhao,Izhak Shafran,TomGriffiths,YuanCao,andKarthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. In Proc. Advances in Neural Information Processing Systems,volume 36,2024.   \nChenrui Zhang,Lin Liu,Jinpeng Wang, Chuyuan Wang, Xiao Sun,Hongyu Wang,and Mingchen Cai. Prefer: Prompt ensemble learning via feedback-reflect-refine. arXiv preprint arXiv:2308.12033, 2023a.   \nYifan Zhang,Jingqin Yang, Yang Yuan,and AndrewChi-Chih Yao. Cumulative reasoning with large language models.arXiv preprint arXiv:2308.04371,2023b.   \nZhuosheng Zhang,Aston Zhang,Mu Li,and Alex Smola. Automatic chain of thought prompting in large language models. In Proc. International Conference on Learning Representations, 2022.   \nXu Zhao,Yuxi Xie,Kenji Kawaguchi, Junxian He,and Qizhe Xie.Automatic model selection with large language models for reasoning. arXiv preprint arXiv:2305.14333,2023.   \nChuanyang Zheng, Zhengying Liu, Enze Xie, Zhenguo Li, and YuLi. Progressive-hint prompting improves reasoning in large language models. arXiv preprint arXiv:2304.09797,2023.   \nAojun Zhou,Ke Wang,Zimu Lu,Weikang Shi, Sichun Luo, ZipengQin,ShaoqingLu,Anya Jia, Linqi Song, Mingjie Zhan, et al. Solving challenging math word problems using gpt-4 code interpreter withcode-based self-verification.arXiv preprint arXiv:2308.07921,2023a.   \nDenny Zhou,Nathanael Scharli,Le Hou,Jason Wei,Nathan Scales,Xuezhi Wang,Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, et al. Least-to-most prompting enables complex reasoning in large language models.In Proc.International Conference on Learning Representations,2023b. ",
        "page_idx": 0
    }
]