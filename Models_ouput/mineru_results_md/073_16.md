of lines 4and 5 between these algorithmsare proved as

$$
\begin{array} { r l } & { \{ \begin{array} { l } { x ^ { \alpha _ { 1 } \alpha _ { 1 } } \gets c ^ { \alpha _ { 1 } \alpha _ { 1 } \lfloor \alpha _ { 1 } \rfloor } + \gamma } \\ { \mathbf { x } ^ { \alpha _ { 1 } \alpha _ { 1 } } \gets \mathbf { N o r n } ( x ^ { \alpha } ) } \\ { \Delta ^ { \alpha _ { 1 } \alpha _ { 1 } } \gets \mathbf { w } ^ { \alpha _ { 1 } \alpha _ { 1 } } \cdot \mathbf { y } ^ { \gamma } } \end{array}  } \\ & { \quad \Leftrightarrow \{ \begin{array} { l } { x ^ { \alpha _ { 1 } \alpha _ { 1 } } \gets c ^ { \alpha _ { 1 } \alpha _ { 1 } \lfloor \alpha _ { 1 } \rfloor } \gets \gamma ^ { \alpha _ { 1 } \alpha _ { 1 } \lfloor \alpha _ { 1 } \rfloor } \gamma + ( 1 - x ^ { \alpha _ { 1 } \alpha _ { 1 } \rfloor \varkappa } ) \gamma + O ( \gamma ^ { 2 } ) } \\ { x ^ { \alpha _ { 2 } \alpha _ { 1 } \alpha _ { 1 } } \gets c ^ { \alpha _ { 2 } \alpha _ { 1 } \alpha _ { 1 } } \gets x ^ { \alpha _ { 2 } \alpha _ { 2 } \lfloor \alpha _ { 1 } \rfloor } \gamma + O ( \gamma ^ { 2 } ) } \\ { \Delta ^ { \alpha _ { 1 } \alpha _ { 1 } } \gets \mathbf { w } ^ { \alpha _ { 1 } \alpha _ { 1 } } \gets \gamma ^ { \alpha _ { 1 } \alpha _ { 1 } \iota } ( \mathbf { x } , \mathbf { y } ) } \end{array}  } \\ & { \quad \Leftrightarrow \{ \begin{array} { l } { x _ { i } ^ { \alpha _ { 1 } } \gets c ^ { \alpha _ { i } } + ( 1 - x ^ { \alpha _ { i } \iota } ) \gamma } \\ { \Delta _ { i } \gets \frac { u ^ { \alpha _ { i } \iota } ( x ^ { \alpha _ { i } \iota } , y ) - u ^ { \alpha _ { i } \iota } ( x , y ) } { \gamma } } \end{array}  } \\ &  \quad \Leftrightarrow \{ \begin{array} { l l }  x _ { i } ^ { \alpha _ { i } } \gets \frac  u ^ { \alpha _ { i } \iota } ( x  \end{array} \end{array}
$$

Here, we ignore terms of $O ( \gamma ^ { 2 } )$ and use the definition of $_ { \textbf { \em x } }$ (i.e., $x _ { i } ^ { \prime } = x ^ { \prime a _ { 1 } | s _ { i } } = 1 - x ^ { \prime a _ { 2 } | s _ { i } \rangle }$ between Eqs.(A31 and (A32).Thus,we use the continualized version of this algorithm;

$$
\dot { \pmb x } = \pmb x \circ ( \mathbf 1 - \pmb x ) \circ \frac { \partial } { \partial \pmb x } \boldsymbol u ^ { \mathrm { s t } } ( \pmb x , \pmb y ) .
$$

# B.2Approximation of learning dynamics

In Section 4.2 and 5.1,we introduce a method to approximate the learning dynamics up to $k$ -th order terms fordeviations from the Nash equilibrium.The stationary state condition ofthe one-memory two-action game is given by

$$
\begin{array} { l } { { { \boldsymbol { p } } ^ { \mathrm { s t } } = M { \boldsymbol { p } } ^ { \mathrm { s t } } , } } \\ { { \boldsymbol { M } } = \left( \begin{array} { l l l l } { { \boldsymbol { x } } _ { 1 } y _ { 1 } } & { { \boldsymbol { x } } _ { 2 } y _ { 2 } } & { { \boldsymbol { x } } _ { 3 } y _ { 3 } } & { { \boldsymbol { x } } _ { 4 } y _ { 4 } } \\ { { \boldsymbol { x } } _ { 1 } { \tilde { y } } _ { 1 } } & { { \boldsymbol { x } } _ { 2 } { \tilde { y } } _ { 2 } } & { { \boldsymbol { x } } _ { 3 } { \tilde { y } } _ { 3 } } & { { \boldsymbol { x } } _ { 4 } { \tilde { y } } _ { 4 } } \\ { { \tilde { \boldsymbol { x } } } _ { 1 } y _ { 1 } } & { { \tilde { \boldsymbol { x } } } _ { 2 } y _ { 2 } } & { { \tilde { \boldsymbol { x } } } _ { 3 } y _ { 3 } } & { { \tilde { \boldsymbol { x } } } _ { 4 } y _ { 4 } } \\ { { \tilde { \boldsymbol { x } } } _ { 1 } { \tilde { y } } _ { 1 } } & { { \tilde { \boldsymbol { x } } } _ { 2 } { \tilde { y } } _ { 2 } } & { { \tilde { \boldsymbol { x } } } _ { 3 } { \tilde { y } } _ { 3 } } & { { \tilde { \boldsymbol { x } } } _ { 4 } { \tilde { y } } _ { 4 } } \end{array} \right) . }  \end{array}
$$

Here, for any variable $\mathcal { X }$ ï¼Œwe define ${ \tilde { \mathcal { X } } } : = 1 - \mathcal { X }$ . Inaddition,letusdenote $O ( \delta ^ { k } )$ term in any variable $\mathcal { X }$ as $\chi ( k )$ .The neighbor of the Nash equilibrium,by substituting ${ \pmb x } = x ^ { * } { \bf 1 } + \delta$ and $\pmb { y } = \ b { y } ^ { * } \pmb { 1 } + \pmb { \epsilon }$ , we can decompose $\begin{array} { r } { \pmb { M } = \sum _ { k = 0 } ^ { 2 } \pmb { M } ^ { ( k ) } } \end{array}$ as

$$
\begin{array} { r l } & { M = \underbrace { ( x ^ { * } \circ y ^ { * } ) \otimes \mathbf { 1 } } _ { = M ^ { ( 0 ) } } + \underbrace { ( y ^ { * } \circ \mathbf { 1 } _ { x } ) \otimes \delta + ( x ^ { * } \circ \mathbf { 1 } _ { y } ) \otimes \epsilon } _ { = M ^ { ( 1 ) } } + \underbrace { \mathbf { 1 } _ { z } \otimes ( \delta \circ \epsilon ) } _ { = M ^ { ( 2 ) } } , } \\ & { ~ \mathrm { ~ } ^ { * } : = ( x ^ { * } , x ^ { * } , \tilde { x } ^ { * } , \tilde { x } ^ { * } ) , ~ y ^ { * } : = ( y ^ { * } , \tilde { y } ^ { * } , y ^ { * } , \tilde { y } ^ { * } ) , } \\ & { ~ x : = ( + 1 , + 1 , - 1 , - 1 ) ^ { \mathrm { T } } , ~ \quad \mathbf { 1 } _ { y } : = ( + 1 , - 1 , + 1 , - 1 ) ^ { \mathrm { T } } , ~ \quad \mathbf { 1 } _ { z } : = \mathbf { 1 } _ { x } \circ \mathbf { 1 } _ { y } = ( + 1 , - 1 , - 1 , + 1 ) ^ { \mathrm { T } } . } \end{array}
$$

In the same way, we can decompose $\begin{array} { r } { \pmb { p } ^ { \mathrm { s t } } \simeq \sum _ { k = 0 } \pmb { p } ^ { \mathrm { s t } ( k ) } } \end{array}$ as

$$
\begin{array} { r l } & { p ^ { \mathrm { s t } ( 0 ) } = M ^ { ( 0 ) } p ^ { \mathrm { s t } ( 0 ) } = \underbrace { ( p ^ { \mathrm { s t } ( 0 ) } \cdot \mathbf { 1 } ) } _ { = 1 } x ^ { * } \circ y ^ { * } = : p ^ { * } , } \\ & { p ^ { \mathrm { s t } ( 1 ) } = M ^ { ( 1 ) } p ^ { \mathrm { s t } ( 0 ) } = ( \delta \cdot p ^ { * } ) y ^ { * } \circ \mathbf { 1 } _ { x } + ( \epsilon \cdot p ^ { * } ) x ^ { * } \circ \mathbf { 1 } _ { y } , } \\ & { p ^ { \mathrm { s t } ( 2 ) } = M ^ { ( 2 ) } p ^ { \mathrm { s t } ( 0 ) } + M ^ { ( 1 ) } p ^ { \mathrm { s t } ( 1 ) } } \\ & { \qquad = ( \delta \circ \epsilon \cdot p ^ { * } ) \mathbf { 1 } _ { z } + \left\{ ( \delta \cdot p ^ { * } ) ( \delta \circ y ^ { * } \cdot \mathbf { 1 } _ { x } ) + ( \epsilon \cdot p ^ { * } ) ( \delta \circ x ^ { * } \cdot \mathbf { 1 } _ { y } ) \right\} y ^ { * } \circ \mathbf { 1 } _ { x } } \\ & { \qquad + \left\{ ( \delta \cdot p ^ { * } ) ( \epsilon \circ y ^ { * } \cdot \mathbf { 1 } _ { x } ) + ( \epsilon \cdot p ^ { * } ) ( \epsilon \circ x ^ { * } \cdot \mathbf { 1 } _ { y } ) \right\} x ^ { * } \circ \mathbf { 1 } _ { y } . } \end{array}
$$