[35]J.Chen,M.Xie,Z.Xing,C.Chen,X.Xu,L.Zhu,andG.Li,“Object detection for graphical user interface:old fashioned or deep learning ora combination?” in proceedings of the 28th ACM joint meeting onEuropean Software Engineering Conference and Symposium on the Foundations of Software Engineering,2020,pp.1202-1214.   
[36] “difflib in python,”https://docs.python.org/3/library/difib.html2022.   
[37]J. Qian, Z. Shang, S. Yan, Y. Wang, and L. Chen,“Roscript: a visual script driven truly non-intrusive robotic testing system for touch screen applications,’in Proceedingsof theACM/IEEE42nd International Conference on Software Engineering,2020,pp.297-308.   
[38]T.-Y.Lin,P.Dollar,R.Girshick,K.He,B.Hariharan,andS.Belongie, "Featurepyramid networks forobject detection,”in Proceedingsof the IEEEconference on computer visionand patternrecognition,2017,pp. 2117-2125.   
[39]B.Deka,Z.Huang,C.Franzen,J.Hibschman,D.Afergan，Y.Li, J.Nichols,andR.Kumar,“Rico:A mobile app dataset for building data-drivendesignapplications,inProceedingsof the3Oth Annual ACM Symposium on User InterfaceSoftwareand Technology,2017,pp.845- 854.   
[40] X.Zhang,L.de Greef,A. Swearngin,S.White,K.Murray,L.Yu, Q.Shan,J.Nichols,J.Wu,C.Fleizach et al.，“Screen recognition: Creating accessbilitymetadata for mobile applications from pixels,” in Proceedings of the 2O21 CHI Conference on Human Factors in Computing Systems,2021,pp.1-15.   
[41]N.Parmar,A.Vaswani,J.Uszkoreit,L.Kaiser,N.Shazeer,A.Ku,and D.Tran,“Image transformer”in International Conference on Machine Learning.PMLR,2018,pp.4055-4064.   
[42] “Wand - python package,https://docs.wand-py.org/en/0.6.2/ 2022.   
[43]Y.Li, Z. Yang,Y. Guo,and X. Chen,“Droidbot: a lightweight ui-guided testinput generatorforandroid,in2017 IEEE/ACM39th International Conference on Software Engineering Companion (ICSE-C). IEEE, 2017, pp.23-26.   
[44]A.Truong,P.Chi,D.Salesin,I.Essa,and M.Agrawala,“Automatic generation of two-level hierarchical tutorials from instructional makeup videos,inProceedings of the2021 CHI Conference on Human Factors in Computing Systems,2021,pp.1-16.   
[45]C.Watman,D.Austin,N.Barnes,G.Overett,and S.Thompson,“Fast sumofabsolutedifferencesvisual landmark detector,”in IEEE International Conference on Roboticsand Automation,20o4.Proceedings. ICRA'04.2004,vol.5.IEEE,2004,pp.4827-4832.   
[46]X.-Y.Wang,J.-F.Wu,and H.-Y.Yang,“Robust imageretrieval based oncolor histogram of local feature regions,’Multimedia Tools and Applications,vol.49,no.2,pp.323-345,2010.   
[47] D.G.Lowe,“Distinctive image features from scale-invariant keypoints,” International journal of computer vision,vol.60,no.2,pp.91-110, 2004.   
[48]H.Bay,T.Tuytelaars,and L.Van Gool,“Surf:Speeded up robust features,”in European conference on computer vision. Springer,2006, pp.404-417.   
[49]C.Zhan,X.Duan，S.Xu,Z.Song，and M.Luo,“Animproved movingobject detection algorithm based on frame difference and edge detection,in Fourth international conferenceonimageand graphics (ICIG2007). IEEE,2007,pp.519-523.   
[50]S.Kaufman,S.Rosset,C.Perlich,and O.Stitelman,“Leakage indata mining:Formulation,detection,and avoidance,ACMTransactionson KnowledgeDiscovery fromData (TKDD),vol.6,no.4,pp.1-21,2012.   
[51]I.Salman,A.T.Misirli,and N.Juristo,“Are students representatives of professionals in software engineering experiments?”in 2015 IEEE/ACM 37th IEEE international conference onsoftware engineering,vol.1. IEEE,2015,pp.666-676.   
[52]M.P.Fay and M.A.Proschan,“Wilcoxon-mann-whitney or t-test?on assumptions for hypothesis tests and multiple interpretations of decision rules,Statistics surveys,vol.4,p.1,2010.   
[53]Y.Zhao,T.Yu,T.Su,Y.Liu,W.Zheng,J.Zhang,andW.G.Halfond, “Recdroid:automatically reproducing android application crashes from bugreports,”in 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). IEEE,2019,pp.128-139.   
[54]M.Fazzini,M.Prammer,M.d'Amorim,andA.Orso,“Automatically translating bug reports into test cases for mobile apps,in Proceedings of the27th ACM SiGSOFT International Symposium on Software Testing and Analysis,2018,pp.141-152.   
[55]S.Talebipour,Y.Zhao,L.Dojcilovic,C.Li,and N.Medvidovic, “Ui test migrationacross mobile platforms,”in 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE,2021,pp.756-767.   
[56]Y.Zhao,J.Chen,A.Sejfia,M.Schmitt Laser,J.Zhang,F.Sarro, M.Harman,andN.Medvidovic,“Fruiter:aframework for evaluating ui test reuse,in Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations ofSoftware Engineering,2020,pp.1190-1201.   
[57]A.Hindle and C.Onuczko,“Preventing duplicate bugreportsby continuously querying bug reports,Empirical Sofware Engineering, vol.24,no.2,pp.902-936,2019.   
[58]M.Xie,S.Feng,Z.Xing,J.Chen,andC.Chen,“Uied:ahybrid toolfor gui element detectionin Proceedings of the28th ACM Joint Meeting onEuropean Software Engineering Conference and Symposium on the Foundations of Software Engineering,2020,pp.1655-1659.   
[59]A.T.Nguyen,T.T.Nguyen,T.N.Nguyen,D.Lo,and C.Sun, "Duplicate bug report detection with a combination of information retrieval and topicmodeling,”in2012Proceedings of the27th IEEE/ACM international conference on automated software engineering. IEEE, 2012, pp.70-79.   
[60]N.Cooper,C.Bernal-Cardenas,O.Chaparro,K.Moran,andD.Poshyvanyk,“It takes two to tango: Combining visual and textual information fordetectingduplicatevideo-basedbugreports,”in2021 IEEE/ACM 43rdInternational ConferenceonSoftware Engineering(ICSE).IEEE, 2021, pp.957-969.   
[61]X.Liu,P.Carrington,X.Chen,and A.Pavel,“What makesvideos accessible to blind and visually impaired people?”in Proceedings of the2021 CHI Conference on Human Factorsin Computing Systems, 2021,pp.1-14.   
[62]Y.Li,G.Li,L.He,J.Zheng,H.Li,and Z.Guan,“Widget captioning:Generating natural language description for mobile user interface elements,”2020,pp.5495-5510.   
[63]T.J.-J.Li,M.Radensky,J.Jia,K.Singarajah,T.M.Mitchell,and B.A.Myers,“Pumice:A multi-modal agent that learns concepts and conditionals from natural languageand demonstrations,”in Proceedings ofthe 32nd annual ACM symposium on user interface software and technology,2019,pp.577-589.   
[64]T.J.-J.Liand O.Riva,“Kite:Building conversational bots from mobile apps,in Proceedings of the l6th Annual International Conference on Mobile Systems,Applications,and Services,2018,pp.96-109.   
[65]C.Chen,S.Feng,Z.Xing,L.Liu，S.Zhao,and J.Wang，“Gallery dc:Design search and knowledge discovery through auto-created gui component gallery Proceedings of the ACM on Human-Computer Interaction,vol.3, no.CCW,pp.1-22,2019.   
[66] S.Feng,C.Chen,and Z. Xing,“Gallery dc: Auto-created gui component gallery for designsearch and knowledge discovery,in Proceedings of theACM/EE4thInterationalConferenceonSoftwareEngieering Companion Proceedings,2022,pp. 80-84.   
[67]C.Chen,S.Feng,Z.Liu,Z. Xing,and S. Zhao,“From lost to found: Discover missing ui design semantics through recovering missing tags,” Proceedings of the ACMon Human-Computer Interaction,vol.4,no. CSCW2,pp.1-22,2020.   
[68] Z.Liu,C.Chen,J.Wang,X.Che,Y.Huang,J.Hu,andQ.Wang,“Fill intheblank:Context-aware automated text input generation for mobile gui testing,arXiv preprint arXiv:2212.04732,2022.   
[69]M.Xie,Z.Xing,S.Feng,C.Chen,L.Zhu,andX.Xu,“Psychologicallyinspired,unsupervised inference of perceptual groups of gui widgets fromgui images,”arXiv preprint arXiv:2206.10352,2022.   
[70]Z.Liu,C.Chen,J.Wang,Y.Huang,J.Hu,and Q.Wang,“Guided bugcrush:Assist manual gui testing of android appsvia hint moves,” in Proceedings of the 2022 CHI Conference on Human Factorsin Computing Systems,2022,pp.1-14.   
[71] ,"Owl eyes: Spotting ui display issues via visual understanding,in 2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE,2020, pp.398-409.   
[72]Y.Su,C.Chen,J.Wang,Z.Liu,D.Wang,S.Li,and Q.Wang,“The metamorphosis: Automatic detection of scaling issues for mobile apps,” in37th IEEE/ACM International Conference on Automated Software Engineering,2022,pp.1-12.   
[73]Z.Liu,C.Chen,J.Wang,Y.Huang,J.Hu,andQ.Wang，“Nighthawk: Fullyautomated localizingui display issuesvia visual understanding,” IEEE TransactionsonoftwareEngineering,vol.49,no.1,p.40418, 2022