# CVF

This CVPR paper is the Open Access version,provided by the Computer Vision Foundation. Except for this watermark,it is identical to the accepted version; the final published version of the proceedings is available on IEEE Xplore.

# Time-Eficient Light-Field Acquisition Using Coded Aperture and Events

Shuji Habuchi† Keita TakahashitChihiro Tsutake†Toshiaki Fujiit Hajime Nagaharat † Nagoya University, Japan‡ Osaka University, Japan

# Abstract

We propose a computational imaging method for timeefficient light-field acquisition that combinesa coded aperturewith an event-based camera. Different from the conventional coded-aperture imaging method, our method applies a sequence of coding patterns during a single exposure for animageframe.Theparallaxinformation,which isrelated to the differences in coding patterns,is recorded asevents. The image frame and events,all ofwhich are measured in a single exposure,are jointly used to computationally reconstructalightfield.Wealsodesigned analgorithmpipeline for our method that is end-to-end trainable on the basisof deep optics and compatible with real camera hardware.We experimentally showed that our method can achieve more accurate reconstruction than several other imaging methodswith a single exposure. We also developed a hardware prototype with the potential to complete the measurement on the camera within 22 msec and demonstrated that light fields from real 3-D scenes can be obtained with convincing visual quality. Our software and supplementary video are available from our projectwebsite1.

plane of acamera.With this method,the light field of a target scene is optically encoded before being recorded on the image sensor. Some images taken froma stationary camera with different coding patterns are used to computationally reconstruct the original light field. As indicated from several studies [10,14, 42], the number of images to acquire can be reduced to only a few (e.g.,2-4).

An issue with coded-aperture imaging is the long measurement time,since two or more images should be acquired in sequence.As a solution for this issue,we propose atime-efficient light-field acquisition method that can complete the measurement in a single exposure.Our method combines a coded aperture[10,14,22,30,38] and an eventbased camera [3, 9],as shown in Fig.1, that can simultaneously capture image frames and events. Our method is based on the premise that the aperture coding can be controlled faster than the frame-rate of the image sensor.2 We apply several coding patterns in sequence during a singleexposure for an image frame.Therefore,we do not directly observe individual coded-aperture images,but we have the sum of them as a single image frame. The camera also measures the events asynchronously during the exposure.Since the target scene is assumed static, the events are caused exclusively by the change in coding patterns. In other words,we actively induce the events by changing the coding patterns over time.These events include the information related to the parallax among different viewpoints, which is essential for light-field/3-D reconstruction. The image frame and events,all ofwhich are measured ina single exposure, are jointly used to computationally reconstruct the light feld.

# 1. Introduction

Alight field isusually represented asa set of multi-view images that captures a target 3-D scene from a dense 2-D grid of viewpoints.Light fields have been used for various applications such as depth estimation [11,16,39], object/material recognition [25,49],view synthesis [4,15, 27],and 3-D display [12,18,50]. In this paper, we consider light-field acquisition from static 3-D scenes.

Due to the large number of images contained in a light field(e.g., $8 \times 8$ views),how to acquire a light field has been a long-standing issue [8,31, 40, 51]. Since views included ina light field are highly redundant with each other,viewby-view sampling seems to be a waste of resources. To achieve more effcient acquisition, researchers investigated coded-aperture imaging [10,14,22,30,38],with which semi-transparent coding patterns are placed at the aperture

We first formalize our imaging method and clarify the quasi-equivalence between our method and the baseline coded-aperture imaging method. We then discuss our design of an end-to-end trainable algorithm tailored for our imaging method while considering the compatibility with real camera hardware. To validate our method,we conducted quantitative evaluations,in which the imaging processwas computationally simulated,and real-world experiments using our prototype camera. Experimental results