encoding the history conversations can help the model reserve more history memory to generate more human-like responses. Moreover, HAHT achieves better performance than HAHTHIsT. This observation indicates that removing the history encoder causes the most decline in all metrics.This result confirms the necessity to leverage history conversations to understand the current conversation and generate the response. In addition, the performance degradation caused by removing the switching mechanism shows that directly copying words from the history conversation can help the model generate more history-aware responses.

# 5.5Case Study

Table 6 shows a case study of the multi-session conversations generated by different models. Compared to baseline models, the proposed HAHT model can better leverage history conversations to understand the current conversation context and generatemore history-aware responses.When the user discusses preparing sandwiches and lemonade with the agent, "I can make sandwiches for us! I also have a very good recipe for homemade lemonade!Do you like lemonade?",HAHT can remember information mentioned in the history conversations,such as the user likes reading and outdoor activities and it has adopted a book-lover persona before.HAHT can leverage these historical contexts and generate more human-like,context-relevant, and history-aware responses: “I love lemonade! I'm sure we can find a lot of good recipes for sandwiches too. Sandwiches and lemonade are perfect for going outdoors and reading books.".

# 6Conclusion

In this work,we propose the History-Aware Hierarchical Transformer(HAHT) model for multisession open-domain dialogue systems. The proposed HAHT model maintains a history memory by hierarchically encoding the history conversation sessions.After that, HAHTusesattention-based encoding to encode the current conversation context together with the history memory and updates the history memory with the current context. In order to explicitlyleverage historical information in the responses,HAHT is designed with a history-aware response generator which can switch between a generic vocabulary and a history-aware vocabulary. Experimental results obtained under both normal and session opening MSC settings demonstrate that

Table 6:A case study of an MSC with two history conversations. Only important utterances in the history and current conversations are presented. Complete conversations sessions are provided in AppendixA.1   

<table><tr><td colspan="2">History Conversation Sessions</td></tr><tr><td colspan="2">[Session 1]</td></tr><tr><td>… User: Agent:</td><td>...My dad is a truck driver. ... I am a big reader myself.</td></tr><tr><td>User: …</td><td>...I like working outdoors.</td></tr><tr><td>[Session 2] User:</td><td>What book are you currently</td></tr><tr><td>Agent:</td><td>reading? I&#x27;m reading a Stephen King</td></tr><tr><td>：</td><td>novel....</td></tr><tr><td>User:</td><td>I used to sit in the truck on long trips with my dad, and had</td></tr><tr><td>Agent:</td><td>nothing to do other than read. Ah,that makes sense.Istarted</td></tr><tr><td>at work.... Current Conversations</td><td>reading when my parents were</td></tr><tr><td colspan="2">…</td></tr><tr><td>Agent:</td><td>... What kinds of picnic foods do you like?</td></tr><tr><td>User:</td><td>Ican make sandwiches for us! I also have a very good recipe for</td></tr><tr><td></td><td>homemade lemonade!Do you like lemonade? Responses from Different Dialogue Systems</td></tr><tr><td colspan="2">BlenderBot: I love lemonades ! I&#x27;m not sure if I could make a picnic for you</td></tr><tr><td></td><td>though. I&#x27;d have to make a lot more than just a picnic. BlenderBotmsc: I love lemonade！I&#x27;m not a</td></tr><tr><td>FID-RAG:</td><td>huge fan of lemonade,but Ilove lemonade. I love lemonade! I&#x27;m sure we</td></tr><tr><td>HAHT</td><td>can find a good picnic for you. I love lemonade! I&#x27;m sure we can find alot of good recipes for</td></tr><tr><td>(ours):</td><td>sandwiches too. Sandwiches and lemonade are perfect for going outdoors and reading</td></tr></table>