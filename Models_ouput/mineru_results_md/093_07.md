![](images/dc60d1bd94b21f39b450a8d033bb97c522bbea8d1e9302dc4a5b4ec0c357523a.jpg)  
Fig.4.Smart sticky trap (upper) and the steps followed for the detection and classification approach (lower).

develop datasets has been described in [43] and [44]. Recent studies have proposed edge-based systems,such as [11] for precision agriculture,most of which suggested power-hungry hardware, such as Raspberry Pi for computation. This research utilized a microcontroller (MCU)-based system to minimize power consumption,whichis a crucial factor for edge-based systems,particularlyinagricultural settings where devices must operate on batteries due to the absence of powerlines in orchards. The image processing solution is here compared to other commonly used approaches,this time using real image data captured in the field throughout the deployment of the IoT device in orchards for several months in 2023.In addition,the impact of considering past data on the system’s accuracy is examined.

# A. Trap Architecture

We designed and developed an edge-based smart trap to make the identification and insect counting procedure automated and more accurate.The system is an ultra low-cost and low-power device able to detect and count insects on the device itself in the orchard without relying on expensive and power-hungry equipment.Fig. 4 depicts the second version of the proposed device.As described in [44] in detail, the camera unit is an OpenMVboard based onanMCUwithan embedded camera capable ofrunning lightweight image processing and deep learningmethods.In addition,this device supports two-sided traps and a servo motoris used to rotate the trap,so the camera can capture images of the trap on both sides.The purpose of the mechanism is to increase the probability of capturing insects (as the captured areais doubled) and,at the same time,make it more approachable to insects since the sticky area is not shadowed by the camera. The image processing pipeline is shown in Fig. 4. This is a modified version of the image processing pipeline proposed in [44].

Theanalysisof real-world data capturedin2O23 revealed that the detection phase was unable to properly detect insects.Consequently, we modified and enhanced this aspect by implementing a histogram equalization technique on the captured images to normalize the contrast and brightness.This adjustment,denoted as the first step in Fig.4,resulted in a significant improvement in the output of the detection phase,reducing both the mean squared error (mse) from 50.8 to 13.6 and mean absolute error (MAE) from 5.1 to 2.1,indicating a reduction bya factor of approximately3.7inmseandapproximately2.5 inMAE.This highlights how important it is to incorporate a wide range of real-world images into the algorithm development and help the algorithm adapt to the complexities of real-world situations.

TABLEIV COMPARISON OFDIFFERENTMODELSONTHENEWDATASETCOLLECTED FROM THE REALWORLD FOR BMSBSCOUNTING   

<table><tr><td>Model</td><td>MAE</td><td>MSE</td><td>P</td><td>R</td><td>MCU Comp.</td></tr><tr><td>YOLOv8-N</td><td>0.71</td><td>1.33</td><td>86.6%</td><td>98.5%</td><td>No</td></tr><tr><td>YOLOv5-N</td><td>0.88</td><td>0.55</td><td>85.1%</td><td>97.6%</td><td>No</td></tr><tr><td>YOLOv3-N</td><td>0.5</td><td>0.40</td><td>88.9%</td><td>98.8%</td><td>No</td></tr><tr><td>Ours in[44]</td><td>5.07</td><td>50.79</td><td>88.5%</td><td>36.7%</td><td>Yes</td></tr><tr><td>This study</td><td>2.07</td><td>13.55</td><td>84.0%</td><td>70.6%</td><td>Yes</td></tr><tr><td>This study (7-day)</td><td>1.05</td><td>1.81</td><td>83.0%</td><td>80.2%</td><td>Yes</td></tr></table>

As shown in Fig.4,in the detection phase,the process beginswith the application of histogram equalization to the raw captured image $\textcircled{1}$ ,followed by conversion to gray scale $\textcircled{2}$ Then,a smoothing filter is applied to eliminate small objects, such aswindblown dust,leaves,or tiny insects $\textcircled{3}$ .Then, theimage is converted to black-and-white using Otsu's method $\textcircled{4}$ and finally the suspected area that might be filled by the target insect is detected usinga blob detection algorithm $\textcircled{5} )$ It should be noted that the detected blobsare fltered based on their size and only those with a size approximating that of a BMSB are considered as suspected areas.So,these suspected areas are cropped and fed to the classification phase ( $\textcircled{6}$ ,where a lightweight CNN-based image classification model is used to classify the images $\textcircled{7}$ .Finally,the number of the target insects on the trap alongwith the cropped images (as an option) is sent to the growers $\textcircled{8}$ ）

Our CNN-based model has a program size of only $8 0 \ \mathrm { k B }$ with a peak memory usage of $7 5 \ \mathrm { k B }$ and an inference time of 0.07 s(on the OpenMV board),making it suitable forrunning on memory-constrained MCUs.In designing the model,as detailed in [44], the main considerations are itemized as follows.

1） Utilizing depthwise separable convolution instead of standard convolution: This reduces computations by factorizing the process,significantly decreasing computational cost.   
2) Using global average pooling instead of flatten layer: This decreases parameter numbers,leading to a substantial reduction in computation and model size.   
3）Quantizing:The model weights were quantized to 8-bit integers fromthe original 32-bit float data,which is critical for deploying the model on memory-constrained MCUs.   
4） Utilizing skip connections: Skip connections enhance performance by facilitating data flow,combining features from different layers,and addressing vanishing gradient issues during training.

# B.Experimental Results

Table IV reports the accuracy of the proposed BMSB identifcation and quantification based on images from the new dataset gathered from the real world as compared to that proposed in [44] using known YOLO methods that are widely used in