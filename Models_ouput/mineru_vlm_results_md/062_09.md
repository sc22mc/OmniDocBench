![](images/afe3882ba954796a9cddab389419c64fb31293e300972f1b859bd5a53529d863.jpg)  
Fig. 12. Pothole recognition and visualization (in the view of ego2).

the focal distance  $f = (f_{x},f_{y})$  represents the distance from the driver to the image plane. With the dimensions of the image plane (windshield), and specifically the aspect ratio, known, the frustum is fully defined and the projection can be made from a point in 3D windshield coordinates  $(x,y,z)$  to pixels  $(u,v)$  on the image plane using the following equation:

$$
{\binom{u}{v}}={\binom{1}{0}}\quad 0\quad x_0\\0\quad 1\quad y\\0\quad 0\quad 0\end{array}{\binom{f_x}{0}}\quad f_y\quad 0\quad{\binom{x}{y}}\\0\quad 0\quad 0\quad 0\quad z
$$

An undesirable property is the sparsity of the projected pixels attributed to the sparsity of the point cloud. To overcome this limitation, we use an iterative nearest neighbour algorithm on the image space to fill the gaps between projected points. The result of this process is shown in Figs. 7,12

More specifically, Fig. 7 and Fig. 10 illustrate the segmented point cloud projected to the AR interface of ego1 and ego2 correspondingly. Note that all information is rendered for the sake of completeness. In real- world cases only the necessary information (e.g., arrows or recognised potholes) will be rendered so as to avoid clutter. Fig. 8 shows the perspective projection of the points to the AR interface and image filling for ego1. In Fig. 9 and Fig. 12 the pothole recognition and visualization is depicted for the vehicles ego1 and ego2, while a warning about an upcoming pothole (retrieved from the database) before reaching the field of view of ego2 is presented in Fig. 11

We would like to clarify here that for evaluation of our methodology and demonstration purposes in the previous figures we project and illustrate in the 2D display device all the information from scene segmentation. However, in real driving scenarios only the most relevant information of the scene (e.g., dangerous objects, potholes) would be highlighted and displayed so as to decrease the amount of any unnecessary information that may bother or confuse the driver.

# B. Information Storage and Vehicle Communication Rules

One of the advantages of autonomous vehicles is their ability to communicate with each other forming a cyberphysical system of systems. Many new opportunities arise from the ability of systems to share information, one of which is the transmission of objects or landmarks of interest that were previously observed by an agent, to other agents of the system who could benefit from such information. In particular, our work focuses on information sharing among vehicles about encountered obstacles, such as potholes and bumps, through a centralized server. When a vehicle identifies an unexpected (i.e., unregistered) obstacle, the vehicle sends a request to the server and after further inspection, the new potential obstacle is either discarded or added to the database. Vehicles may also send information regarding already known obstacles when they come across them. Such information includes the Global Positioning System (GPS) location, dimensions and geometrical characteristics in case the obstacle needs updating in the database, e.g. it has increased in size or has been fixed. Through this communication system, a driver can be warned about potential hazards that may not yet be in his field of view or they are obstructed by other objects and thus, increase his performance and decision- making abilities. We should clarify that our work does not focus on communication protocols and defence mechanisms against potential network attacks, but rather defines a solid framework describing the roles of each node and the information flow.

By using the LiDAR- based obstacle detection method, described in section III, the vehicle transmits via a communication component to a central server the points belonging to the obstacle, segmented from the point cloud scene. The information is coupled with a timestamp and the GPS location of the vehicle at that instance. The server then transmits to any vehicle in the vicinity of the obstacle, alerting (autonomous vehicles or human operators) about potential hazards from a large distance and thus helping alleviate the inability of the LiDAR sensor to identify obstacles from such a range. In the case of a driver, we also use the AR interface of the vehicle to display, in a non- distracting manner, the location and nature of the potentially upcoming obstacle.

Potholes can change shape over time, most commonly due to deterioration of the surrounding pavement and erosion caused by environmental effects or in the opposite case due to pothole repair. Thus, periodic updates are necessary for the long- term reliability of the pothole visualization component. As there is a need for periodical evaluation of the objects in the server database and update in the case of changes, we assign a shape- and geometry- based descriptor at each obstacle, so that it is characterized by a unique representative signature. Thus, every vehicle encountering the obstacle in a nearby range, calculates the descriptor of the obstacle's area. The new descriptor is then transmitted to the server and is used to confirm whether the information is up- to- date. In the case of a difference in the descriptor's value, an algorithm running in the server decides between keeping the old descriptor, updating it with the new one, or marking the obstacle as removed and deleting the entry from the database.

More specifically, we implement a simple system that (when a new pothole is detected) initiates a database search to retrieve whether the pothole is new or already existed and needs to be updated. Since potholes are static and thus change only in shape, the similarity check is based only on the bounding box of the re- identified pothole. When the overlap of the bounding boxes is less than a threshold, the previous object is replaced by the new one. In our experiments we used a