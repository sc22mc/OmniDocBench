IEEE TRANSACTIONS ON AGRIFOOD ELECTRONICS, VOL. 1, NO. 2, DECEMBER 2023

TABLE IV

COMPARISON OF DIFFERENT TYPES OF MODELS [42]

\begin{tabular}{|ll|l|l|l|l|} \hline \textsl{Model name} & \textsl{Input parameters} & \textsl{Performance=} & \textsl{Model com-} & \textsl{scalability with} & \textsl{Recommended applica-} & \textsl{References:} \\ & & \textsl{of } & \textsl{plicity} & \textsl{respect to time} & \textsl{tions} & \\ & & \textsl{models} & & \textsl{and geography} & \textsl{cal location} & \\ & & & & & & \\ \hline \textsl{Linear} & \textsl{-One variable such as} \textsl{vegetation} & \textsl{Low-light} & \textsl{Low} & \textsl{-To choose the range of} & \textsl{predictor variables and to} & \textsl{identify the model which} \\ \textsl{Regression} & \textsl{index or reference values:} & \textsl{(ceilpoints)} & \textsl{(ceilpoints)} & \textsl{upon} & \textsl{to identify the optimal} & \textsl{range of} \\ & \textsl{Model:} & \textsl{-One response variable such as} & \textsl{( explanatory)} & \textsl{upon} & \textsl{to identify the optimal} & \textsl{regression slope} \\ & & \textsl{chlorophyton measurement:} & \textsl{(input)} & \textsl{variable} & \textsl{to collect the data} & \textsl{on the} \\ & & & & & \textsl{To write and store the} & \textsl{processing results} \\ & & & & & \textsl{to generate output} & \\ \hline \textsl{Advanced Linear} & \textsl{Multiple input} & \textsl{Medium} & \textsl{Medium} & \textsl{Low} & \textsl{To include spectral and} & \textsl{[182--291]} \\ \textsl{Regression} & \textsl{-Multiple: response variable-output} & \textsl{high} & \textsl{high} & \textsl{temporal information} & \textsl{-To provide} & \textsl{[395--441]} \\ \textsl{Model:} & \textsl{variable} & & & \textsl{-To provide} & \textsl{performance} & \textsl{an} \\ & & & & & & \textsl{accuracy of} \\ & & & & & & \textsl{performed on} \\ \hline \textsl{Machine Learning} & \textsl{Multiple input/prediction: variable} & \textsl{Medium-} & \textsl{Medium} & \textsl{Low} & \textsl{To include spectral and} & \textsl{[174, 396, 538]} \\ \textsl{ing based Model} & \textsl{-Multiple: responses: variable} & \textsl{mediums} & \textsl{high} & \textsl{temporal information} & \textsl{-To provide} & \textsl{[395--441]} \\ & \textsl{number of trees/less function:} \textsl{(dec-} & & & \textsl{-To provide} & \textsl{performance} & \textsl{an} \\ & \textsl{performs upon the} \textsl{selected model:} & & & & & \textsl{performance} \\ & & & & & & \\ \hline \textsl{Deep Learning} & \textsl{Multiple input variables} & \textsl{Medium-} & \textsl{High} & \textsl{High} & \textsl{To employ a} & \textsl{[299--301]} \\ \textsl{nated Model} & \textsl{based on the input of the} \textsl{size of} & \textsl{the model is} & \textsl{decomposition} & \textsl{data/samples to prevent} & \textsl{overfitting/underfitting} & \\ & & \textsl{such as follows:} & \textsl{the} & \textsl{underfitting/overfitting} & \textsl{to} & \textsl{[364--365]} \\ & & & & \textsl{underfitting/overfitting} & \textsl{[364--365]} & \\ & & & & \textsl{overfitting/underfitting} & \textsl{to obtain} & \textsl{[348, 349]} \\ & & & & \textsl{underfitting/overfitting} & \textsl{[348, 349]} & \\ & & & & \textsl{overfitting} & \textsl{to obtain} & \textsl{[324--325]} \\ & & & & \textsl{underfitting/overfitting} & \textsl{[324--325]} & \\ & & & & \textsl{overfitting} & \textsl{to generate output} & \\ & & & & \textsl{underfitting} & \textsl{[306--307]} & \\ & & & & \textsl{underfitting} & \textsl{to write and store the} & \\ & & & & \textsl{underfitting} & \textsl{[35--36]} & \\ & & & & \textsl{underfitting} & \textsl{underfitting/overfitting} & \\ & & & & \textsl{underfitting} & \textsl{underfitting} & \\ \hline \end{tabular}

spectral features [263], [264]. RF is an ensemble-based learning method that combines multiple decision trees to produce robust and accurate classification or regression results. RF can be employed for plant disease detection to classify hyperspectral data into healthy or diseased classes [265], [266]. kNN is a nonparametric-based algorithm for classification and regression tasks. For plant disease detection, it compares the plant sample with its neighboring features to identify whether the sample is infected or not [266], [267]. SAM is an algorithm that classifies hyperspectral imagery based on the angle between the spectra. Based on the spectral angle difference, pixels are classified into categories such as healthy or diseased plants [268]. Maximum likelihood classification is a probabilistic classifier that assigns a pixel to the class that has the maximum likelihood. It can be used for plant disease detection to classify hyperspectral data into categories like healthy or diseased [269]. On the other hand, PLSR is a statistical technique that can model the relationship between hyperspectral data and plant disease severity [270]. Dirichlet aggregation regression uses Dirichlet distributions for modeling compositional data, and it can also be used to model the relationship between hyperspectral data and plant disease severity [271]. Logistic regression is used for cases with binary classification, such as disease or no disease detection [272], whereas multiple linear regression can provide multiple classes classification [273].

The machine-learning-based classification models can be broadly categorized into supervised and unsupervised learn- ing techniques. Supervised learning techniques require labeled training images/samples to detect the pixel of the region of interest (ROI). A label is associated with each ROI to map the class categories. The labeling of the images is visually conducted and sent to the classification model for training. This aids in improving the detection accuracy of the models but at the expense of high labor costs. On the other hand, unsupervised learning techniques require no prior knowledge and learning through clustering and distribution rules of the spectral features in the images. An example of unsupervised learning would be the K-means clustering algorithm. Rice sheath blight diseases were detected using the K-means clustering algorithm in [274]. A study by Yuan et al. [275] proposed an unsupervised learning technique to identify anthracnose diseases in tea leaves. The study could achieve around 96% of accuracies for disease de- tection [274].

Besides machine learning models, deep learning, a subset of machine learning algorithms, is now applied for hyperspectral image analysis. Over the past decades, deep learning algorithms have improved image classification performance, object detec- tion, and so on. Recently, remote sensing image processing algorithms have also been developed to process complex images such as multispectral and hyperspectral images. Some popular algorithms are CNN [276], deep belief networks [277], stacked autoencoder [278], and so on. Table IV compares different models used in image processing techniques for hyperspectral imaging.

B. Applications of Hyperspectral Imaging in Plant Disease Detection

Once the image acquisition is completed and the images are processed through objective-based selected models, the next step is to analyze the models. The term objective-based se- lected models refer to the analytical models chosen based on the specific goals or objectives such as disease detection and identification, classification, severity, and genetic resistance for the diseases [166], [292], [293]. The analyses are carried out in different levels and arrangements. For instance, to observe

Authorized licensed use limited to: FUDAN UNIVERSITY. Downloaded on August 28,2025 at 01:49:24 UTC from IEEE Xplore. Restrictions apply.