Figure 3. Overview of the OmniDocBench dataset construction.

3. OmniDocBench Dataset

Constructing a diverse and comprehensive document pars- ing benchmark with precise annotations is a significant challenge. As illustrated in Figure 3, we have designed a systematic and professional annotation framework for OmniDocBench, encompassing data acquisition, intelligent pre-annotation, and manual refinement. This ensures that OmniDocBench possesses the following key attributes:

• Page Diversity. We sourced document pages from a va- riety of origins to ensure a wide range of document types.

• Comprehensive Annotation. We meticulously anno- tated all elements on the pages, including bounding boxes, specific contents, and various potential attributes.

• Annotation Accuracy. By integrating semi-automated annotation processes, annotator corrections, and expert quality checks, we ensure the reliability of all annotations.

The following sections detail the data acquisition pro- cess, the annotation methodology, and a statistical analysis of the final annotated dataset.

3.1. Data Acquisition

During the data acquisition phase, we sourced document pages from diverse origins and used clustering algorithms to initially select visually diverse pages, followed by manual annotation of page attributes to finalize the OmniDocBench pages. Specifically, we collected over 200,000 initial PDF documents from Common Crawl, Google, Baidu search en- gines, and internal data. Subsequently, we extracted visual features from these document pages using ResNet-50 and performed clustering using Faiss sampling 6,000 visu- ally diverse pages from 10 cluster centers. Finally, anno- tators provided page-level attribute annotations, including page type, layout type, and language type, and further bal- anced the selection to 981 samples for the final dataset. The OmniDocBench dataset includes pages from nine distinct types, multiple layout categories, and various attribute an- notations, covering a wide range of real-world scenarios.

3.2. Data Annotation

To ensure the comprehensiveness of OmniDocBench’s an- notations, we conducted detailed annotations for layout de- tection and content recognition.

3.2.1. Annotation Types

Layout Detection Annotations: Unlike typical layout de- tection tasks, OmniDocBench includes four comprehensive types of annotations: (1) Layout Bounding Box Annota- tions: Positioanl information for 19 distinct region cate- gories such as titles, text paragraphs, tables, and images. (2) Layout Attribute Annotations: Detailed attribute anno- tations for detected boxes, including 3 text box attribute cat- egories, 6 table attribute categories, 9 bbox-level attribute labels in total. (3) Reading Order Annotations: Annotating the reading sequence of detected boxes. (4) Affiliation An- notations: For images, tables, formulas, and code blocks, we annotate captions and titles to distinguish them from main text. Similarly, for cross-page paragraphs, we anno- tate affiliation relationships.

Content Recognition Annotations: Based on the content type within each region, we conduct the following three types of annotations: (1) Text Annotations: Pure text anno- tations for titles, text paragraphs, and other plain text con- tent. (2) Formula Annotations: LaTeX format annotations for inline formulas, display formulas, and subscripts. (3) Table Annotations: Providing both HTML and LaTeX an- notations for table data.

3.2.2. Annotation Process

For these annotation tasks on diverse pages, we design a standardized process to ensure quality and efficiency, com- prising intelligent automatic annotation, annotator correc- tion, and expert quality inspection.

Automatic Annotation. Manually annotating entire doc- uments is time-consuming and costly. To enhance ef- ficiency, we employ state-of-the-art detection and recog- nition models for pre-annotation of layout detection and content recognition. Specifically, we use fine-tuned Lay- outLMv3 [17] for layout detection annotations and Pad- dleOCR [23], UniMERNet [40], and GPT-4o [2] for text, formula, and table annotations, respectively.

Annotator Correction. After the layout detection phase, annotators refine the detection boxes and enhance annota- tions with reading order and affiliation details. Each char- acter is verified to ensure accuracy in content recognition. For complex annotations of tables and formulas, requiring LaTeX and HTML formats, annotators use tools like Tables Generator and latexlive for verification and correction. Expert Quality Inspection. Despite thorough annotator corrections, the complexity of formulas and tables may re- sult in residual issues. To address these, we use CDM’s ren- dering techniques [41] to identify unrenderable elements. These elements are then reviewed and corrected by three researchers to ensure accuracy in the final annotations.

https://github.com/facebookresearch/faiss https://www.tablesgenerator.com/ https://www.latexlive.com/

24841