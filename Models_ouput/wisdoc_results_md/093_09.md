IEEE TRANSACTIONS ON AGRIFOOD ELECTRONICS, VOL. 3, NO. 1, MARCH/APRIL 2025

Fig. 6. Screenshots of the Android app interfaces. In (a) the user can take pictures (or upload other ones) and perform the detection, while in (b) the UAV operator can visualize the status of the autonomous mission.

the message body. The model string in the URL can refer to any of the models discussed in Section III, such as x-model or m-model. When a client invokes the exposed service, the server executes the image recognition procedure using the specified model, implemented with PyTorch [48]. If BMSBs are detected, the server returns a set of bounding box coordinates plus the confidence values to the requesting client.

Considering the GUI interaction, a web page is hosted in the Flask service at the root of the previous URL. The web page consists of a minimal interface that comprises a list box, a file picker, and a button. The list box allows the user to select the preferred model for the detection, whereas the file picker consents to upload the images to be processed. Once the user has made their selection, they can submit their choice using the button, which will then display the detection results, i.e., images with the BMSB outlined by a bounding box. While this GUI service is based on the same framework as the API, it serves as a user-friendly shortcut for nontech users to access the service and promotes wider project dissemination.

C. Client Side

The client component is responsible for capturing pictures and sending requests to the server. As the server component is decoupled in this architecture, various devices with differ- ent technologies can make requests to the server, as long as they support HTTP POST requests. For us, clients can include smartphones, tablets, laptops, computers, as well as drones.

For smartphones and tablets, we developed an Android-based Java app [see Fig. 6(a)], whereas for laptops and computers, we created an HTTP-based web app. In both versions, users can capture or select pictures and choose amodel for querying, either via HTTP POST requests or through the web page interface. The app’s aim is to enable people, particularly farmers, to actively scout and monitor the presence of BMSB. Users can manually take pictures of trees with one or more BMSBs, upload pre- viously captured images, select an appropriate ML model, and await the detection results. The server then sends the potential

Fig. 7. Autonomous UAV operations in an orchard: (a) Waypoints for image capturing performed with a photo mosaic as a 4× 5 matrix in (b).

BMSB detections back to the client, represented by bounding box coordinates and their corresponding confidence levels. In the current version of the app, the pictures sent by clients, along with the detections, are stored on the server. This step is crucial for augmenting the dataset and improving the ML models. We are considering adding an additional supervisory step to verify the accuracy of the detections, facilitating effective retraining of the models. Thereby, the more expert the models become, the more accurate they will be, saving a lot of time for annotations.

The client app running on our drone (a DJI Matrice 300) has been developed in Java using the DJI mobile software development kit (SDK)V4 [see Fig. 6(b)]. This SDK enables the creation of custom Android- or iOS-based apps for installation on mobile devices directly connected to the drone’s remote controller. With this app, the drone can autonomously perform flights at designated waypoints, adjust the gimbal, and capture images with specific camera parameters, such as focal length. Communication between the app and the remote controller occurs via a USB cable, which communicates with the DJI Matrice 300 drone and its DJI Zenmuse H20 camera. Although primarily designed for autonomous flights and image capture, the app also allows users to manually select and send stored pictures to the server. So, the Android app prompts the user to specify waypoints [see Fig. 7(a)] within the orchard where the drone will capture images. At each waypoint, the drone halts and captures approximately 20 adjacent images from different angles, forming a grid pattern of four rows by five columns [see Fig. 7(b)]. The images are sent to the server to augment the dataset and to conduct analysis through predictions.

VII. BMSB PUNCTURES DETECTION

Due to the high damage potential of BMSB [49], it is crucial to adopt monitoring strategies both upstream, through field moni- toring to prevent BMSB activity and to address crop infestations in a timelymanner, and downstream along the food supply chain to manage the quality of the harvesting. To this aim, in the HALY.ID project, SWIR-HSI was also evaluated as a postharvest sorting system for the identification of BMSB late damages on pears, which consist in internal necrosis of the fruit pulp not visible to the naked eye.

A. Experimental Setup and Data Collection

Pear fruits of cv. Williams and cv. Abate Fétel were collected in an organic orchard in Carpi during summer 2022 and 2023.