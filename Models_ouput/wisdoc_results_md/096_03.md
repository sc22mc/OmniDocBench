Figure 2. Definition of world coordinates in a Manhattan world. The origins of the world coordinates of the Manhattan world and a camera are OM -XMYMZM and OC -XCYCZC , respectively. All walls of the cuboid buildings are parallel to the corresponding planes in OM -XMYMZM .

In this paper, we focus on calibration methods that both recover rotation and remove distortion from a single im- age, as specified in Table 1. A pioneering learning-based method was proposed by López-Antequera et al. [33] to ad- dress rotation and distortion based on Brown’s quartic poly- nomial models [5]. Wakai and Yamashita [52] proposed a learning-based method for fisheye cameras using equi- solid angle projection. Wakai et al. [53] also proposed a learning-based method using generic camera models. How- ever, these methods cannot estimate pan angles because they use a non-Manhattan world.

For a Manhattan world, Wildenauer et al. [57] proposed a pioneering geometry-based calibration method from a sin- gle image using a constraint based on parallel scene lines. This method addressed distortion using a one-parameter di- vision model [14]. A geometry-based calibration method has been proposed to improve calibration accuracy using the lines of circle centers [3]. Pritts et al. [41] proposed joint solvers for the affine rectification of an imaged scene plane and radial lens distortion from coplanar points. Con- sidering distortion and focal length, Lochman et al. [32] proposed solvers based on combinations of imaged transla- tional symmetries and parallel scene lines. Although these geometry-based methods can estimate camera angles in a Manhattan world, images with few arcs degrade the perfor- mance because of a lack of constraints.

Heatmap regression. Interest has grown in the use of heatmap regression for various tasks, such as human pose estimation [56], object detection [21], and face align- ment [54]. In camera calibration, heatmap regression was used for distortion estimation [28, 29]. Although heatmap regression has the potential for accurate and robust estima- tion, the heatmap regression is not used for VP estimation because VPs are often located beyond the image borders.

Table 2. Labels of VPs and ADPs

\begin{tabular}{ccc} \hline \noalign{\vskip 0.1cm} Label name & Direction & Image coordinate$^1$ \\ \hline \noalign{\vskip 0.1cm} Vanishing point \\ front & $\vec{Z}_M$ & $(W/2,H/2)$ \\ back & $-\vec{Z}_M$ & $(0,H/2)$ \\ left & $-\vec{X}_M$ & $(W/4,H/2)$ \\ right & $\vec{X}_M$ & $(3W/4,H/2)$ \\ top & $-\vec{Y}_M$ & $(0,0)$ \\ bottom & $\vec{Y}_M$ & $(0,H)$ \\ \hline \end{tabular}

\begin{tabular}{ccc} \hline \noalign{\vskip 1mm} Label name & Direction & Image coordinate$^{1}$ \\ \hline \noalign{\vskip 1mm} Vanishing point & & \\ \noalign{\vskip 1mm} front & $\vec{Z}_M$ & $(W/2,H/2)$ \\ back & $-\vec{Z}_M$ & $(0,H/2)$ \\ left & $-\vec{X}_M$ & $(W/4,H/2)$ \\ right & $\vec{X}_M$ & $(3W/4,H/2)$ \\ top & $-\vec{Y}_M$ & $(0,0)$ \\ bottom & $\vec{Y}_M$ & $(0,H)$ \\ \hline \noalign{\vskip 1mm} Auxiliary diagonal point & & \\ \noalign{\vskip 1mm} front-left-top (FLT) & $(\vec{Z}_M-\vec{X}_M-\vec{Y}_M)/\sqrt{3}$ & $(3W/8,H/4)$ \\ front-right-top (FRT) & $(\vec{Z}_M+\vec{X}_M-\vec{Y}_M)/\sqrt{3}$ & $(5W/8,H/4)$ \\ front-left-bottom (FLB) & $(\vec{Z}_M-\vec{X}_M+\vec{Y}_M)/\sqrt{3}$ & $(3W/8,3H/4)$ \\ front-right-bottom (FRB) & $(\vec{Z}_M+\vec{X}_M+\vec{Y}_M)/\sqrt{3}$ & $(5W/8,3H/4)$ \\ back-left-top (BLT) & $(-\vec{Z}_M-\vec{X}_M-\vec{Y}_M)/\sqrt{3}$ & $(W/8,H/4)$ \\ back-right-top (BRT) & $(-\vec{Z}_M+\vec{X}_M-\vec{Y}_M)/\sqrt{3}$ & $(7W/8,H/4)$ \\ back-left-bottom (BLB) & $(-\vec{Z}_M-\vec{X}_M+\vec{Y}_M)/\sqrt{3}$ & $(W/8,3H/4)$ \\ back-right-bottom (BRB) & $(-\vec{Z}_M+\vec{X}_M+\vec{Y}_M)/\sqrt{3}$ & $(7W/8,3H/4)$ \\ \noalign{\vskip 1mm} \multicolumn{3}{l}{$^{1}$ The $W$ and $H$ denote periodic image width and height, respectively.} \end{tabular}