This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.

Except for this watermark, it is identical to the accepted version;

the final published version of the proceedings is available on IEEE Xplore.

Time-Efficient Light-Field Acquisition Using Coded Aperture and Events

Shuji Habuchi† Keita Takahashi† Chihiro Tsutake† Toshiaki Fujii† Hajime Nagahara‡ † Nagoya University, Japan ‡ Osaka University, Japan

Abstract

We propose a computational imaging method for time- efficient light-field acquisition that combines a coded aper- ture with an event-based camera. Different from the conven- tional coded-aperture imaging method, our method applies a sequence of coding patterns during a single exposure for an image frame. The parallax information, which is related to the differences in coding patterns, is recorded as events. The image frame and events, all of which are measured in a single exposure, are jointly used to computationally recon- struct a light field. We also designed an algorithm pipeline for our method that is end-to-end trainable on the basis of deep optics and compatible with real camera hardware. We experimentally showed that our method can achieve more accurate reconstruction than several other imaging meth- ods with a single exposure. We also developed a hardware prototype with the potential to complete the measurement on the camera within 22 msec and demonstrated that light fields from real 3-D scenes can be obtained with convincing visual quality. Our software and supplementary video are available from our project website1.

1. Introduction

A light field is usually represented as a set of multi-view images that captures a target 3-D scene from a dense 2-D grid of viewpoints. Light fields have been used for vari- ous applications such as depth estimation [11, 16, 39], ob- ject/material recognition [25, 49], view synthesis [4, 15, 27], and 3-D display [12, 18, 50]. In this paper, we con- sider light-field acquisition from static 3-D scenes.

Due to the large number of images contained in a light field (e.g., 8×8 views), how to acquire a light field has been a long-standing issue [8, 31, 40, 51]. Since views included in a light field are highly redundant with each other, view- by-view sampling seems to be a waste of resources. To achieve more efficient acquisition, researchers investigated coded-aperture imaging [10, 14, 22, 30, 38], with which semi-transparent coding patterns are placed at the aperture

plane of a camera. With this method, the light field of a tar- get scene is optically encoded before being recorded on the image sensor. Some images taken from a stationary camera with different coding patterns are used to computationally reconstruct the original light field. As indicated from sev- eral studies [10, 14, 42], the number of images to acquire can be reduced to only a few (e.g., 2–4).

An issue with coded-aperture imaging is the long mea- surement time, since two or more images should be ac- quired in sequence. As a solution for this issue, we propose a time-efficient light-field acquisition method that can com- plete the measurement in a single exposure. Our method combines a coded aperture [10, 14, 22, 30, 38] and an event- based camera [3, 9], as shown in Fig. 1, that can simul- taneously capture image frames and events. Our method is based on the premise that the aperture coding can be controlled faster than the frame-rate of the image sensor.2 We apply several coding patterns in sequence during a sin- gle exposure for an image frame. Therefore, we do not directly observe individual coded-aperture images, but we have the sum of them as a single image frame. The camera also measures the events asynchronously during the expo- sure. Since the target scene is assumed static, the events are caused exclusively by the change in coding patterns. In other words, we actively induce the events by changing the coding patterns over time. These events include the infor- mation related to the parallax among different viewpoints, which is essential for light-field/3-D reconstruction. The image frame and events, all of which are measured in a single exposure, are jointly used to computationally recon- struct the light field.

We first formalize our imaging method and clarify the quasi-equivalence between our method and the baseline coded-aperture imaging method. We then discuss our de- sign of an end-to-end trainable algorithm tailored for our imaging method while considering the compatibility with real camera hardware. To validate our method, we con- ducted quantitative evaluations, in which the imaging pro- cess was computationally simulated, and real-world exper- iments using our prototype camera. Experimental results

24923

1https://www.fujii.nuee.nagoya-u.ac.jp/Research/EventLF/

2Some electronic devices used for implementing a coded aperture can run much faster than standard image sensors.