Table 1. Quantitative evaluation of our method on BasicLFSR test dataset. Four different models w.r.t. τ and ablation models are † compared. Reported scores are PSNR/SSIM; larger is better for both. indicates that model was trained with second loss term.

\begin{tabular}{l|c|c||ccccc|c} \hline \textbf{Configuraion} & \textbf{$\tau$min} $\tau$ & \textbf{test} $\tau$ & \textbf{FFPI} & \textbf{HCI} (\texttt{ncw}) & \textbf{HCI} (\texttt{old}) & \textbf{INRA} & \textbf{Stanford} & \textbf{A1.1} \\ \hline \hline \textsc{Fixed-$\tau$-low} & 0.675 & 0.075 & 34\textbf{7.66/0.9534} & 32\textbf{04/0.8522} & 39\textbf{53/0.9612} & 36\textbf{ 11/0.9454} & 29\textbf{ 5/0.8975} & 34\textbf{4.54/0.9219 } \\ \textsc{Fixed-$\tau$-mid} & 0.15 & 0.15 & 34\textbf{ 35/0.9503} & 31\textbf{ 22/0.8337} & 38\textbf{ 86/0.9548} & 35\textbf{ 81/0.9437} & 28\textbf{ 7/0.8762} & 33\textbf{ 83/0.9118 } \\ \textsc{Fixed-$\tau$-high} & 0.3 & 0.3 & 34\textbf{ 04/0.9471} & 30\textbf{ 96/0.9287} & 38\textbf{ 11/0.9531} & 35\textbf{ 18/0.9421} & 28\textbf{ 13/0.8684 } & 33\textbf{ 39/0.9080 } \\ \hline & & 0.075 & 34\textbf{ 1.01/0.9459} & 31\textbf{ 13/0.8543} & 38\textbf{ 41/0.9531} & 35\textbf{ 19/0.9351} & 28\textbf{ 35/0.9280 } & 33\textbf{ 56/0.9113 } \\ \textsc{Flexible-$\tau$} & \texttt{Random} & 0.15 & 34\textbf{ 30/0.9502} & 31\textbf{ 26/0.9424} & 38\textbf{ 39/0.9570} & 35\textbf{ 68/0.9442} & 28\textbf{ 75/0.9306} & 33\textbf{ 79/0.9149 } \\ & & 0.3 & 32\textbf{ 29/0.9348} & 29\textbf{ 69/0.7839} & 35\textbf{ 35/0.9013} & 34\textbf{ 47/0.9388 } & 25\textbf{ 57/0.8720} & 31\textbf{ 85/0.8574 } \\ \hline \textsc{Image only} & -- & -- & 27\textbf{ 35/0.8639} & 25\textbf{ 43/0.7916} & 31\textbf{ 13/0.8462} & 29\textbf{ 08/0.8845} & 28\textbf{ 11/0.8783} & 25\textbf{ 16/0.8630} \\ \textsc{Events only$^-$} & \texttt{Random} & 0.15 & 16\textbf{ 29/0.5747} & 12\textbf{ 98/0.4669} & 18\textbf{ 99/0.5835} & 14\textbf{ 92/0.5997} & 10\textbf{ 88/0.5533} & 15\textbf{ 74/0.5079} \\ \textsc{Events only$^-$} & \texttt{Random} & 0.15 & 28\textbf{ 40/0.8447} & 27\textbf{ 17/0.7955} & 29\textbf{ 43/0.8009} & 29\textbf{ 43/0.8009} & 25\textbf{ 45/0.7679} & 28\textbf{ 35/0.7487 } \\ \hline \end{tabular}

Table 2. Quantitative evaluation of other imaging methods on BasicLFSR test dataset. Second column (“#”) shows number of acquired images. CA captures one or more images, while full 4-D, JAEC, and LA capture single image.

\begin{tabular}{l|c|ccccc|c} Method & \# & EPFL & HCI {\scriptsize (new)} & HCI {\scriptsize (old)} & INRIA & Stanford & \small{ALL} \\ \hline\hline CA ($N=4$) + RecNet & {\bf 4} & 35.52/0.9556 & 36.0/0.8796 & 40.1/0.9654 & 36.89/0.9471 & 31.39/0.9254 & 35.39/0.9346 \\ CA ($N=2$) + RecNet & {\it 2} & 34.05/0.9455 & 31.98/0.9599 & 38.82/0.9546 & \small{35.84/0.9414} & 29.76/0.9307 & 34.09/0.9211 \\ CA ($N=1$) + RecNet & {\scriptsize 1} & 27.78/0.8654 & 26.1/0.7251 & 31.31/0.8352 & 29.40/0.8915 & 22.99/0.7522 & 27.62/0.8139 \\ Full-4D + RecNet & {\scriptsize 1} & 32.91/0.9336 & 31.26/0.8371 & 37.0/0.9434 & \small{34.88/0.9345} & 29.16/0.8595 & 32.32/0.9076 \\ IALC ($N-4$) + RecNet & {\scriptsize 1} & 31.84/0.9195 & 30.05/0.8078 & 36.23/0.9213 & \small{33.36/0.9256} & 27.80/0.8569 & 31.97/0.8862 \\ IAEC ($N=1$) {\scriptsize [$\mathcal{I}$]} & {\scriptsize 1} & 30.38/0.9253 & 28.87/0.7732 & 30.1/0.8923 & 33.17/0.9685 & 26.14/0.8737 & 30.7/0.8632 \\ LA + RecNet & {\scriptsize 1} & 24.25/0.6843 & 26.17/0.6714 & 30.81/0.7978 & 25.85/0.7628 & 24.03/0.6926 & 26.22/0.7188 \\ LA ({\scriptsize naive}) & {\scriptsize 1} & 22.25/0.5820 & 24.75/0.6500 & 28.55/0.7157 & \small{23.71/0.7032} & 22.42/0.5934 & 24.36/0.6548 \\ \end{tabular}

Full-4D [42] is an idealized hypothetical imaging model without physical hardware implementations, which enables arbitrary 4-D coding while capturing a single image: ∑

$$
I_{x,y}=\sum_{u,v}m_{x,y,u,v}L_{x,y,u,v}
$$

(14)

where mx,y,u,v ∈ With these three methods, we [0, 1].

appended the same amount of noise as our method to the observed images (σ the intensity range = 0.005 w.r.t. [0, 1]). As indicated by “+RecNet”, each method was com- bined with a light-field reconstruction network that had the same architecture as RecNet.4 The network was trained for each imaging method from scratch; the coding patterns and weights in RecNet were jointly optimized on the same dataset as ours.5 We also used the software of JAEC pro- vided by Mizuno et al. [28], which had 12 times the param- eters of our RecNet, and was retrained on the same dataset as ours. Finally, to simulate lens-array based imaging (LA) [1, 2, 31, 32], which can take a light field in a single shot, we down-sampled each view of a light field into the 1/8×1/8 spatial resolution, and up-sampled it into the orig-

4With CA, N observed images were stacked along the channel dimen- sion and fed to RecNet. With JAEC and full4D, we lifted the observed image to a sparse tensor with 64 channels before feeding to RecNet, as was done in a previous study [42].

5With JAEC, we fixed the coding patterns for the imaging plane, p1, . . . , p4, to those provided by Mizuno et al.’ [28] to ensure the com- patibility with the hardware constraints.

inal resolution using bicubic interpolation (“naive”). We also used RecNet to enhance the quality of the up-sampled light field (“+RecNet”).6

CA (N = 4) can be regarded as the upper-bound ref- erence for our method since our method can obtain a set of data that is quasi-equivalent to the four coded-aperture images (See 3.2). Aligned with this theory, the quantita- tive scores of our method (fixed-τ -low) were close to those of CA (N Our method with a moderate configura- = 4).

tion (flexible-τ , test τ = 0.15) still performed comparably to CA (N = 2) and outperformed CA (N = 1), full-4D, JAEC, and LA. Our method (flexible-τ ) was also stable over a wide range of τ . As shown in Fig. 5. our method (flexible- τ ) consistently (τ ∈ [0.075, 0.275]) outperformed the other imaging methods that can complete the measurement in a single exposure (CA (N = 1), JAEC, and LA).

Several visual results are presented in Fig. 6. Our method obtained a visually-convincing result comparable to that of the reference (CA with N The image-only model = 4).

reconstructed the overall appearance but lost some details and the consistency among the viewpoints. The result ob- tained with the events-only† model seems somewhat con- sistent among the viewpoints but lacking correct intensity. Please refer to the supplementary video for more results with better visualization.

6The up-sampled 64 views were stacked along the channel dimension and fed to RecNet, and RecNet was trained on the same dataset as ours.

24929