Timewarp: Transferable Acceleration of Molecular Dynamics by Learning Time-Coarsened Dynamics

$$
z^{p},z^{v}\sim{\mathcal{N}}(0,I)
$$

$$
x^{p}(t+\tau),x^{v}(t+\tau):=f_{\theta}(z^{p},z^{v};x^{p}(t),x^{v}(t)).
$$

Here zp ∈ R3N and zv ∈ R3N . For all settings of θ and x(t), fθ( · ;x(t)) is a diffeomorphism that takes the latent variables (zp, zv) ∈ R6N to (xp(t+ τ), xv(t+ τ)) ∈ R6N . The conditioning state x(t) parameterises a family of diffeo- morphisms, defining a conditional normalising flow (Win- kler et al., 2019). Note that there are no invertibility con- straints on the mapping from the conditioning state x(t) to the output x(t+ τ), only the map from z to x(t+ τ) must be invertible. Using the change of variables formula, we can evaluate pθ(x(t+ τ)|x(t)) analytically as: ∣∣∣detJf−1θ

(3)

$$
\mathcal{N}\left(f_{\theta}^{-1}(x(t+\tau);x(t));0,I\right)\left|\operatorname*{det}\mathcal{J}_{f_{\rho}^{-1}(x,(t;x))}(x(t+\tau))\right|,
$$

where f−1θ ( · ;x(t)) : R6N → R6N is the inverse of the dif- feomorphism fθ(·;x(t)), and Jf−1θ denotes (·;x(t))(x(t+τ)) the Jacobian of f−1θ ( · ;x(t)) evaluated at x(t+ τ).

non-physical auxiliary variables within the augmented nor- malising flow framework (Huang et al., 2020). For each dat- apoint x(t) = xp(t), xv(t) in D, instead of obtaining xv(t) by recording the velocities in the MD trajectory, we discard the MD velocity and independently draw xv(t) ∼ N (0, I). The auxiliary variables xv(t) now contain no information about the future state xp(t+ τ), xv(t+ τ), since xv(t) and xv(t+ τ) are drawn independently. Hence we can simplify fθ to depend only on xp(t), with xp(t + τ), xv(t + τ) := p, fθ(z zv;xp(t)). This raises the question of why auxiliary variables are necessary: we could instead directly model p(t pθ(x + τ)|xp(t)), without the need for xv. We include auxiliary variables for two reasons: First, they increase the expressivity of the distribution for xp without a prohibitive increase in computational cost (Huang et al., 2020; Chen et al., 2020). Second, constructing a conditional flow that re- spects permutation equivariance is simplified with auxiliary variables — we discuss this in more detail in Section 4.1.

3.4. Targeting the Boltzmann distribution with MCMC

Once the flow pθ(x(t + τ)|x(t)) has been trained, we use it as a proposal distribution in an MCMC method to target the joint distribution of the positions xp and the auxiliary variables xv , which has density:

$$
\begin{array}{r}{\textstyle\mu_{\mathrm{aug}}(x^{p},x^{v})\propto\exp\left({-\frac{U(x^{p})}{k_{B}T}}\right)\mathcal{N}(x^{v};0,I).}\end{array}
$$

N (xv; 0, I). (4)

3.2. Dataset generation

We now describe the dataset used to train the flow. We generate MD trajectories by integrating Equation (2) using the OpenMM library (Eastman et al., 2017). We simulate small proteins (peptides) in implicit water, i.e., without explicitly modelling the degrees of freedom of the water molecules. Specifically, we generate a dataset of trajec- tories D = {Ti}Pi=1, where P is the number of peptides. For each peptide i, we generate an MD trajectory that is temporally sampled with a spacing of τ , so that Ti = (x(0), x(τ), x(2τ), . . .). During training, we randomly sam- ple pairs x(t), x(t + τ) from D. Each pair represents a sample from the conditional distribution µ(x(t+ τ)|x(t)). These samples are used as examples to train the parameters θ of the flow. Additional details are provided in Appendix D.

Since the flow is trained on trajectory data from multiple peptides, we can deploy it at test time to generalise to new peptides not seen in the training data.

3.3. Augmented normalising flows

Typically in molecular simulations, we are primarily inter- ested in the distribution of the positions xp, rather than the velocities xv . Thus, it is not necessary for xv(t), xv(t+τ) to represent the actual velocities of the atoms in Equation (3). We hence simplify the learning problem by treating xv as Letm index the states in the Markov chain. Starting from an p v initial state X0 = (X , X ) ∈ R6N atm = 0, we iterate:

$$
\tilde{X}_{m}\sim p_{\theta}(\cdot\vert X_{m}^{p})
$$

(5)

$$
\begin{array}{r}{X_{m+1}:=\left\{\tilde{X}_{m}\quad\textnormal{with~probability~}\alpha(X_{m},\tilde{X}_{m})\atop X_{m}\quad\textnormal{with~probability~}1-\alpha(X_{m},\tilde{X}_{m})}\end{array}\right.}\end{array}
$$

(6)

where α(Xm, X̃m) is the Metropolis-Hastings (MH) accep- tance ratio (Metropolis et al., 1953) targeting Equation (4):

$$
\alpha(X,{\tilde{X}})=\operatorname*{min}\left(1,\,{\frac{\mu_{\mathrm{aug}}({\tilde{X}})p_{\theta}(X\mid{\tilde{X}}^{p})}{\mu_{\mathrm{aug}}(X)p_{\theta}({\tilde{X}}\mid X^{p})}}\right)
$$

(7)

The flow used for pθ must allow for efficient sampling and exact likelihood evaluation, which is crucial for fast imple- mentation of Equations (5) and (7). Additionally, after each MH step, we resample the auxiliary variables Xv using a Gibbs sampling update:

$$
(X_{m}^{p},X_{m}^{v})\gets(X_{m}^{p},\epsilon),\quad\epsilon\sim{\cal N}(0,I).
$$

(8)

v Iterating these updates yields a sample Xpm, X ∼ µaug as m m→∞. To obtain a Boltzmann-distributed sample of the positionsXpm ∼ µ, we simply discard the auxiliary variables Xvm. In practice, sendingm→∞ is infeasible. Instead, we fix a computational budget and simulate the chain until the budget is reached. Algorithm 1 shows pseudocode for the MCMC procedure, using a batch sampling procedure for the proposals which significantly speeds up sampling.