References

[1] Edward H Adelson and John YA Wang. Single lens stereo with a plenoptic camera. IEEE transactions on pattern anal- ysis and machine intelligence, 14(2):99–106, 1992. 2, 7

[2] Jun Arai, Fumio Okano, Haruo Hoshino, and Ichiro Yuyama. Gradient-index lens-array method based on real-time integral photography for three-dimensional images. Applied optics, 37(11):2034–2045, 1998. 2, 7

[3] Christian Brändli, Raphael Berner, Minhao Yang, Shih-Chii Liu, and Tobi Delbruck. A 240 × 180 130 dB 3 µs latency global shutter spatiotemporal vision sensor. IEEE Journal of Solid-State Circuits, 49:2333–2341, 2014. 1, 2

[4] Michael Broxton, John Flynn, Ryan Overbeck, Daniel Er- ickson, Peter Hedman, Matthew DuVall, Jason Dourgarian, Jay Busch, Matt Whalen, and Paul Debevec. Immersive light field video with a layered mesh representation. In ACM Transactions on Graphics (Proc. SIGGRAPH), 2020. 1

[5] Eric R. Chan, Marco Monteiro, Petr Kellnhofer, Jiajun Wu, and GordonWetzstein. Pi-GAN: Periodic implicit generative adversarial networks for 3D-Aware image synthesis. In Pro- ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021. 2

[6] Eric R. Chan, Koki Nagano, MatthewA. Chan, AlexanderW. Bergman, Jeong Joon Park, Axel Levy, Miika Aittala, Shalini De Mello, Tero Karras, and Gordon Wetzstein. Generative novel view synthesis with 3D-aware diffusion models. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 4217–4229, 2023.

[7] Bin Chen, Lingyan Ruan, and Miu-Ling Lam. LFGAN: 4D light field synthesis from a single RGB image. ACM Trans.

Multimedia Comput. Commun. Appl., 16(1), 2020. 2

[8] Toshiaki Fujii, Kensaku Mori, Kazuya Takeda, Kenji Mase, Masayuki Tanimoto, and Yasuhito Suenaga. Multipoint mea- suring system for video and sound - 100-camera and micro- phone system. In IEEE International Conference on Multi- media and Expo, pages 437–440, 2006. 1, 2

[9] Guillermo Gallego, Tobi Delbrück, Garrick Orchard, Chiara Bartolozzi, Brian Taba, Andrea Censi, Stefan Leutenegger, Andrew J. Davison, Jürg Conradt, Kostas Daniilidis, and Davide Scaramuzza. Event-based vision: A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence, 44(1):154–180, 2022. 1, 2

[10] Mantang Guo, Junhui Hou, Jing Jin, Jie Chen, and Lap- Pui Chau. Deep spatial-angular regularization for light field imaging, denoising, and super-resolution. IEEE Transac- tions on Pattern Analysis and Machine Intelligence, 44(10): 6094–6110, 2022. 1, 2, 3, 6

[11] Katrin Honauer, Ole Johannsen, Daniel Kondermann, and Bastian Goldluecke. A dataset and evaluation methodology for depth estimation on 4D light fields. In Asian Conference on Computer Vision, 2016. 1

[12] Fu-Chung Huang, Kevin Chen, and Gordon Wetzstein. The light field stereoscope: immersive computer graphics via fac- tored near-eye light field displays with focus cues. ACM Transactions on Graphics, 34(4):60, 2015. 1

[13] Michael Iliadis, Leonidas Spinoulas, and Aggelos K. Kat-

saggelos. Deepbinarymask: Learning a binary mask for video compressive sensing, 2016. 2, 4

[14] Yasutaka Inagaki, Yuto Kobayashi, Keita Takahashi, Toshi- aki Fujii, and Hajime Nagahara. Learning to capture light fields through a coded aperture camera. In European Con- ference on Computer Vision, pages 418–434, 2018. 1, 2, 3, 4, 5, 6

[15] Nima Khademi Kalantari, Ting-Chun Wang, and Ravi Ra- mamoorthi. Learning-based view synthesis for light field cameras. ACM Transactions on Graphics, 35(6), 2016. 1

[16] Numair Khan, Min H. Kim, and James Tompkin. Edge- aware bidirectional diffusion for dense depth estimation from light fields. In British Machine Vision Conference (BMVC), 2021. 1

[17] H Kim, S Leutenegger, and AJ Davison. Real-time 3D re- construction and 6-DoF tracking with an event camera. In European Conference on Computer Vision (ECCV), pages 349–364, 2016. 2

[18] Seungjae Lee, Changwon Jang, Seokil Moon, Jaebum Cho, and Byoungho Lee. Additive light field displays: realiza- tion of augmented reality with holographic optical elements.

ACM Transactions on Graphics, 35(4):1–13, 2016. 1

[19] Jiaxin Li, Zijian Feng, Qi She, Henghui Ding, Changhu Wang, and Gim Hee Lee. MINE: Towards continuous depth MPI with NeRF for novel view synthesis. In International Conference on Computer Vision, 2021. 2

[20] Qinbo Li and Nima Khademi Kalantari. Synthesizing light field from a single image with variable MPI and two network fusion. ACM Transactions on Graphics, 2020. 2

[21] Yuqi Li, Miao Qi, Rahul Gulve, Mian Wei, Roman Genov, Kiriakos N. Kutulakos, and Wolfgang Heidrich. End-to-end video compressive sensing using anderson-accelerated un- rolled networks. In International Conference on Computa- tional Photography, pages 137–148, 2020. 2, 4

[22] Chia-Kai Liang, Tai-Hsu Lin, Bing-Yi Wong, Chi Liu, and Homer H Chen. Programmable aperture photography: mul- tiplexed light field acquisition. ACM Transactions on Graph- ics, 27(3):1–10, 2008. 1, 2, 3, 6

[23] Zhengyu Liang. BasicLFSR (open source light field tool- box for super-resolution). https://github.com/ ZhengyuLiang24/BasicLFSR, 2021. 5, 6

[24] Qi Ma, Danda Pani Paudel, Ajad Chhatkuli, and Luc Van Gool. Deformable neural radiance fields using RGB and event cameras. In Proceedings of the IEEE/CVF In- ternational Conference on Computer Vision (ICCV), pages 3590–3600, 2023. 2

[25] Kazuki Maeno, Hajime Nagahara, Atsushi Shimada, and Rin-Ichiro Taniguchi. Light field distortion feature for trans- parent object recognition. In IEEE Conference on Computer Vision and Pattern Recognition, pages 2786–2793, 2013. 1

[26] Kshitij Marwah, Gordon Wetzstein, Yosuke Bando, and Ramesh Raskar. Compressive light field photography using overcomplete dictionaries and optimized projections. ACM Transactions on Graphics, 32(4):1–12, 2013. 2, 4

[27] Ben Mildenhall, Pratul P. Srinivasan, Rodrigo Ortiz-Cayon, Nima Khademi Kalantari, Ravi Ramamoorthi, Ren Ng, and

24931