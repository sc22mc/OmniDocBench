IEEE TRANSACTIONS ON AGRIFOOD ELECTRONICS, VOL. 2, NO. 1, MARCH/APRIL 2024

Fig. 5. Detailed illustration of the flood fill operation initially presented in Fig. 3(b). (a) Sampled plot coordinate image shows the field objects enclose several holes. (b) Flood fill of the background starting at pixel (0, 0). The remaining background regions are the holes. (c) Perform a binary image inversion, the holes are now labeled as foreground regions. (d) Inverted image is combined with the original image eliminating all field object holes.

Next, the image output from the flood fill operation is inverted, as shown in Fig. 5(c). Finally, the inverted flood filled image is combined with the original image in Fig. 5(a). The resultant image is shown in Fig. 5(d). The erosion and dilation image operations, to remove field object connecting pathways, can now take place.

c) Erosion and Dilation: Erosion is a morphological image processing technique that can be used to segment connected image objects. Six iterations of a 2× 2 kernel (pixels) are applied to the flood fill output presented in Fig. 3(b). The operation segments the field objects by removing the pathway pixels in the sampled coordinate image. In addition, the boundary pixels of the field object are eroded. Therefore, a dilation operation (inversion of erosion), of the same kernel size and number of iterations, is applied to restore the field objects to their original size. The result is illustrated in Fig. 3(c). Note that the pathways between field objects are not restored. It may also occur that the dilation operation does not restore all field object boundary pixels that were previously eroded. This is likely to occur on fields which contain tight angled corners. The impact is that some coordinate points at the field perimeter may fall outside the field boundaries detected in the find field contours operation, and be mislabeled as path points.

The field objects are segmented, the algorithm can move onto the next stage to determine the field boundaries as shown in Fig. 3(d).

d) Find Field Contours: Contours are a curve that joins a set of continuous pixels along a boundary that have the same pixel value (color) [63]. Since the field objects are now disconnected, contours can be drawn around the field object edges to represent the field boundaries. To locate the field contours, a border following algorithm, presented in [64], was used via OpenCV. The output of which is illustrated in Fig. 3(d).

The pixel area of each contour polygon is obtained. This allows the proposed algorithm to ensure that incorrectly iso- lated regions are not designated as a false positive (over- segmentation). The lower limit for contour area is 1000 pix- els squared. Converting this back to Cartesian equates to 0.3 Hectares or 3000 m2. An assumption is made that a standalone job is not taking place in a field of such a limited area.An isolated region can arise when, for example, performing a “bulb-pattern” turn at the headland regions when the machine finishes an operation on a linear row. An example of a bulb turn is shown in Section IV, in the left-hand corner of Figs. 7(c). The erosion and dilation operation performed in Stage II, isolates the bulb turn from the main body of the field and is detected as a potentially different field. The contour area of the turn is, however, below the 1000 pixels squared limit and thus, disregarded as path coordinates.

e) Label Coordinate Data: In the final step of Stage II, the detected field boundary pixels are converted to Cartesian. The converted field boundary coordinates are then used to create a set of polygons to checkwhichmachinery trajectory coordinates points they enclose. Fig. 3(e) shows the algorithm result, the coordinates are colored with respect to the segmented field boundary by which they are enclosed. Coordinates not inside a field boundary are labeled as path points and are highlighted in black.

The next section will validate the presented method against two machinery implement datasets, the generation of which is described under Section III-A. To benchmark the algorithm, the field boundaries detected by the algorithm are compared to manually annotated field delineations.

IV. EXPERIMENTAL RESULTS

The algorithmwas validated against two implemented job site datasets. Tables I and II, discussed in Section III-B, show the baler and mower datasets contain 21 and ten cases of conjoined field sites, respectively. The remaining job sites contain singular fields. Job sitemeasurementswere uploaded toGoogleMyMaps and the field geometric boundaries were manually delineated by the authors to verify the contained number of fields. These were then visually compared to the field boundaries output by the algorithm. Two examples of hand-drawn field boundaries for a single field and conjoined field job site are shown in Fig. 6.

Measurements from each site were treated as unique data; the baler and mower may have visited the same harvest site, however, both implementswill traverse the same sites differently due to distinct implement widths and driving patterns. Historical knowledge of geofencing sites was not considered for this study.