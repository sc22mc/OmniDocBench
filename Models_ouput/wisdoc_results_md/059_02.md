Specifically, as the number of tokens in a con- versation utterance and the number of turns in a conversation are usually not very long1, we first en- code the history conversation hierarchically into the history memory using Transformer (Vaswani et al., 2017). The history memory serves as a high-level representation of history conversations. Secondly, as history conversations usually can facilitate the understanding of the current conversation context, we design a history-aware context encoder. The context encoder encodes conversation context, con- sidering both history conversations and the current conversation, by adopting the transformer attention over the history memory and current conversation context. Then, the context encoder also updates the history memory based on the current conver- sation context. Finally, we design a history-aware decoder to fuse learned history information into the response generation process. The history-aware decoder can switch between two strategies, i.e., generating a word from the generic vocabulary or directly copying a word from history conversations.

Experimental results on the large-scale Face- book MSC dataset show that the proposed HAHT model outperforms previous multi-session open- domain dialogue systems in various evaluation metrics. Human evaluation results support that HAHT generates more readable, context-relevant, and history-relevant responses than baseline mod- els. In addition, the ablation study confirms that both the hierarchical encoding of history conver- sations and the history-aware decoder contribute greatly to HAHTâ€™s performance on MSCs and help it leverage historical information more effectively.

2 Related Work

Open-domain dialogue systems aim to perform chit-chat without task and domain restrictions (Rit- ter et al., 2011) and establish long-term relation- ships with users (Clark et al., 2019; Roller et al., 2020). They are generally divided into two groups: generation-based systems and retrieval-based sys- tems. Retrieval-based systems seek to find a suit- able response from a large response candidate set (Zhou et al., 2016; Yuan et al., 2019; Zhong et al., 2020; Zhu et al., 2021; Qian et al., 2021), whereas, generation-based systems focus on generating re- sponses from scratch based on the dialogue history (Serban et al., 2016; Shum et al., 2018; Adiwardana et al., 2020; Roller et al., 2020; Xu et al., 2022). In this paper, we focus on generation-based systems.

Early approaches to response generation include template-based generation methods (Higashinaka et al., 2014) and statistical machine translation (SMT) methods (Ritter et al., 2011). With the de- velopment of deep learning, sequence-to-sequence (Seq2seq) models have been applied to generation- based dialogue systems and achieved great per- formance (Li et al., 2016; Vinyals and Le, 2015; Serban et al., 2017). Recently, with the increas- ing availability of large-scale dialogue datasets (Li et al., 2017; Zhang et al., 2018; Dinan et al., 2019; Huang et al., 2020), Transformer-based lan- guage models pretrained with large-scale corpora, such as Meena (Adiwardana et al., 2020), Blender- Bot (Roller et al., 2021), DialogueGPT (Zhang et al., 2020), and PLATO (Platonov et al., 2020), have made significant progress in the area of open- domain dialogues.

Despite the advancements in the field, current state-of-the-art generative pre-trained models are designed for and trained on large datasets of single- session conversations with a small number of turns. As a result, most existing models employ short token truncation lengths, such as 128 tokens for Meena (Adiwardana et al., 2020), and are unable to encode and utilize historical contexts in MSCs effectively. In addition, there is also a lack of public MSC datasets. Xu et al. released the first multi-session conversation dataset, i.e., Facebook MULTI-SESSION CHAT (Facebook MSC), and explored different retrieval-augmented generative models on the dataset (Lewis et al., 2020; Shuster et al., 2021), which achieved better results than the standard Transformer (Vaswani et al., 2017). However, the experimental results demonstrate that

1On average, conversations have 13 turns and conversation utterances have 16 tokens in Facebook MSC dataset.