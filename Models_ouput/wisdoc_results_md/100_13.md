Published as a conference paper at ICLR 2024

where the chain prompt is the aggregated thought chain z1...n.

chain feedback format: Can this reasoning chain complete the task and reach the target correctly by executing its reasoning steps? why? Write a analysis report with conclusion under ‘Anlysis Report:’.

step feedback format: For each reasoning step, please provide a detailed analysis of whether the current step is a logical inference of the previous step and whether the reasoning step is beneficial to the correct solution. For each reasoning step with errors, please provide an error report and the corresponding advice on revision. For each reasoning step, please provide recommendation or rejection descriptions. Comments should be brief and follow the format: Reasoning step ⟨idx⟩. Analysis report: . Advice: . Recommendation or Reject description: .

confidence feedback format: What is your confidence score on these your evaluations and comments? Please select one value from [0.1, 0.3, 0.5, 0.7, 0.9, 1.0]. The score should be placed after ‘Confidence score:’ for users to read.”

With the feedback prompt, LLMs generate reasoning experience Ft containing conclusion and analysis on the reasoning chain and each reasoning step.

A.3 REASONING PIPELINE

To facilitate the understanding of the proposed Boosting of Thoughts, we summarize the reasoning pipeline in Algorithm Table 1. The source code for this pipeline can be found in the file examples/BoostingOfThought/BoT core.py.

Algorithm 1: Main reasoning pipeline of BoT

Input: Number of iterations T , Number of tree structuresM , Question Q.

Output: Aggregated chain zT1...n.

where F0 will be an empty string. S,X,Q,F0, {Gi} 1 Initialize a simple prompt I0

2 for each iteration t = 1, 2, ..., T do Use LLMs with the prompt It−1 to createM heterogeneous tree S,X,Q,Ft−1, {Gi} }M thought structures through Thought Structure Generation.

Extract thought chains from theM thought structures where each zn is the zn }M i=1 i=1 m=1 best thought chain ofm-th tree structure.

Aggregate into a single thought chain zt1...n by using either Best-First zn i=1 m=1 Aggregation or Greedy aggregation.

Perform Thought Chain Analysis on zt1...n with LLMs to obtain the feedback, which is t.

combined with zt1...n to obtain experience F

Update the prompt by accumulating Ft, leading to It S,X,Q,Ft−1,t, {Gi} 8 end

9 Obtain the solution zT1...n.

B INSIGHTS FOR BOOSTING OF THOUGHTS

Boosting of Thoughts derives from our insights that the reasoning ability of large language models (LLMs) for addressing mathematical problems comes directly from experience, which contains the accumulation of the analysis and advice on previous mistakes. Once the prompt embraces valid historical reasoning experience to be recalled by LLMs before performing reasoning, the produced reasoning steps are generally more logical and reasonable, as shown in the comparison between Table 5 and 6. Such insights also made us consider that LLMs do not need to rely heavily on a well-prepared prompt with human annotations (a few chains of thought demonstrations as exemplars in prompts) for each task. Yet, as LLMs are able to learn from experience, we can start from a simple prompt without examples or manually designed content to gradually collect experience during the reasoning process. Eventually, by accumulating experiences in the prompt, LLMs achieve strong reasoning toward addressing complex problems. With these insights, the Boosting of Thoughts is designed as an automated prompting framework, which iteratively collects an ensemble of trial-and- error reasoning experiences for problem-solving with LLMs. We argue that the proposed BoT is not an application of LLMs to specific tasks but rather builds upon the insights that LLMs’ reasoning ability can be derived directly from the experience gained by analyzing incorrect reasoning chains, without relying on human priors.