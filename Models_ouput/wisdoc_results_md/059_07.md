\begin{tabular}{c|cc|c|c|c|c|c|c|c|c|c|c} \hline \multirow{2}{*}{Model} & \multicolumn{2}{c|}{Session 2} & \multicolumn{3}{c|}{Session 3} & \multicolumn{3}{c|}{Session 4} & \multicolumn{3}{c}{Session 5} \\ & \textsc{B-2} & \textsc{B-3} & \textsc{R-L} & \textsc{B-2} & \textsc{B-3} & \textsc{R-L} & \textsc{B-2} & \textsc{B-3} & \textsc{R-L} & \textsc{B-2} & \textsc{B-3} & \textsc{R-L} \\ \hline BlenderBo & 4.71 & 1.47 & 18.20 & 3.85 & \underline{0.93} & 17.10 & 3.69 & \underline{0.83} & 16.78 & 4.00 & 1.19 & 17.19 \\ BlenderBo$_{\textsc{inuc}}$ & 6.39 & 2.56 & 19.30 & 5.82 & 1.93 & 18.67 & 5.30 & 1.76 & 17.9 & \textbf{6.10} & 2.30 & 18.65 \\ FID-RAG & 6.41 & 2.51 & 19.82 & 5.83 & 1.95 & 18.38 & \textbf{5.81} & 1.85 & \textbf{18.44} & 6.02 & 2.27 & 18.52 \\ \textsc{HA}$_{\textsc{ait}}$ ($\textsc{ours}$) & \textbf{6.69} & \textbf{2.73} & \textbf{20.02} & \textbf{6.03} & \textbf{2.20} & \textbf{18.70} & 5.48 & \textbf{1.95} & 18.00 & \textbf{6.38} & \textbf{2.51} & \textbf{19.18} \\ \hline \end{tabular}

Table 4: Automatic evaluation results of different models on session-opening data. Session i indicates there are i-1 history conversation sessions. B-2, B-3, and R-L denote BLEU-2, BLEU-3, and Rouge-L respectively. The best results are in boldface.

\begin{tabular}{c|c|c|c|cc|c|c|c|c|c|c|c} \hline \multirow{2}{*}{Model} & \multicolumn{3}{c|}{Session 2} & \multicolumn{3}{c|}{Session 3} & \multicolumn{3}{c|}{Session 4} & \multicolumn{3}{c}{Session 5} \\ \cline{2-13} & B-2 & B-3 & R-L & B-2 & B-3 & R-L & B-2 & B-3 & R-L & B-2 & B-3 & R-L \\ \hline $\text{HAHT}$ & \textbf{5.07} & \textbf{1.57} & \textbf{16.90} & \textbf{5.27} & \textbf{1.67} & \textbf{16.72} & \textbf{5.00} & \textbf{1.55} & \textbf{15.97} & \textbf{5.16} & \textbf{1.60} & \textbf{16.42} \\ $\text{HAHT}_{\text{w/o HER}}$ & 5.00\textsuperscript{1} & 1.57 & \textbf{16.72} & 5.19 & 1.63 & \textbf{16.61} & 4.86 & 1.49 & \text{15.90} & \textit{5.11}\textsuperscript{1} & 1.57 & 16.21 \\ $\text{HAHT}_{\text{w/o HERST}}$ & 4.98 & 1.50 & 16.81 & 5.09 & 1.58 & 16.51 & 4.75 & 1.45 & 15.51 & \textit{5.10}\textsuperscript{1} & 1.49 & 16.24 \\ $\text{HAHT}_{\text{w/o SW}}$ & 5.01 & 1.56 & 16.86 & 5.19 & 1.61 & 16.46 & 4.87 & 1.55 & 15.88 & \textbf{5.07} & 1.55 & 16.17 \\ \hline \end{tabular}

Table 5: The performance achieved by HAHT and different HAHT variants. Session i indicates there are i-1 history conversation sessions. B-2, B-3, and R-L denote BLEU-2, BLEU-3, and Rouge-L respectively. The best results are in boldface.

5.2 Human Evaluation

Table 3 summarizes the human evaluation results on the Facebook MSC dataset. Generally, HAHT outperforms all the baseline methods in terms of all perspectives. This observation is consistent with the automatic evaluation results shown in Table 2. In particular, we find that HAHT performs much better than other baselines in terms of history rel- evancy. This demonstrates that HAHT can better leverage the history conversation sessions and en- gage the user more in the on-going session with the history memory. HAHT also performs better than other baselines in terms of readability and context relevancy. This indicates that HAHT can better understand the current conversation context with the help of the history memory.

5.3 Evaluation on Session Openings

In the MSC task, the session opening is the first con- versation turn of the current conversation. Accord- ing to our observation and the similar observation in (Xu et al., 2022), the opening conversation turn is categorically different from other conversation turns. It typically involves a statement or question that aims to reengage the other speaker based on the known information that has been exchanged in history conversations. Therefore, the performance on the session opening data can further demon- strate the model’s capability in understanding and leveraging history conversations.

We compare all models on these opening re- sponses and show the results in Table 4. We ob- serve that the proposed HAHT model achieves the best performance in terms of most metrics. Es- pecially, when there are 4 history conversations, HAHT outperforms FID-RAG and BlenderBotmsc by 10.6% and 9.1% in terms of BLUE-3. This indi- cates that the proposed HAHT can better leverage conversation history to reengage the user into a new conversation session.

5.4 Ablation study

To better understand the effectiveness of each main component of HAHT, we conduct ablation study for HAHT. Specifically, we consider the following variants of HAHT.

• HAHTw/o HIER: In this variant, we do not en- code the history conversations hierarchically. In- stead, we concatenate all the utterances of his- tory conversations into a long sentence and di- rectly encode it using the transformer encoder.

• HAHTw/o HIST: In this variant, we remove the history encoder from HAHT.

• HAHTw/o SW: In this variant, we remove the switching mechanism from the response genera- tor of HAHT.

Table 5 summarizes the results achieved by dif- ferent HAHT variants, in terms of BLEU-2, BLEU- 3, and Rouge-L. We note that HAHT outperforms HAHTw/o HIER, which indicates that hierarchically