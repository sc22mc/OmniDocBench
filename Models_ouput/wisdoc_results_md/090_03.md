IEEE TRANSACTIONS ON AGRIFOOD ELECTRONICS, VOL. 2, NO. 2, SEPTEMBER/OCTOBER 2024

Fig. 1. Schematic representation of the experimental setup with plants of both groups monitored using bioimpedance measurement. The portable impedance analyzer Analog Discovery 2 is connected to each plant through a multiplexer, synchronized by a Python script controlling the channel opening by an Arduino board.

D. Data Processing and Classification

The dataset to train the models was composed of the equiva- lent circuit parameters extracted for the measurement acquired in the temporal interval between the 5th of August and the 27th of August, labeling the data according to the respective group of the plant, either control or stress. In addition, the measurements collected from the iron-stressed plants were further divided into two classes, with data from the 5th of August to the 16th of August labeled as in early stress while data referring to the measurements of the subsequent days (i.e., until 27th of August) indicated as late stress. Afterward, the obtained dataset was partitionedwith an 80:20 ratio into train and test sets, to train and validate various machine learning classification models, includ- ing discriminant analysis (DA), kernel methods (KM), k-nearest neighbors (KNN), linear models (LM), naive Bayes classifier (NBC), multilayer perceptron (MLP), support vector machines (SVM), and decision trees (DT), using MATLABâ€™s automatic toolbox fitcauto that allows the evaluation of the performance of different classification algorithms by automatically optimizing their hyperparameters. The different type of machine learning algorithms was employed due to their different characteristics, to evaluate the one with better performance in discriminating the fruit ripening. LR utilizes a logistic function to model a binary dependent variable, assuming a linear relationship be- tween log-odds and predictors. DT are nonparametric, creating simple decision rules from data features, providing easily in- terpretable models but susceptible to overfitting. NBC assumes conditional independence of features given the class variable, offering speed and effectiveness in generating simple models. KNN assigns class membership based on similarity among samples, calculating distances to k nearest neighbors. SVMdraw hyperplanes in feature space to maximize class separation.MLP is a simple feed-forward neural network capable of learning nonlinear models with at least three layers and nonlinear ac- tivation functions [28]. The robustness of the trained model was assessed by a subsequent 10 000-round bootstrapping validation phase together with a tenfold cross validation, evaluated on an equally distributed subset of data, and the accuracy of the obtained models was evaluated in terms of F 1-score.

III. RESULTS AND DISCUSSION

The eight plants, divided between four plants exposed to the complete nutrient solution (i.e., control) and four plants with