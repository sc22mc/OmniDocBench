A Proofs

A.1 Proof of Theorem 1

First, line 6 in Algorithm 1 is equal to

$$
x^{a^{\prime}}|_{s_{i}}\gets\left\{\begin{array}{ll}{x^{a^{\prime}}|_{s_{i}}+(1-x^{a^{\prime}}|_{s_{i}})\eta\pi(\mathbf{x}_{i^{\prime}},\mathbf{x},\mathbf{y})+O(\gamma^{2})}&{(a^{\prime}=a)}\\ {x^{a^{\prime}}|_{s_{i}}-x^{a^{\prime}}|_{s_{i}}\eta\pi(\mathbf{x}_{i^{\prime}},\mathbf{x},\mathbf{y})+O(\gamma^{2})}&{(a^{\prime}\neq a)}\end{array}\right.,
$$

(A1)

from Definition 1. st In the stationary state of the repeated games, state si occurs with the probability of p . Then, player i

X (resp. Y) chooses action a (resp. b) with the probability of xa|si and yb|si . If we take the limit η → 0 for updating 1/η times, Algorithm 1 is continualized as dynamics

$$
\begin{array}{rl}&{\dot{x}^{a|s_{i}}=p_{i}^{\mathrm{st}}\displaystyle\sum_{b}y^{b|s_{i}}\Bigg(x^{a|s_{i}}(1-x^{a|s_{i}})\pi(\boldsymbol{e}_{i^{\prime}(a,b)},\mathbf{x},\mathbf{y})+\displaystyle\sum_{a^{\prime}\neq a}x^{a^{\prime}|s_{i}}(-x^{a|s_{i}})\pi(\boldsymbol{e}_{i^{\prime}(a^{\prime},b)},\mathbf{x},\mathbf{y})\Bigg)}\\ &{\quad\quad=p_{i}^{\mathrm{st}}x^{a|s}\Bigg\{\pi(\underbrace{\sum_{b}y^{b|s_{i}}\boldsymbol{e}_{i^{\prime}(a,b)}}_{=\boldsymbol{p}^{a|s}},\mathbf{x},\mathbf{y})-\sum_{a^{\prime}}x^{a^{\prime}|s_{i}}\pi(\underbrace{\sum_{b}y^{b|s_{i}}\boldsymbol{e}_{i^{\prime}(a^{\prime},b)}}_{=\boldsymbol{p}^{a^{\prime}|s_{i}}},\mathbf{x},\mathbf{y})\Bigg\}}\\ &{\quad\quad=p_{i}^{\mathrm{st}}x^{a|s_{i}}\Bigg(\pi(\boldsymbol{p}^{a|s_{i}},\mathbf{x},\mathbf{y})-\underbrace{\sum_{a^{\prime}}x^{a^{\prime}|s_{i}}\pi(\boldsymbol{p}^{a^{\prime}|s_{i}},\mathbf{x},\mathbf{y})}_{=\bar{\pi}^{s_{i}}(\mathbf{x},\mathbf{y})}\Bigg).}\end{array}
$$

(A2)

(A3) (A4)

− Here, i′(a, b) indicates the next state index i′ such that si′ = abs . Eq. (A4) corresponds to Eqs (8) and (9) i in the main manuscript.

A.2 Proof of Theorem 2

Taking the limit γ → 0, we obtain

$$
\Delta^{a|s}=\frac{\partial u^{\mathrm{st}}(\mathrm{Norm}(\mathbf{x}),\mathbf{y})}{\partial x^{a|s}}.
$$

Then, if we take the limit η → 0 for updating 1/η times, Algorithm 2 is continualized as dynamics

(A5)

$$
\dot{x}^{a|s}({\bf x},{\bf y})=x^{a|s}\frac{\partial}{\partial x^{a|s}}u^{\mathrm{st}}(\mathrm{Norm}({\bf x}),{\bf y}).
$$

(A6)

Eq. (A6) corresponds to Eq. (10).

A.3 Proof of Theorem 3

We assume infinitesimal dxa|si , and the infinitesimal change in x;

$$
x^{a|s_{i}}\gets x^{a|s_{i}}+\mathrm{d}x^{a|s_{i}},
$$

$$
\mathbf{x}\leftarrow\operatorname{Norm}(\mathbf{x}),
$$

(A7) (A8)

By this change, the Markov transition matrix M(x,y) changes into M(x,y) + dM(x,y, dxa|s), described as  for all i′, i′′ ∈ {1, . . . , |S|}. Then, the equilibrium state pst(x,y) changes into pst(x,y) + dpst(x,y, dxa|s). Here, note that dM and dpst are a matrix and a vector of order O(dxa|s), respectively. From the stationary state condition, both (E −M )pst = 0 and (E − (M + dM ))(pst + dpst) = 0 hold.

$$
\mathrm{d}M_{i^{\prime}i^{\prime\prime}}=\mathrm{d}x^{a|s_{i}}y^{b|s_{i}}\times\left\{\begin{array}{ll}{{1-x^{a|s_{i}}}}&{{(s_{i^{\prime\prime}}=s_{i},~s_{i^{\prime}}=abs_{i}^{-})}}\\ {{-x^{a^{\prime}|s_{i}}}}&{{(s_{i^{\prime\prime}}=s_{i},~s_{i^{\prime}}=a^{\prime}bs_{i}^{-},a^{\prime}\neq a)}}\\ {{0}}&{{(\mathrm{otherwise})}}\end{array}\right..
$$

(A9)