\begin{tabular}{c|l|cc|cc|cc|cc|cc|cc|cc} \toprule \multirow{2}{*}{\textbf{Method Type}} & \multirow{2}{*}{\textbf{Metahits}} & \multicolumn{2}{c|}{\textbf{Text}$\downarrow$} & \multicolumn{2}{c|}{\textbf{Formula}$\downarrow$} & \multicolumn{2}{c|}{\textbf{Formula}$\downarrow$} & \multicolumn{2}{c|}{\textbf{Table}$\downarrow$} & \multicolumn{2}{c|}{\textbf{Table}} & \multicolumn{2}{c}{\textbf{Read Order}$\downarrow$} & \multicolumn{2}{c}{\textbf{Overall}$\downarrow$} \\ & & \textit{EN} & \textit{ZH} & \textit{EN} & \textit{ZH} & \textit{EN} & \textit{ZH} & \textit{EN} & \textit{ZH} & \textit{EN} & \textit{ZH} & \textit{EN} & \textit{ZH} & \textit{EN} & \textit{ZH} \\ \midrule \multirow{4}{*}{\textbf{Pipeline Tools}} & MinerU {[}42{]} & \textbf{0.061} & \textbf{0.215} & \textbf{0.278} & 0.577 & 3.52 & -2.9 & \textbf{78.6} & 0.21 & \textbf{0.384} & \textbf{0.079} & 0.22 & \textbf{0.15} & \textbf{0.357} \\ & Marker {[}34{]} & 0.08 & 0.315 & 0.53 & 0.883 & 17.6 & 1.17 & 67.6 & 49.2 & 0.019 & 0.685 & 0.14 & 0.34 & 0.326 & 0.556 \\ & Makhpix {[}1{]} & 0.105 & 0.384 & 0.306 & \textbf{0.454} & 62.7 & \textbf{61.1} & \textbf{77.0} & \textbf{67.1} & 0.243 & \textbf{0.32} & 0.08 & 0.304 & 0.151 & 0.365 \\ \midrule \multirow{2}{*}{\textbf{Expert VLMs}} & GOT$\downarrow$CTR {[}45{]} & 0.19 & 0.315 & 0.60 & \underline{0.578} & 35.3 & 7.9 & 59.3 & 47.7 & 0.419 & 3.57 & 0.41 & 0.44 & 0.78 & 0.74 & 1.1 \\ & Menger {[}7{]} & 0.365 & 0.908 & 0.28 & 0.88 & 0.941 & 15.1 & 16.8 & 38.9 & 0.0 & 0.57 & 1.00 & 0.38 & 0.94 & 0.81 & 0.85 \\ \midrule \multirow{3}{*}{\textbf{General VLMs}} & GPT$\downarrow$ {[}47{]} & 0.144 & 0.409 & 0.25 & 0.75 & 0.508 & \underline{72.8} & -2.78 & 73.0 & 67.5 & \underline{0.734} & \underline{0.329} & 0.738 & \underline{0.274} & 0.33 & 0.351 \\ & Qwen$\downarrow$V1-773R {[}44{]} & 0.096 & \underline{0.718} & 0.40 & 0.457 & \underline{82.2} & \underline{6.7} & \underline{78.6} & \underline{76.4} & 0.387 & 0.408 & 0.19 & \textbf{0.19} & \underline{0.75} & \underline{0.327} & \underline{0.377} \\ & Iven$\downarrow$V1-7.25KS {[}45{]} & 0.355 & 0.791 & 0.543 & 0.71 & 67.4 & 44.1 & 63.7 & 0.60 & 0.57 & 0.55 & 0.317 & \underline{0.228} & 0.44 & 0.44 & 0.45 \\ \bottomrule \end{tabular}

Table 2. Comprehensive evaluation of document parsing algorithms on OmniDocBench: performance metrics for text, formula, table, and reading order extraction, with overall scores derived from ground truth comparisons.

\begin{tabular}{c|l|llllllll|l} \toprule \multirow{2}{*}{\textbf{Model Type}} & \multirow{2}{*}{\textbf{Models}} & \textbf{Book} & \textbf{Slides} & \textbf{Financial} & \textbf{Textbook} & \textbf{Educativ} & \textbf{Magazine} & \textbf{Academic} & \textbf{Notes} & \textbf{Newspaper} & \textbf{Overall}\\ \midrule \multirow{3}{*}{\textbf{[Pipeline Tools}} & \texttt{MNerU[42]} & \textbf{0.055} & 0.124 & \textbf{0.033} & \textbf{0.102} & \textbf{0.159} & \underline{0.600} & \textbf{0.025} & 0.984 & \textbf{0.171} & \underline{0.600}\\ & \texttt{Marka[34]} & \underline{0.074} & 0.34 & 0.089 & 3.319 & 0.452 & 0.153 & \underline{0.059} & 0.651 & \underline{0.122} & 0.274\\ & \texttt{Matipis [4]} & 0.131 & 0.22 & 0.2\textasciicircum{}2 & 3.216 & 0.278 & 0.147 & 0.091 & 6.354 & 0.65 & 0.34\\ \midrule \multirow{2}{*}{\textbf{Expert VLMs}} & \texttt{CoIL-OCR[45]} & 0.111 & 0.222 & 0.106 / & \underline{0.132} & 0.204 & 0.198 & 0.1/9 & 0.388 & 0.7 / 1 & 0.25/\\ & \texttt{Noough[7]} & 0.734 & 0.958 & 1.00C & 3.820 & 0.930 & 0.83 & 0.214 & 0.991 & 0.871 & 0.895\\ \midrule \multirow{3}{*}{\textbf{General VLMs}} & \texttt{GPT-4[2]} & 0.157 & 0.163 & 0.548 & 3.187 & 0.281 & 0.173 & 0.145 & 0.607 & 0.751 & 0.316\\ & \texttt{Qwen-GLUE-72E[4]} & 0.096 & \textbf{0.061} & \underline{0.047} & 3.149 & \underline{0.195} & \textbf{0.071} & 0.085 & \textbf{0.168} & 0.57\% & \textbf{0.179}\\ & \texttt{InterV-GLUE-76R[4]} & 0.716 & \underline{0.199} & 0.167 & 3.184 & 0.74/ & 0.130 & 0.419 & \underline{0.776} & 0.904 & 0.133\\ \bottomrule \end{tabular}

Table 3. End-to-end text recognition performance on OmniDocBench: evaluation using edit distance across 9 PDF page types.

Table 4. End-to-end text recognition on OmniDocBench: eval- uation under various page attributes using the edit distance metric. The value is Mean/Variance of scores in the attribute group. Columns represent: Fuzzy (Fuzzy scan), Water (Water- mark), Color (Colorful background). None (No special issue)

\begin{tabular}{l|ccc|c} \textbf{Models} & \textbf{Fuzzy} & \textbf{Water} & \textbf{Color} & \textbf{None} \\ \hline \multicolumn{1}{l|}{MinerU $[$[42$]$} & 0.15/0.048 & \textbf{0.151}/\textbf{0.031} & \underline{0.107}/\underline{0.052} & \underline{0.079}/\textbf{0.035} \\ \multicolumn{1}{l|}{Marker $[$34$]$} & 0.333/0.092 & 0.484/0.126 & 0.319/0.127 & \textbf{0.062}/0.125 \\ \multicolumn{1}{l|}{Mathpix $^{4}$} & 0.294/0.064 & 0.290/0.059 & 0.216/0.09 & 0.135/0.043 \\ \midrule \multicolumn{1}{l|}{GOT-OCR $[$45$]$} & 0.175/0.05 & 0.199/0.056 & 0.186/0.097 & 0.177/0.081 \\ \multicolumn{1}{l|}{Nought $[$7$]$} & 0.934/0.051 & 0.915/0.071 & 0.873/0.096 & 0.615/0.208 \\ \midrule \multicolumn{1}{l|}{GPT4B $[$2$]$} & 0.263/0.078 & 0.195/0.057 & 0.184/0.078 & 0.186/0.072 \\ \multicolumn{1}{l|}{Qwen2-VL--72B $[$44$]$} & \textbf{0.088}/\textbf{0.01} & \underline{0.172}/0.078 & \textbf{0.104}/\textbf{0.05} & 0.084/0.042 \\ \multicolumn{1}{l|}{InterVL2-76B $[$8$]$} & \underline{0.120}/\underline{0.013} & 0.197/\underline{0.042} & 0.155/0.059 & 0.261/0.082 \\ \end{tabular}

Table 5. End-to-end reading order evaluation on OmniDocBench: results across different column layout types using Normalized Edit Distance. The value is Mean/Variance of scores in the at- tribute group.

\begin{tabular}{l|cccc} \toprule \textbf{Models} & \textbf{Single} & \textbf{Double} & \textbf{Three} & \textbf{Complex} \\ \midrule MinerU $[42]$ & 0.311/0.187 & \textbf{0.101}/\textbf{0.013} & \textbf{0.117}/\underline{0.046} & \underline{0.385}/\textbf{0.057} \\ Marker $[34]$ & 0.299/0.143 & 0.299/0.299 & \underline{0.149}/0.063 & \textbf{0.363}/\underline{0.086} \\ Mathpix $^{4}$ & 0.207/0.123 & 0.188/0.07 & 0.225/\textbf{0.029} & 0.452/0.177 \\ \midrule GOT-OCR $[45]$ & 0.163/0.106 & \underline{0.145}/0.059 & 0.257/0.072 & 0.468/0.185 \\ Nogat $[7]$ & 0.852/0.084 & 0.601/0.224 & 0.662/0.093 & 0.873/0.09 \\ \midrule GPT4 $[2]$ & 0.109/0.112 & 0.204/0.076 & 0.254/\underline{0.046} & 0.426/0.188 \\ Qwen2-VL-72B $[44]$ & \textbf{0.066}/\underline{0.048} & \underline{0.145}/0.059 & 0.204/0.055 & 0.394/0.203 \\ InterVLL-726B $[8]$ & \underline{0.082}/\underline{0.052} & 0.312/0.069 & 0.682/0.098 & 0.444/0.174 \\ \end{tabular}

Ignore Handling. We implement an ignore logic for cer- tain components in PDF page content, meaning they par- ticipate in matching but are excluded from metric calcula- tions. This is mainly because of inconsistent output stan- dards among models, which should not affect the validation results. For fairness, we ignore: (1) Headers, footers, page numbers, and page footnotes, which are handled inconsis- tently by different models. (2) Captions for figures, tables, and footnotes often have uncertain placements, thus compli- cating the reading order. Additionally, some models embed table captions in HTML or LaTeX tables, while others treat them as plain text.

4.3. Metric Calculation

Pure Text. We calculate Normalized Edit Distance [21], averaging these metrics at the sample level to obtain the fi- nal scores.

Tables. All tables are converted to HTML format be- fore calculating the Tree-Edit-Distance-based Similarity (TEDS) [54] metric and Normalized Edit Distance.

Formulas. Formulas are currently evaluated using the Character Detection Matching (CDM) metric [41], Normal- ized Edit Distance, and BLEU [33].

Reading Order. Reading order is evaluated using the Nor- malized Edit Distance as metric. It only involves text com- Table 6. Component-level layout detection evaluation on OmniDocBench layout subset: mAP results by PDF page type.

https://github.com/tesseract-ocr/tesseract https://github.com/VikParuchuri/surya https://github.com/lukas-blecher/LaTeX-OCR

24843