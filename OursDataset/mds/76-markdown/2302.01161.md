arXiv:2302.01161v1 [cs.LG] 2 Feb 2023

# Vectorized Scenario Description and Motion Prediction for Scenario-Based Testing

1<sup>st</sup> Max Winkelmann AD Functions & Simulation IAV GmbH Berlin, Germany max.winkelmann@iav.de

2<sup>nd</sup> Constantin Vasconi AD Functions & Simulation IAV GmbH Berlin, Germany constantin.vasconi@iav.de

3<sup>rd</sup> Steffen Müller Department of Automotive Engineering Technische Universität Berlin Berlin, Germany steffen.mueller@tu-berlin.de

Abstract-Automated vehicles (AVs) are tested in diverse scenarios, typically specified by parameters such as velocities, distances, or curve radii. To describe scenarios uniformly independent of such parameters, this paper proposes a vectorized scenario description defined by the road geometry and vehicles' trajectories. Data of this form are generated for three scenarios, merged, and used to train the motion prediction model VectorNet, allowing to predict an AV's trajectory for unseen scenarios. Predicting scenario evaluation metrics, VectorNet partially achieves lower errors than regression models that separately process the three scenarios' data. However, for comprehensive generalization, sufficient variance in the training data must be ensured. Thus, contrary to existing methods, our proposed method can merge diverse scenarios' data and exploit spatial and temporal nuances in the vectorized scenario description. As a result, data from specified test scenarios and real-world scenarios can be compared and combined for (predictive) analyses and scenario selection.

Index Terms-automated driving, motion prediction, safety validation, scenario-based testing, scenario selection

# I. INTRODUCTION

Validating the safety of automated vehicles (AVs) is challenging. Their environment's complex and open nature prevents all-encompassing testing of AVs. Due to the rare nature of accidents, statistical safety validation based on representative routes of human drivers is not possible either [1]. Thus, AVs' validation requires targeted testing to uncover problems effectively and determine residual risks precisely [2], [3].

Which scenarios are risky differs from AV to AV, depending on the hardware and software. Thus, search-based techniques systematically vary scenarios and provoke critical behaviors [\[4\]](#page-9-1). Here, scenario-based testing provides the framework for variation [\[5\]](#page-9-1). First, a *functional* scenario is described in natural language, e.g., "The AV (Ego) follows a curved road.". An associated *logical* scenario specifies open parameters and their ranges, e.g.,  $v_{\text{Ego}} \in [8 \frac{\text{m}}{\text{s}}, 16 \frac{\text{m}}{\text{s}}]$ . Finally, *concrete* scenarios, e.g.,  $v_{\text{Ego}} = 9 \frac{\text{m}}{\text{s}}$ , are parameterized within the logical scenario. Here, data of executed *concrete* scenarios are used to perform predictive analyses for further *concrete* scenarios and select relevant *concrete* scenarios for executio.

However, the description of scenarios by parameters has limitations. Conventional techniques for predictive analyses cannot be used across logical and functional scenarios as 

This work was supported in part by IAV GmbH, 10587 Berlin, Germany

their parameters vary considerably. Thus, the search for relevant concrete scenarios starts anew for each functional and logical scenario. Furthermore, real-world scenarios may only be described inadequately by parameters since, e.g., the road geometry can be arbitrarily complex  $[6]$ – $[8]$ . Thus, it is unclear what behavior to expect in real-world tests, and the comparison of AVs' behavior in tests and real-world scenarios is restricted.

This paper explores how a uniform scenario description and predictive analyses across logical, functional, and real-world scenarios can be achieved. Motion prediction techniques are examined as possible solutions. Our main contributions are:

- A vectorized scenario description suitable for diverse and complex concrete scenarios and (predictive) analyses.
- The integration of motion prediction into scenariobased testing, enabling comprehensive predictive analyses across functional, logical, and real-world scenarios.
- The implementation and investigation of our approach using the motion prediction model VectorNet [9].

# II. RELATED WORK

Below, we discuss the essential artifacts in scenario-based testing and assess their suitability as a basis for predictive analyses. The lower part of Fig. 1 illustrates these artifacts.

## A. From Functional Scenarios to Concrete Scenarios

**Functional scenarios** are described in natural language [5] and can be supported by sketches [10]. Thus, functional scenarios are human-readable, but their representation and abstraction limit their suitability as a data basis for predictive analyses. Similar limitations apply to abstract scenarios [10], which we do not discuss further due to their low prevalence.

Logical scenarios complement functional scenarios with  $N_I$  influencing parameters [5], which we denote by inputs  $\boldsymbol{x} \in \mathbb{R}^{N_I}$ . Furthermore, lower and upper bounds of  $\boldsymbol{x}$  or the distribution  $p(x)$  are determined. For a specific functional scenario, different logical scenarios can exist if influences are modeled differently in different test setups or are not controllable. E.g., fog may be modeled by noise in a 2D simulation, rendered in a 3D simulation, or real but not controllable in a field test. Due to their open nature, logical scenarios cannot be directly processed but they provide the structure for predictive analyses and search-based techniques.

![](_page_1_Figure_0.jpeg)

Fig. 1. Artifacts in scenario-based testing. While the literature primarily considers the successive definition of functional, logical, and concrete scenarios, tests ultimately have to be instantiated in a test setup. Thus, we refer to the scenario that is executed as the instantiated scenario. During execution, evaluation data are generated, which usually include objects' trajectories and log data. Based on these, evaluation metrics are derived to enable automated assessment. Section II-A to II-C explain these artifacts and transitions in detail. To generate relevant concrete scenarios, current search-based techniques learn a mapping from concrete scenarios to the evaluation metrics, e.g., via regression or classification models (see Section II-D). To learn and predict across functional scenarios and evaluation metrics, we propose using motion prediction models that predict objects' trajectories based on scenario embeddings (see Section III).

**Concrete scenarios** assign fixed values to the inputs of a logical scenario [5]. Hence, each concrete scenario is a parameterized sample  $x$  that can be processed automatically.

## B. From Concrete Scenarios to Instantiated Scenarios

Typically, concrete scenarios are considered the final representation before execution [5]. However, to execute concrete scenarios, they need to be implemented in a test setup [11], [12]. Thereby, some essential properties are determined, which may not be defined in standardized formats such as OpenScenario, e.g., material properties of objects. Since such properties may significantly influence the outcomes of concrete scenarios' execution, we define a more concrete type of scenario:

Instantiated scenarios are scenarios that are ready to be executed in a test setup and include everything that is determined prior to execution. For virtual test setups, the instantiated scenario includes the environment models and their configuration. On a proving ground or during field tests, only some properties of the instantiated scenario are controllable, while others may not be controllable or are even unknown. Since the instantiated scenario can take on various digital, physical, or mixed forms, it cannot be preserved or processed in a uniform data representation.

## C. From Instantiated Scenarios to Evaluation Metrics

Two artifacts result from executing instantiated scenarios:

Evaluation data are generated during instantiated scenarios' execution [11] and typically include objects' trajectories and log data. Some data can only be recorded in virtual test setups, e.g., ground truth object positions.

**Evaluation metrics** are derived from evaluation data [\[11\]](#page-11-1) and chosen based on the test criteria (e.g., comfort or safety), the functional scenario investigated, and the test setup used. E.g., purely longitudinal scenarios may use a minimum time to collision, and more complex scenarios a post encroachment time. Analogous to concrete scenarios, evaluation metrics are outputs, and  $N_O$  evaluation metrics are a sample  $\boldsymbol{y} \in \mathbb{R}^{N_O}$ .

## D. Search-Based Techniques for Scenario Selection

Since relevant concrete scenarios are rare and their execution can be resource-intensive, search-based techniques are used to systematically parameterize scenarios [4], [12]-[15], e.g., via Bayesian optimization, genetic algorithms, reinforcement learning, or adaptive importance sampling. These methods commonly treat the transition from a concrete scenario  $x$  to evaluation metrics  $y$  as a black-box [12]. This is most apparent for regression and classification metamodels, which approximate the mapping from  $\boldsymbol{x}$  to  $\boldsymbol{y}$  based on  $N_S$ samples forming a dataset  $\boldsymbol{X} \in \mathbb{R}^{N_S \times N_I}$ ,  $\boldsymbol{Y} \in \mathbb{R}^{N_S \times N_O}$  [16], [17]. This way, metamodels can bypass the resource-intensive execution by predictions (see upper part of Fig. 1).

Search-based techniques can significantly increase the efficiency of scenario-based testing  $[13]$ – $[17]$ . However, the sole reliance on concrete scenarios and evaluation metrics is restrictive: For different logical scenarios (more, less, or different inputs), the nature of  $x$  changes and data cannot simply be compared or combined; the same is true for evaluation metrics and  $y$ . If the transition between  $x$  and  $y$  changes,  $x$  and  $y$  have the same nature but may have a very different relationship. Thus, here too, data cannot always be compared or combined.

Due to the described problems, most search-based techniques can only be used for a fixed logical scenario with fixed evaluation metrics. However, considering that many functional and logical scenarios with different evaluation metrics have to be analyzed, more extensive transfers of data are beneficial:

1) Transfer Across Instantiated Scenarios: [18] and [19] consider that multiple test setups are available for a given logical scenario and evaluation metric, which allows the advantages of different test setups to be combined. However, as discussed in Section II-A, a change of the test setup may allow for or require a change of the logical scenario.

2) Transfer Across Logical Scenarios: In [20], changes of the logical scenario are handled by translating between concrete scenarios with different inputs (e.g., from rain to

![](_page_2_Figure_0.jpeg)

Fig. 2. Parametric representations of the scenarios (a) adaptive cruise control (ACC, "The Ego follows the Co on a straight road."), (b) lane keeping (LK, "The Ego follows a curved road."), and (c) ACC&LK ("The Ego follows the Co on a curved road."). The center of the lanes in (b) and (c) follows a polynomial of 3<sup>rd</sup> degree. In (a) and (c), the Co starts from its initial x-coordinate  $x_{\text{Co}}$  with a velocity of  $v_{\text{Co}}$ . After a time of  $t_{v}$   $_{\text{Co}}$ , it decelerates with  $a_{\text{Co}}$  for  $t_{a}$   $_{\text{Co}}$ . The Ego's initial velocity  $v_{\rm Ego}$  is varied in all scenarios. More details about the variation are given in Section IV-A. As a result of the execution, evaluation metrics are calculated: the Ego's minimum deceleration  $a_{\min}$ , the Ego's maximum lateral position  $p_{\text{lat max}}$ , and the vehicles' minimum distance  $d_{\min}$ .

![](_page_2_Figure_2.jpeg)

Fig. 3. Vectorized representations of the above scenarios. The scenarios are defined by the static environment (lanes, gray), the dynamic environment (Co, purple), and the Ego's initial pose and velocity (blue). The execution determines the trajectory of the Ego, which can be utilized to calculate evaluation metrics as the ones in Fig. 2. To account for interactions between the Ego and Co(s), trajectories of Co(s) may also result from execution (see Section VI).

sensor noise). Considering scenarios' elements [21], such a translation works for environmental conditions, which parameters can characterize. Digital information is specific to the AV under test and will mostly not change. However, the road network and traffic guidance objects (layer 1  $(L1)$ ), roadside structures (L2), temporary modifications of L1 and  $L2$  (L3), and dynamic objects (L4) cannot be described well by parameters. Hence, translating between concrete scenarios' representations might not be possible for changes in L1 to L4.

3) Transfer Across Functional Scenarios: A change of the functional scenario mostly leads to changes in L1 to L4 and evaluation metrics. Therefore, a transfer of data can not be handled by the discussed search-based techniques.

# III. INTEGRATING SCENARIO-BASED TESTING AND MOTION PREDICTION

This section illustrates the previously described problems with an example and presents an approach to solving them. Considering the three functional scenarios in Fig. 2, it is desirable that data from the scenarios adaptive cruise control  $(ACC)$  and lane keeping  $(LK)$  allow to predict the scenario ACC&LK's outcomes. However, the different logical scenarios and evaluation metrics stand against such a transfer. To enable the transfer of data across different functional (and hence logical) scenarios, metamodels must get more information than just concrete scenarios and evaluation metrics. To implement this, we propose scenario *embeddings*.

## A. From Concrete Scenarios to Scenario Embeddings

An embedding can be defined as "a relatively lowdimensional space into which you can translate high-

dimensional vectors" [22]. Since the instantiated scenario cannot be described by structured data, we create scenario embeddings holding information added during the transition from concrete to instantiated scenarios. Thereby, scenario embeddings can be created without (costly) scenario execution.

A scenario embedding can have various representations. To cover changes in L1 to L4, rendered or vectorized representations from motion prediction are particularly suitable [23] (see upper part of Fig. 3). In  $[6]$ – $[8]$ , such representations are used to generate synthetic scenarios based on real scenarios. However, the behavior of an Ego and the resulting criticality are not considered. Our approach is thus complementary, enabling predictive analyses for synthetic scenarios as well.

Since vectorized representations are characterized by a high level of detail and computational efficiency [23], we choose a vectorized scenario description for our scenario embeddings.

## B. From Evaluation Metrics to Trajectories

To allow for the transfer of data across different evaluation metrics, scenarios' outcomes must be captured in a uniform representation independent of the utilized evaluation metrics. To assess the criticality of scenarios, most evaluation metrics are calculated based on the trajectories of the Ego and other objects. Since the static and dynamic environment of the Ego is already modeled in the scenario embedding, we consider the Ego's trajectory the product of the execution (see lower part of Fig. 3), allowing for the calculation of evaluation metrics.

## C. Motion Prediction for Scenario-Based Testing

Fig. 1 shows that predictive analyses require trajectories to be predicted based on scenario embeddings. A model suitable

for this purpose was introduced in 2020 with VectorNet [23]. Thus, VectorNet is a solid baseline and ideally suitable for our application. The problem is flipped: In typical motion prediction tasks, AVs predict surrounding objects' trajectories. In testing, the trajectories of surrounding objects are (partially) known, but the AVs' behavior has to be predicted.

Scenario embeddings do not cover all properties of instantiated scenarios. The relevant properties may have to be determined by feature selection. Remaining properties can be accounted for by probabilistic motion prediction models.

# IV. EXPERIMENTS

Below, we describe our investigation aimed at addressing three main questions: Can VectorNet predict Ego trajectories...

- for individual functional scenarios it is trained on?
- for multiple functional scenarios it is trained on?
- for functional scenarios not seen during training?

## A. Generation of the Scenario Embeddings and Trajectories

To enable a comparison to regression metamodels, we generate vectorized scenario embeddings for the three scenarios in Fig. 2 parametrically but introduce random variations making the scenarios more complex and realistic (see Fig. 4).

The center of the lanes follows a polynomial of 3<sup>rd</sup> degree with  $x \in [-55 \text{ m}, 55 \text{ m}]$ ; where vectors describe the lanes (at  $-55 \text{ m} + \frac{110 \text{ m}}{24} \cdot i \;\forall i \in \mathbb{N}_0^{\leq 24}$ ), the *y*-coordinate of the lane's center is shifted uniformly by  $\mathcal{U}(-0.5 \text{ m}, 0.5 \text{ m})$ . Accordingly, the lane width is  $3.5 \text{ m} + \mathcal{U}(-0.3 \text{ m}, 0.3 \text{ m})$ . Ego and Co use a lane keeping controller; the resulting vehicle orientations are varied randomly with  $\mathcal{U}(-2.9^{\circ}, 2.9^{\circ})$ . The Co's velocity follows the description in Fig. 2 and is varied with  $\mathcal{U}(-0.1 \frac{\text{m}}{\text{s}}, 0.1 \frac{\text{m}}{\text{s}})$ . Using a P-controller, the Ego tries to ensure a time gap of  $2 \text{ s}$  to the Co. Concrete scenarios are sampled uniformly from the ranges given in Table I. The time step width is  $0.2 \text{ s}$ , and the scenarios are simulated for  $5 \text{ s}$ .

## B. Training of the Motion Prediction Model VectorNet

We build upon a publically available implementation of VectorNet [9]. VectorNet is supplied with the lanes, the Co's trajectory, and the initial vector of the Ego (which holds information about the position, orientation, and velocity). It has to predict all following vectors of the Ego. Available data are split into 90% training and 10% validation data.

TABLE I

LOGICAL SCENARIOS' INPUTS AND RANGES

Input Min Max Unit Explanation 0<sup>th</sup> polynomial coefficient -1 1  $a_0$  $-0.1$  $0.1$ 1<sup>st</sup> polynomial coefficient  $a_1$  $2^{\text{nd}}$  $a_2$  $-0.01$  $0.01$ polynomial coefficient  $-0.001$  $0.001$ 3<sup>rd</sup> polynomial coefficient  $a_3$  $\overline{\text{m}}$  $v_{\text{Ego}}$ 8  $16$ Ego's initial velocity  $\overline{50 + 2v_{\text{Ego}}}$  $50 + v_{\text{Ego}}$  $Co's initial x-coordinate$  $\mathrm{m}$  $x_{\text{Co}}$  $\mathbf{m}$ Co's initial velocity  $v_{\rm Ego}$  $-4$  $v_{\rm Ego}$  $+4$  $v_{\text{Co}}$ 0 3 duration of constant velocity  $t_{\rm v~Co}$  $\mathbf{s}$  $-8$  $-1$ Co's acceleration  $\frac{\text{m}}{2}$  $a_{\text{Cc}}$ 1 3 duration of acceleration  $t_{\rm a, Ca}$ 

![](_page_3_Figure_13.jpeg)

Fig. 4. Data of the scenario ACC&LK. Each vector is defined by its start and end points, object type, object ID, and timestamp. The numbers next to the vectors represent their timestamps in seconds; lanes' timestamps are 0. Note that vectors can contain more features, e.g., bounding boxes or object colors.

## C. Evaluation Procedure and Criteria

To answer the research questions, VectorNet is trained with different mixes of the three scenarios' data.  $N_{\rm LK}$ ,  $N_{\rm ACC}$ , and  $N_{\text{ACC\&LK}}$  denote the number of samples of the respective scenario VectorNet is supplied with.  $ADE_{LK}$ ,  $ADE_{ACC}$ , and  $ADE_{ACC\&LK}$  denote the average displacement error (ADE) with respect to the Ego's trajectory. The ADEs are calculated based on a test set with a size of 10k per functional scenario.

As shown in Fig. 1, we also use VectorNet's predictions to calculate evaluation metrics and compare these to predictions of regression metamodels, which predict the evaluation metrics based on the respective inputs of the scenarios in Table I.

# V. RESULTS

Below, we assess VectorNet's predictive performance based on the predicted Ego trajectories and evaluation metrics.

## A. Assessment Based on Predicted Ego Trajectories

Rows 1 to 3 of Table II indicate that trained with individual functional scenarios' data, VectorNet achieves good ADEs for the functional scenario it is trained on. Rows 4 to 7 show that combining data from two functional scenarios is possible; however, for LK and ACC&LK, 3k samples are required. Combining data from all three scenarios (row 8), the predictive performance is similar to that of the separately trained models (rows 1 to 3); Fig. 5 visualizes this model's predictions.

The more challenging task is the generalization to functional scenarios not seen during training. Row 3 shows that trained on ACC&LK, a low ADE for ACC is achieved. This is expected

TABLE II AVERAGE DISPLACEMENT ERRORS (ADE) OF PRED. EGO TRAJECTORIES

| Row | $N_{\text{ACC}}$ | $N_{\rm LK}$ | $N_{\text{ACC\&LK}}$ | $\text{ADE}_{\text{ACC}}$ | $\text{ADE}_{\text{LK}}$ | $\text{ADE}_{\text{ACC\&LK}}$ |
|-----|------------------|--------------|---------------------|---------------------------|--------------------------|------------------------------|
| 1   | 2000             | 0            | 0                   | $0.37 \,\mathrm{m}$       | $12.47 \,\mathrm{m}$     | $8.96 \,\mathrm{m}$          |
| 2   | 0                | 2000         | 0                   | $2.40 \,\mathrm{m}$       | $0.40 \,\mathrm{m}$      | $6.48 \,\mathrm{m}$          |
| 3   | 0                | 0            | 2000                | $0.43 \,\mathrm{m}$       | $14.86 \,\mathrm{m}$     | $0.52 \,\mathrm{m}$          |
| 4   | 2000             | 2000         | 0                   | $0.39 \,\mathrm{m}$       | $0.41 \,\mathrm{m}$      | $4.69 \,\mathrm{m}$          |
| 5   | 0                | 2000         | 2000                | $1.58 \,\mathrm{m}$       | $0.97 \,\mathrm{m}$      | $1.73 \,\mathrm{m}$          |
| 6   | 0                | 3000         | 3000                | $0.45 \,\mathrm{m}$       | $0.46 \,\mathrm{m}$      | $0.54 \,\mathrm{m}$          |
| 7   | 2000             | 0            | 2000                | $0.37 \,\mathrm{m}$       | $9.18 \,\mathrm{m}$      | $0.47 \,\mathrm{m}$          |
| 8   | 2000             | 2000         | 2000                | $0.40 \,\mathrm{m}$       | $0.42 \,\mathrm{m}$      | $0.60 \,\mathrm{m}$          |
| 9   | 2000             | 2000         | 200                 | $0.41 \text{ m}$          | $0.42 \,\mathrm{m}$      | $0.83 \,\mathrm{m}$          |
| 10  | 0                | 0            | 200                 | $0.88 \,\mathrm{m}$       | $9.95 \,\mathrm{m}$      | $1.13 \,\mathrm{m}$          |

![](_page_4_Figure_0.jpeg)

Fig. 5. Trained with 2k samples of each functional scenario (6k samples overall), VectorNet can predict the Ego's trajectory for all three functional scenarios.

![](_page_4_Figure_2.jpeg)

Fig. 6. Trained on 2k samples of the scenario ACC&LK, VectorNet learns that the Ego follows the Co, which enables predictions for the scenario ACC. However, the prediction for the scenario LK indicates that VectorNet primarily considers the Co's trajectory to predict the lateral behavior of the Ego, not the lanes. VectorNet does not know that the Ego's lateral behavior is determined by the lanes, and only the longitudinal behavior is determined by the Co.

![](_page_4_Figure_4.jpeg)

Fig. 7. Trained on the scenarios ACC and LK (2k samples each), generalization to ACC&LK is not achieved. Here, within the training data, the presence of the Co indicates a straight trajectory of the Ego; curved lanes indicate a constant velocity of the Ego. Accordingly, there is insufficient variance for generalization.

since ACC is a special case of ACC&LK (a straight road). The generalization to LK, however, is poor. Row 4 shows that no generalization from ACC and LK to ACC&LK is achieved. Fig. 6 and Fig. 7 indicate that these results are due to insufficient variance in the training data.

Row 9 shows that generalization from ACC and LK to ACC&LK is achieved if some data from the scenario ACC&LK are added. The resulting ADE is better than what is achieved with the same number of samples of ACC&LK on their own (see row 10). Hence, existing data can improve predictions for new functional scenarios or reduce the amount of data necessary to achieve a certain predictive performance.

Originally, VectorNet uses 211k training and 41k validation samples [23, p. 5]. Our results show that with  $\leq 2k$  samples, reasonable ADEs are achievable. We expect that adjusting the architecture or hyperparameters would allow working with even less data or increasing predictive performance.

## B. Assessment Based on Predicted Evaluation Metrics

Next, we assess the prediction of evaluation metrics derived from VectorNet's predictions (see Fig. 1). The baselines are an extra-tree (ET) and a Bayesian neural network (BNN) with [17]'s hyperparameters. All models are trained with 2k samples. Table III shows that for different evaluation metrics, different models achieve the best mean average errors (MAEs).

The regression models' high performance can be attributed to them learning directly on the relevant features (5 to 10 scenario inputs). However, they cannot account for the complex spatial and temporal nuances described in the scenario embeddings (although it would be possible to take these nuances into account, this would result in up to 150 features, which regression models can hardly process). VectorNet, on the other hand, can account for the nuances but must first identify the relevant features influencing the Ego's trajectory (for the ACC scenarios, the feature (FT) matrix has  $581 \text{ entries}^1$ ). Hence, learning based on vectorized scenario embeddings is more flexible but also more challenging.

<sup>1</sup>(2 lanes  $\cdot$  24  $\frac{\text{vec.}}{\text{lane}}$  + Co  $\cdot$  25  $\frac{\text{vec.}}{\text{Co}}$  + Ego  $\cdot$  1  $\frac{\text{vec.}}{\text{Ego}}$ )  $\cdot$  7  $\frac{\text{FT}}{\text{vec.}}$  = 518 FT

TABLE III MEAN AVERAGE ERRORS (MAE) OF PREDICTED EVALUATION METRICS

| Scenario | Evaluation Metric    | MAE ET               | MAE BNN                     | MAE VectorNet        |
|----------|----------------------|----------------------|-----------------------------|----------------------|
| ACC      | $a_{\min}$           | 0.13 $\frac{m}{s^2}$ | <b>0.07</b> $\frac{m}{s^2}$ | 0.58 $\frac{m}{s^2}$ |
| ACC      | $d_{\min}$           | 0.87 m               | 0.44 m                      | <b>0.26</b> m        |
| LK       | $p_{\text{lat max}}$ | 0.09 m               | <b>0.08</b> m               | 0.38 m               |
| ACC&LK   | $a_{\min}$           | 0.19 $\frac{m}{s^2}$ | <b>0.09</b> $\frac{m}{s^2}$ | 0.74 $\frac{m}{s^2}$ |
| ACC&LK   | $d_{\min}$           | 1.14 m               | 0.55 m                      | <b>0.43</b> m        |
| ACC&LK   | $p_{\text{lat max}}$ | <b>0.08</b> m        | <b>0.08</b> m               | 0.21 m               |

# VI. CONCLUSION AND FUTURE WORK

This paper presented a vectorized scenario description that provides a uniform way to describe both test and real-world scenarios, including spatial and temporal nuances. Unlike scenario description formats such as OpenScenario, which are intended for scenario definition, our vectorized scenario description is especially suitable for (predictive) analyses. We demonstrated this by generating and merging data from three functional scenarios to train the motion prediction model VectorNet. The results showed that VectorNet is able to predict an AV's trajectories based on both individual and multiple scenarios. Given existing data, a small amount of data is sufficient to enable generalization to new functional scenarios. Based on the predicted trajectories, evaluation metrics can also be predicted. Here, VectorNet partially achieves higher predictive performance than conventional regression metamodels. However, for our scenarios that inputs can still represent, the regression metamodels' overall performance is better.

Our results suggest that conventional search-based techniques are preferable for individual test campaigns with specified scenarios. However, our method can benefit from data accumulated during development and testing, and enables new use cases. For example, the behavior of AVs in specified test and real-world scenarios could be compared without scenario identification [24]. For this purpose, data from (virtual) tests could be combined to predict the behavior in real-world scenarios. If the actual behavior deviates from expectations, this indicates factors of reality that have not been thoroughly investigated in tests – a valuable hint for SOTIF area 3 [2].

Possible future work includes integrating dynamics models into the motion prediction to explicitly predict longitudinal and lateral behavior and enforce physically possible predictions. Probabilistic motion prediction models could account for uncertainties. The scenario embeddings could be extended to include inputs such as weather conditions and additional scenario elements such as traffic lights [7], [8]. The model could also be extended to predict logs and learn the behavior of other objects in the environment. This would allow studying interactions between the Ego and its environment.

In summary, integrating motion prediction into scenariobased testing is a promising direction to accelerate and fortify scenario-based testing by expanding the data pool for scenario selection and linking specified (virtual) and real-world tests.

# REFERENCES

- [1] N. Kalra and S. Paddock, "Driving to safety: How many miles of driving would it take to demonstrate autonomous vehicle reliability?' Transportation Research Part A: Policy and Practice, vol. 94, pp. 182-193, Dec. 2016.
- [2] ISO Central Secretary, "Road vehicles Safety of the intended functionality," International Organization for Standardization, Geneva, CH, Standard ISO 21448:2022, Jun. 2022.
- [3] United Nations Economic Commission for Europe, "UN Regulation No. 157 - Automated Lane Keeping Systems (ALKS)," United Nations. Standard E/ECE/TRANS/505/Rev.3/Add.156, Mar. 2021.
- [4] A. Corso, R. Moss, M. Koren, R. Lee, and M. Kochenderfer, "A [4] Survey of Algorithms for Black-Box Safety Validation of Cyber-Physical Systems," Journal of Artificial Intelligence Research, vol. 72, pp. 377-428. Jan. 2022.

- [5] T. Menzel, G. Bagschik, and M. Maurer, "Scenarios for Development, Test and Validation of Automated Vehicles," in 2018 IEEE Intelligent Vehicles Symposium (IV), Jun. 2018, pp. 1821–1827.
- [6] M. Wen, J. Park, and K. Cho, "A scenario generation pipeline for autonomous vehicle simulators," Human-centric Computing and Information Sciences, vol. 10, no. 1, p. 24, Jun. 2020.
- [7] S. Tan, K. Wong, S. Wang, S. Manivasagam, M. Ren, and R. Urtasun, "SceneGen: Learning to generate realistic traffic scenes," in 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Jun. 2021, pp. 892–901.
- [8] L. Feng, Q. Li, Z. Peng, S. Tan, and B. Zhou, "TrafficGen: Learning to Generate Diverse and Realistic Traffic Scenarios," arXiv:2210.06609, Oct. 2022.
- [9] B. Zhang, "VectorNet," https://github.com/ForeverFancy/VectorNet, Dec. 2022.
- [10] C. Neurohr, L. Westhofen, M. Butz, M. H. Bollmann, U. Eberle, and R. Galbas, "Criticality Analysis for the Verification and Validation of Automated Vehicles," IEEE Access, vol. 9, pp. 18016-18041, 2021.
- [11] M. Steimle, T. Menzel, and M. Maurer, "Toward a Consistent Taxonomy for Scenario-Based Development and Test Approaches for Automated Vehicles: A Proposal for a Structuring Framework, a Basic Vocabulary, and Its Application," IEEE Access, vol. 9, pp. 147828-147854, 2021.
- [12] X. Zhang, J. Tao, K. Tan, M. Törngren, J. M. G. Sánchez, M. R. Ramli, X. Tao, M. Gyllenhammar, F. Wotawa, N. Mohan, M. Nica, and H. Felbinger, "Finding Critical Scenarios for Automated Driving Systems: A Systematic Literature Review," arXiv:2110.08664, Oct. 2021.
- [13] F. Batsch, S. Kanarachos, M. Cheah, R. Ponticelli, and M. Blundell, "A taxonomy of validation strategies to ensure the safe operation of highly automated vehicles," Journal of Intelligent Transportation Systems, pp. 1-20. Mar. 2020.
- [14] S. Riedmaier, T. Ponn, D. Ludwig, B. Schick, and F. Diermeyer, "Survey on Scenario-Based Safety Assessment of Automated Vehicles," IEEE Access, vol. 8, pp. 87456-87477, 2020.
- [15] J. Cai, W. Deng, H. Guang, Y. Wang, J. Li, and J. Ding, "A Survey on Data-Driven Scenario Generation for Automated Vehicle Testing," Machines, vol. 10, no. 11, p. 1101, Nov. 2022.
- [16] H. Zhang, H. Zhou, J. Sun, and Y. Tian, "Risk Assessment of Highly Automated Vehicles with Naturalistic Driving Data: A Surrogate-based optimization Method," in 2022 IEEE Intelligent Vehicles Symposium (IV), Jun. 2022, pp. 580-585.
- [17] M. Winkelmann, M. Kohlhoff, H. H. Tadjine, and S. Müller, "Probabilistic Metamodels for an Efficient Characterization of Complex Driving Scenarios," IEEE Transactions on Intelligent Transportation Systems, vol. 23, no. 12, pp. 23 896-23 905, Dec. 2022.
- [18] Z. Huang, M. Arief, H. Lam, and D. Zhao, "Synthesis of Different Autonomous Vehicles Test Approaches," in 2018 21st International Conference on Intelligent Transportation Systems (ITSC), Nov. 2018, рр. 2000-2005.
- [19] S. Feng, Y. Feng, H. Sun, Y. Zhang, and H. X. Liu, "Testing Scenario Library Generation for Connected and Automated Vehicles: An Adaptive Framework," IEEE Transactions on Intelligent Transportation Systems, vol. 23, no. 2, pp. 1213-1222, Feb. 2022.
- [20] M. Winkelmann, C. Vasconi, and S. Müller, "Transfer Importance Sampling - How Testing Automated Vehicles in Multiple Test Setups Helps With the Bias-Variance Tradeoff," in 2022 IEEE 25th International Conference on Intelligent Transportation Systems (ITSC), Oct. 2022, pp. 26-31.
- [21] M. Scholtes, L. Westhofen, L. R. Turner, K. Lotto, M. Schuldes, H. Weber, N. Wagener, C. Neurohr, M. H. Bollmann, F. Körtke, J. Hiller, M. Hoss, J. Bock, and L. Eckstein, "6-Layer Model for a Structured Description and Categorization of Urban Traffic and Environment," IEEE Access, vol. 9, pp. 59 131-59 147, 2021.
- [22] Sally Goldman, "Embeddings," https://developers.google.com/machinelearning/crash-course/embeddings/video-lecture.
- [23] J. Gao, C. Sun, H. Zhao, Y. Shen, D. Anguelov, C. Li, and C. Schmid, "VectorNet: Encoding HD Maps and Agent Dynamics From Vectorized Representation," in 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Jun. 2020, pp. 11 522-11 530.
- [24] F. Montanari, C. Stadler, J. Sichermann, R. German, and A. Djanatliev, [24] "Maneuver-based Resimulation of Driving Scenarios based on Real Driving Data," in 2021 IEEE Intelligent Vehicles Symposium (IV), Jul. 2021, pp. 1124-1131.