{
    "layout_dets": [
        {
            "category_type": "header",
            "poly": [
                452,
                110,
                1222,
                110,
                1222,
                150,
                452,
                150
            ],
            "ignore": false,
            "order": 1,
            "anno_id": 1,
            "text": "Published as a conference paper at ICLR 2024",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        452,
                        110,
                        1222,
                        110,
                        1222,
                        150,
                        452,
                        150
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "section",
            "poly": [
                452.0000000000001,
                346,
                934.0000000000001,
                346,
                934.0000000000001,
                388,
                452.0000000000001,
                388
            ],
            "ignore": false,
            "order": 2,
            "anno_id": 1,
            "text": " # ACKNOWLEDGEMENTS",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        452.0000000000001,
                        346,
                        934.0000000000001,
                        346,
                        934.0000000000001,
                        388,
                        452.0000000000001,
                        388
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "section",
            "poly": [
                450,
                698,
                728,
                698,
                728,
                740,
                450,
                740
            ],
            "ignore": false,
            "order": 4,
            "anno_id": 1,
            "text": "# REFERENCES",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        450,
                        698,
                        728,
                        698,
                        728,
                        740,
                        450,
                        740
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "footer",
            "poly": [
                1242,
                3126,
                1298,
                3126,
                1298,
                3172,
                1242,
                3172
            ],
            "ignore": false,
            "order": 6,
            "anno_id": 1,
            "text": "10",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        1242,
                        3126,
                        1298,
                        3126,
                        1298,
                        3172,
                        1242,
                        3172
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "plain_text",
            "poly": [
                442,
                775.9949999999999,
                2106,
                775.9949999999999,
                2106,
                3045.9449999999997,
                442,
                3045.9449999999997
            ],
            "ignore": false,
            "order": 5,
            "anno_id": 1,
            "text": "- Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et al. Training a helpful and harmless assistant with reinforcement learning from human feedback. *arXiv preprint arXiv:2204.05862*, 2022a. - Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, et al. Constitutional ai: Harmlessness from ai feedback. *arXiv* preprint arXiv:2212.08073, 2022b. - Manik Bhandari, Pranav Narayan Gour, Atabak Ashfaq, Pengfei Liu, and Graham Neubig. Reevaluating evaluation in text summarization. In *Proceedings of the 2020 Conference on Empirical* Methods in Natural Language Processing (EMNLP), pp. 9347–9359, Online, November 2020. Association for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-main.751. URL https: //aclanthology.org/2020.emnlp-main.751. - Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901, 2020. - Tianqi Chen, Bing Xu, Chiyuan Zhang, and Carlos Guestrin. Training deep nets with sublinear memory cost. *arXiv* preprint *arXiv*:1604.06174, 2016. - Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and Eric P. Xing. Vicuna: An open-source chatbot impressing gpt-4 with 90%\\* chatgpt quality, March 2023. URL https: //lmsys.org/blog/2023-03-30-vicuna/. - Tri Dao. Flashattention-2: Faster attention with better parallelism and work partitioning. *arXiv* preprint arXiv:2307.08691, 2023. - Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher Ré. Flashattention: Fast and memoryefficient exact attention with io-awareness. Advances in Neural Information Processing Systems, 35:16344-16359, 2022. - Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pp. 4171–4186, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1423. URL https: //aclanthology.org/N19-1423. - Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy Liang, and Tatsunori B Hashimoto. Alpacafarm: A simulation framework for methods that learn from human feedback. *arXiv* preprint arXiv:2305.14387, 2023. - Kawin Ethayarajh, Yejin Choi, and Swabha Swayamdipta. Understanding dataset difficulty with V-usable information. In *International Conference on Machine Learning*, pp. 5988–6008. PMLR, 2022. - Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei Liu. Gptscore: Evaluate as you desire. arXiv *preprint arXiv:2302.04166, 2023.* - Leo Gao, John Schulman, and Jacob Hilton. Scaling laws for reward model overoptimization. In International Conference on Machine Learning, pp. 10835–10866. PMLR, 2023.",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        442,
                        775.9949999999999,
                        2106,
                        775.9949999999999,
                        2106,
                        3045.9449999999997,
                        442,
                        3045.9449999999997
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "plain_text",
            "poly": [
                440,
                442,
                2102,
                442,
                2102,
                632,
                440,
                632
            ],
            "ignore": false,
            "order": 3,
            "anno_id": 1,
            "text": "We thank Chunpu Xu and Yuqing Yang for supporting the human annotation process, and Yuan Guo for his support in the post-submission maintenance and development of Auto-J. We also thank the anonymous reviewers for their valuable feedback and helpful suggestions. This project is supported by Qingyuan Research Project and Shanghai Artificial Intelligence Laboratory.",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        440,
                        442,
                        2102,
                        442,
                        2102,
                        632,
                        440,
                        632
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        }
    ],
    "extra": {
        "relation": []
    },
    "page_info": {
        "page_attribute": {},
        "page_no": 1030,
        "height": 3300,
        "width": 2550,
        "image_path": "99_10_png.jpg"
    }
}