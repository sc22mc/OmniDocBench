{
    "layout_dets": [
        {
            "category_type": "header",
            "poly": [
                442.49999999999994,
                112.5,
                1222.5,
                112.5,
                1222.5,
                150,
                442.49999999999994,
                150
            ],
            "ignore": false,
            "order": 1,
            "anno_id": 1,
            "text": "Published as a conference paper at ICLR 2024",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        442.49999999999994,
                        112.5,
                        1222.5,
                        112.5,
                        1222.5,
                        150,
                        442.49999999999994,
                        150
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "plain_text",
            "poly": [
                450,
                350,
                2110,
                350,
                2110,
                657.5,
                450,
                657.5
            ],
            "ignore": false,
            "order": 2,
            "anno_id": 1,
            "text": "are limited compared to the more substantial enhancements observed in simpler problem categories. After directly adding 5 correct CoT examples into the prompt, GPT-4 BoT + CoT demonstrates a significant performance boost, surpassing GPT-4 BoT by  $7.7\\%$  and  $11.5\\%$  in Precalculus and Intermediate Algebra domains, respectively. This basic conclusion from these observations is that to guarantee the top performance of BoT in complex mathematical problems, relying on trial-and-error analysis to learn how to reason is not sufficient; instead, the correct answers should also be provided in the prompt for LLMs.",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        450,
                        350,
                        2110,
                        350,
                        2110,
                        657.5,
                        450,
                        657.5
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "plain_text",
            "poly": [
                447.5,
                682.5,
                2107.5,
                682.5,
                2107.5,
                1185,
                447.5,
                1185
            ],
            "ignore": false,
            "order": 3,
            "anno_id": 1,
            "text": "While GPT3.5 with BoT may initially fall behind GPT-4 CoT, leveraging GPT-4 as the evaluator and analyzer to generate experience allows GPT-3.5 BoT (GPT-4) to outperform GPT-4 Complex **CoT**. With the GPT3.5, which has less capacity than GPT4, as the LLM, the solving rate obtained by BoT is at least  $7.7\\%$  (on Algebra) lower than GPT4 ComplexCoT. It is evident that when less powerful LLMs produce lower-quality trial-and-error analyses, the BoT is unable to outperform GPT4 ComplexCoT. Thus, after using the GPT4 in the experience generation part while GPT3.5 is only used to generate reasoning steps, GPT3.5 BoT (GPT4) shows a significant improvement in all categories, leading to a solving rate of  $55.8\\%$ , which outperforms GPT4 ComplexCoT by  $5.5\\%$  and is even  $1.9\\%$  higher than the current state-of-the-art GPT4 PHP+ComplexCoT. These observations further demonstrate that the accumulation of experience over iterations in the prompt constitutes the primary factor contributing to the success of the BoT framework.",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        447.5,
                        682.5,
                        2107.5,
                        682.5,
                        2107.5,
                        1185,
                        447.5,
                        1185
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "plain_text",
            "poly": [
                450,
                1365,
                2100,
                1365,
                2100,
                1592.5,
                450,
                1592.5
            ],
            "ignore": false,
            "order": 5,
            "anno_id": 1,
            "text": "First, in Table 5 - Table 9, we present the detailed prompts that BoT used during the reasoning process, thus providing a comprehensive understanding of what BoT does within each iteration. Then, starting from Table 10, we show some exact examples containing the whole reasoning process of BoT. Following the basic settings shown in the experiment section, these experiments are obtained using BoT with the GPT-3.5-turbo model.",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        450,
                        1365,
                        2100,
                        1365,
                        2100,
                        1592.5,
                        450,
                        1592.5
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "plain_text",
            "poly": [
                450,
                2732.5,
                2100,
                2732.5,
                2100,
                2915,
                450,
                2915
            ],
            "ignore": false,
            "order": 9,
            "anno_id": 1,
            "text": "BoT uses similar basic prompts and the specific format as shown in Table 5 - Table 9. Only the task prompt will be changed, as shown in Table 15. Then, starting from Table 16, we show some exact examples containing the whole reasoning process of BoT. Following the basic settings shown in the experiment section, these experiments are obtained using BoT with the GPT-3.5-turbo model.",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        450,
                        2732.5,
                        2100,
                        2732.5,
                        2100,
                        2915,
                        450,
                        2915
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "footer",
            "poly": [
                1245,
                3112.5,
                1300,
                3112.5,
                1300,
                3170,
                1245,
                3170
            ],
            "ignore": false,
            "order": 10,
            "anno_id": 1,
            "text": "19",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        1245,
                        3112.5,
                        1300,
                        3112.5,
                        1300,
                        3170,
                        1245,
                        3170
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "section",
            "poly": [
                447.49999999999994,
                2622.5,
                1307.5,
                2622.5,
                1307.5,
                2677.5,
                447.49999999999994,
                2677.5
            ],
            "ignore": false,
            "order": 8,
            "anno_id": 1,
            "text": " # H REASONING RESULTS OF \"GSM8K\"",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        447.49999999999994,
                        2622.5,
                        1307.5,
                        2622.5,
                        1307.5,
                        2677.5,
                        447.49999999999994,
                        2677.5
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "table_caption",
            "poly": [
                447.5,
                1642.4999999999998,
                2110,
                1642.4999999999998,
                2110,
                1762.4999999999998,
                447.5,
                1762.4999999999998
            ],
            "ignore": false,
            "order": 6,
            "anno_id": 1,
            "text": "**Table 5:** Reasoning steps generated by gpt-3.5-turbo when no experience is included in the input prompt. We first let the model generate one step of reasoning five times to check the diversity and then present the final reasoning chain after finishing the first iteration of BoT.",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        447.5,
                        1642.4999999999998,
                        2110,
                        1642.4999999999998,
                        2110,
                        1762.4999999999998,
                        447.5,
                        1762.4999999999998
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "table",
            "poly": [
                455,
                1805,
                2097.5,
                1805,
                2097.5,
                2530,
                455,
                2530
            ],
            "ignore": false,
            "order": 7,
            "anno_id": 1,
            "text": "",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        455,
                        1805,
                        2097.5,
                        1805,
                        2097.5,
                        2530,
                        455,
                        2530
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": "",
                "table_layout": "",
                "language": ""
            },
            "html": "<table>\n<thead>\n<tr>\n<th>Prompt of Game of 24 without experience</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>In the game of 24, you are given four numbers, and the goal is to use basic arithmetic operations $(+, -, *, /)$ to combine these numbers and obtain a result of 24. You</td>\n</tr>\n<tr>\n<td>can only use each number once, and parentheses can be used to change the order of operations.</td>\n</tr>\n<tr>\n<td>Analysis format of each step: Step , Current set: , Selected two numbers: , Operation: , Computed new number: , Remaining numbers: , New set: .</td>\n</tr>\n<tr>\n<td>The given four numbers are: $1 1 4 6$ .</td>\n</tr>\n<tr>\n<td>Let's think step by step.</td>\n</tr>\n<tr>\n<td>Recall historical reasoning experience (Ignore when experience is empty):<br>##########################################</td>\n</tr>\n<tr>\n<td>Pay attention to analysis and conclusion in the experience to avoid making similar mistakes by following the advice.</td>\n</tr>\n<tr>\n<td>Below is a list of ordered reasoning steps, accompanied by their evaluated scores (A higher score means the reasoning step is more likely to complete the task.):</td>\n</tr>\n<tr>\n<td></td>\n</tr>\n<tr>\n<td></td>\n</tr>\n<tr>\n<td>Based on listed reasoning steps only within the above \"——\" (i.e., Not the ones in the experience block), please make one step of reasoning to generate only one<br>subsequential possible reasoning step.</td>\n</tr>\n<tr>\n<td>Five responses from the gpt-3.5-turbo</td>\n</tr>\n<tr>\n<td>Step 1, Current set: 1 1 4 6, Selected two numbers: 1 1, Operation: +, Computed new number: 2, Remaining numbers: 4 6, New set: 2 4 6.</td>\n</tr>\n<tr>\n<td>Step 1, Current set: 1 1 4 6, Selected two numbers: 1 1, Operation: +, Computed new number: 2, Remaining numbers: 4 6, New set: 2 4 6.</td>\n</tr>\n<tr>\n<td>Step 1, Current set: 1 1 4 6, Selected two numbers: 1 1, Operation: +, Computed new number: 2, Remaining numbers: 4 6, New set: 2 4 6.</td>\n</tr>\n<tr>\n<td>Step 1, Current set: 1 1 4 6, Selected two numbers: 1 1, Operation: +, Computed new number: 2, Remaining numbers: 4 6, New set: 2 4 6.</td>\n</tr>\n<tr>\n<td>Step 1, Current set: 1 1 4 6, Selected two numbers: 1 1, Operation: +, Computed new number: 2, Remaining numbers: 4 6, New set: 2 4 6.</td>\n</tr>\n<tr>\n<td>Obtained reasoning chain after aggregation</td>\n</tr>\n<tr>\n<td>Step 1, Current set: 1 1 4 6, Selected two numbers: 1 1, Operation: +, Computed new number: 2, Remaining numbers: 4 6, New set: 2 4 6. Evaluate Score: 0.7</td>\n</tr>\n<tr>\n<td>Step 2, Current set: 1 1 4 6, Selected two numbers: 1 4, Operation: *, Computed new number: 4, Remaining numbers: 1 6, New set: 4 1 6. Evaluate Score: 0.7</td>\n</tr>\n<tr>\n<td>Step 1, Current set: 1 1 4 6, Selected two numbers: 1 1, Operation: *, Computed new number: 1, Remaining numbers: 4 6, New set: 1 4 6. Evaluate Score: 0.7</td>\n</tr>\n</tbody>\n</table>",
            "latex": ""
        },
        {
            "category_type": "section",
            "poly": [
                447.5,
                1260,
                1390,
                1260,
                1390,
                1315,
                447.5,
                1315
            ],
            "ignore": false,
            "order": 4,
            "anno_id": 1,
            "text": "# G REASONING RESULTS OF “GAME OF 24”  ",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        447.5,
                        1260,
                        1390,
                        1260,
                        1390,
                        1315,
                        447.5,
                        1315
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        }
    ],
    "extra": {
        "relation": []
    },
    "page_info": {
        "page_attribute": {},
        "page_no": 10,
        "height": 3300,
        "width": 2550,
        "image_path": "100_19_png.jpg"
    }
}