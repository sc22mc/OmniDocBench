{
    "layout_dets": [
        {
            "category_type": "plain_text",
            "poly": [
                297.4999999999999,
                302.5,
                2255,
                302.5,
                2255,
                452.5,
                297.4999999999999,
                452.5
            ],
            "ignore": false,
            "order": 1,
            "anno_id": 1,
            "text": " **Assumption 1** (One-memory two-action zero-sum game). We assume a two-action (i.e.,  $\\mathcal{A} = \\{a_1, a_2\\}$ and  $\\mathcal{B} = \\{b_1, b_2\\}$ ), one-memory (i.e.,  $\\mathbf{s} = (a_1b_1, a_1b_2, a_2b_1, a_2b_2)$ ), and zero-sum game (i.e.,  $\\mathbf{v} = -\\mathbf{u}$ ). Inparticular, we discuss zero-sum games where both  $u_1$  and  $u_4$  are smaller or larger than both  $u_2$  and  $u_3$ .",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        297.4999999999999,
                        302.5,
                        2255,
                        302.5,
                        2255,
                        452.5,
                        297.4999999999999,
                        452.5
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "plain_text",
            "poly": [
                297.4999999999999,
                477.5,
                2257.5,
                477.5,
                2257.5,
                672.5,
                297.4999999999999,
                672.5
            ],
            "ignore": false,
            "order": 2,
            "anno_id": 1,
            "text": " Under Assumption 1, we exclude uninteresting zero-sum payoff matrices that the Nash equilibrium exists as a set of pure strategies because the learning dynamics trivially converge to such pure strategies. The condition that both  $u_1$  and  $u_4$  are smaller or larger than both  $u_2$  and  $u_3$  is necessary and sufficient for the existence of no dominant pure strategy.",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        297.4999999999999,
                        477.5,
                        2257.5,
                        477.5,
                        2257.5,
                        672.5,
                        297.4999999999999,
                        672.5
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "plain_text",
            "poly": [
                295,
                672.5,
                2257.5,
                672.5,
                2257.5,
                772.5,
                295,
                772.5
            ],
            "ignore": false,
            "order": 3,
            "anno_id": 1,
            "text": " In the rest of this paper, we use a vector notation for strategies of X and Y;  $x := \\{x_i\\}_{i=1,...,4}$  and  $y := \\{y_i\\}_{i=1,...,4}$  as  $x_i := x^{a_1|s_i}$  and  $y_i := y^{b_1|s_i}$ . Indeed,  $x^{a_2|s_i} = 1 - x_i$  and  $y^{b_2|s_i} = 1 - y_i$  hold.",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        295,
                        672.5,
                        2257.5,
                        672.5,
                        2257.5,
                        772.5,
                        295,
                        772.5
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "plain_text",
            "poly": [
                295,
                800.0000000000001,
                2267.5,
                800.0000000000001,
                2267.5,
                892.5000000000001,
                295,
                892.5000000000001
            ],
            "ignore": false,
            "order": 4,
            "anno_id": 1,
            "text": " **Theorem 4** (Uniqueness of Nash equilibrium). Under Assumption 1, the unique Nash equilibrium of this game is  $(x_i, y_i) = (x^*, y^*)$  for all *i* as",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        295,
                        800.0000000000001,
                        2267.5,
                        800.0000000000001,
                        2267.5,
                        892.5000000000001,
                        295,
                        892.5000000000001
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "isolate_formula",
            "poly": [
                825,
                935.0000000000001,
                1737.5,
                935.0000000000001,
                1737.5,
                1037.5,
                825,
                1037.5
            ],
            "ignore": false,
            "order": 5,
            "anno_id": 1,
            "text": " $$ x^* = \\frac{-u_3 + u_4}{u_1 - u_2 - u_3 + u_4}, \\ y^* = \\frac{-u_2 + u_4}{u_1 - u_2 - u_3 + u_4}. $$",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        825,
                        935.0000000000001,
                        1737.5,
                        935.0000000000001,
                        1737.5,
                        1037.5,
                        825,
                        1037.5
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "formula_caption",
            "poly": [
                2180,
                942.4999999999999,
                2250,
                942.4999999999999,
                2250,
                1002.4999999999999,
                2180,
                1002.4999999999999
            ],
            "ignore": false,
            "order": 6,
            "anno_id": 1,
            "text": "(11)",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        2180,
                        942.4999999999999,
                        2250,
                        942.4999999999999,
                        2250,
                        1002.4999999999999,
                        2180,
                        1002.4999999999999
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "plain_text",
            "poly": [
                294.9999999999999,
                1112.5,
                2250,
                1112.5,
                2250,
                1355,
                294.9999999999999,
                1355
            ],
            "ignore": false,
            "order": 7,
            "anno_id": 1,
            "text": "  *Proof Sketch.* Let us prove that X's strategy in Nash equilibrium is uniquely  $x = x^*1$ . First, we define  $u^*$  and  $v^*$  as X's and Y's payoffs in the Nash equilibrium in the zero-memory game. If  $x = x^*1$ , X's expected payoff is  $u^{st} = u^*$ , regardless of Y's strategy  $y$ . Second, we consider that X uses another strategy  $x \\neq x^*1$ . Then, there is Y's strategy such that  $v^{st} > v^* \\Leftrightarrow u^{st} < u^*$ . Thus, X's minimax strategy is uniquely  $x = x^*1$ , completing the proof. See Appendix A.4 for the full proof.  $\\Box$ ",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        294.9999999999999,
                        1112.5,
                        2250,
                        1112.5,
                        2250,
                        1355,
                        294.9999999999999,
                        1355
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "figure",
            "poly": [
                832.5,
                1402.5000000000002,
                1720,
                1402.5000000000002,
                1720,
                2545,
                832.5,
                2545
            ],
            "ignore": false,
            "order": 8,
            "anno_id": 1,
            "text": "",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        832.5,
                        1402.5000000000002,
                        1720,
                        1402.5000000000002,
                        1720,
                        2545,
                        832.5,
                        2545
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "plain_text",
            "poly": [
                1302.5,
                2552.5,
                1392.5,
                2552.5,
                1392.5,
                2592.5,
                1302.5,
                2592.5
            ],
            "ignore": false,
            "order": 9,
            "anno_id": 1,
            "text": "time",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        1302.5,
                        2552.5,
                        1392.5,
                        2552.5,
                        1392.5,
                        2592.5,
                        1302.5,
                        2592.5
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "plain_text",
            "poly": [
                294.9999999999999,
                2912.5,
                2250,
                2912.5,
                2250,
                3015,
                294.9999999999999,
                3015
            ],
            "ignore": false,
            "order": 11,
            "anno_id": 1,
            "text": " Regarding Theorem 4,  $X (Y)$  chooses each action in the same probability independent of the last state. Here, they do not utilize their memory. Thus, note that in this sense, the Nash equilibrium is the same as",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        294.9999999999999,
                        2912.5,
                        2250,
                        2912.5,
                        2250,
                        3015,
                        294.9999999999999,
                        3015
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "footer",
            "poly": [
                1242.5,
                3085,
                1290,
                3085,
                1290,
                3135,
                1242.5,
                3135
            ],
            "ignore": false,
            "order": 12,
            "anno_id": 1,
            "text": "6",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        1242.5,
                        3085,
                        1290,
                        3085,
                        1290,
                        3135,
                        1242.5,
                        3135
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        },
        {
            "category_type": "figure_caption",
            "poly": [
                305.0000000000001,
                2630,
                2250,
                2630,
                2250,
                2850,
                305.0000000000001,
                2850
            ],
            "ignore": false,
            "order": 10,
            "anno_id": 1,
            "text": "Figure 2: Multi-memory learning dynamics near the Nash equilibrium in the penny-matching game. In the upper six panels, colored lines indicate the time series of δi (X’s strategy). The solid (resp. broken) lines are approximated (resp. experimental) trajectories of learning dynamics. From the top, the trajectories are predicted by approximations up to the first, second, and third orders. The bottom panel shows the errors between the approximated and experimental trajectories.",
            "line_with_spans": [
                {
                    "category_type": "text_span",
                    "poly": [
                        305.0000000000001,
                        2630,
                        2250,
                        2630,
                        2250,
                        2850,
                        305.0000000000001,
                        2850
                    ],
                    "text": ""
                }
            ],
            "attribute": {
                "text_language": "",
                "text_background": "",
                "text_rotate": ""
            }
        }
    ],
    "extra": {
        "relation": []
    },
    "page_info": {
        "page_attribute": {},
        "page_no": 744,
        "height": 3300,
        "width": 2550,
        "image_path": "73_6_png.jpg"
    }
}