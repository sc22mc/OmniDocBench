{
  "layout_dets": [
    {
      "category_type": "header",
      "poly": [
        1190,
        132.5,
        2325,
        132.5,
        2325,
        162.5,
        1190,
        162.5
      ],
      "ignore": false,
      "order": "2",
      "anno_id": 1,
      "text": "IEEE TRANSACTIONS ON AGRIFOOD ELECTRONICS, VOL. 1, NO. 2, DECEMBER 2023",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            1190,
            132.5,
            2325,
            132.5,
            2325,
            162.5,
            1190,
            162.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "header",
      "poly": [
        172.5,
        132.5,
        220,
        132.5,
        220,
        162.5,
        172.5,
        162.5
      ],
      "ignore": false,
      "order": "1",
      "anno_id": 1,
      "text": "120 ",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            172.5,
            132.5,
            220,
            132.5,
            220,
            162.5,
            172.5,
            162.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "table_caption",
      "poly": [
        897.5,
        262.5,
        1595,
        262.5,
        1595,
        342.5,
        897.5,
        342.5
      ],
      "ignore": false,
      "order": 3,
      "anno_id": 1,
      "text": " TABLE IV  COMPARISON OF DIFFERENT TYPES OF MODELS [42]",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            897.5,
            262.5,
            1595,
            262.5,
            1595,
            342.5,
            897.5,
            342.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "table",
      "poly": [
        182.5,
        384.9999999999999,
        2307.5,
        384.9999999999999,
        2307.5,
        1415,
        182.5,
        1415
      ],
      "ignore": false,
      "order": 4,
      "anno_id": 1,
      "text": "",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            182.5,
            384.9999999999999,
            2307.5,
            384.9999999999999,
            2307.5,
            1415,
            182.5,
            1415
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": "",
        "table_layout": "",
        "language": ""
      },
      "html": "\n| Model name                       | Input parameters                                                                                                                                                                              | Performance of the models                  | Model complexity | Scalability with respect to time and geographical location | Recommended applications                                                                                                                              | References          |\n|----------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------|------------------|------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------|\n| Linear Regression Model          | -One variable such as vegetation index or reflectance values<br>-One response variable such as chlorophyll measurement                                                                        | Low-high (depends upon the input variable) | Low              | Low                                                        | -To choose the range of predictor variables and to identify the input which performs best<br>-To remove noise in the training data                    | [289-291]           |\n| Advanced Linear Regression Model | -Multiple inputs<br>-Multiple response variable/output variable                                                                                                                               | Medium-high                                | Medium           | Low                                                        | -To include spectral and temporal information<br>-Hyperparameter tuning can result in optimal performance                                             | [292-296]           |\n| Machine Learning based Model     | -Multiple input/predictor variables<br>-Multiple response variables<br>-number of trees/loss function (depends upon the selected model)                                                       | Medium-high                                | Medium           | Low                                                        | -To include spectral and temporal information<br>-Hyperparameter tuning can result in optimal performance                                             | [74, 161, 297, 298] |\n| Deep Learning based Model        | -Multiple input variables<br>-Based on the input of the size of the model is determined<br>-Size refers to the number of layers and weights<br>-Pre-trained models can be used (if available) | Medium-high                                | High             | High                                                       | -To employ a large number of training data/samples to prevent overfitting/underfitting issues<br>-Optimize the model to obtain an optimal performance | [299-301]           |",
      "latex": ""
    },
    {
      "category_type": "plain_text",
      "poly": [
        172.5,
        1475,
        1227.5,
        1475,
        1227.5,
        2707.5,
        172.5,
        2707.5
      ],
      "ignore": false,
      "order": 5,
      "anno_id": 1,
      "text": " spectral features [263], [264]. RF is an ensemble-based learning method that combines multiple decision trees to produce robust and accurate classification or regression results. RF can be employed for plant disease detection to classify hyperspectral data into healthy or diseased classes [265], [266]. kNN is a nonparametric-based algorithm for classification and regression tasks. For plant disease detection, it compares the plant sample with its neighboring features to identify whether the sample is infected or not [266], [267]. SAM is an algorithm that classifies hyperspectral imagery based on the angle between the spectra. Based on the spectral angle difference, pixels are classified into categories such as healthy or diseased plants [268]. Maximum likelihood classification is a probabilistic classifier that assigns a pixel to the class that has the maximum likelihood. It can be used for plant disease detection to classify hyperspectral data into categories like healthy or diseased [269]. On the other hand, PLSR is a statistical technique that can model the relationship between hyperspectral data and plant disease severity [270]. Dirichlet aggregation regression uses Dirichlet distributions for modeling compositional data, and it can also be used to model the relationship between hyperspectral data and plant disease severity [271]. Logistic regression is used for cases with binary classification, such as disease or no disease detection [272], whereas multiple linear regression can provide multiple classes classification  $[273]$ .",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            172.5,
            1475,
            1227.5,
            1475,
            1227.5,
            2707.5,
            172.5,
            2707.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        170,
        2712.5,
        1227.5,
        2712.5,
        1227.5,
        3112.5,
        170,
        3112.5
      ],
      "ignore": false,
      "order": 6,
      "anno_id": 1,
      "text": " The machine-learning-based classification models can be broadly categorized into supervised and unsupervised learning techniques. Supervised learning techniques require labeled training images/samples to detect the pixel of the region of interest (ROI). A label is associated with each ROI to map the class categories. The labeling of the images is visually conducted and sent to the classification model for training. This aids in improving the detection accuracy of the models but at the",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            170,
            2712.5,
            1227.5,
            2712.5,
            1227.5,
            3112.5,
            170,
            3112.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        1265,
        2710,
        2325,
        2710,
        2325,
        3100,
        1265,
        3100
      ],
      "ignore": false,
      "order": "10",
      "anno_id": 1,
      "text": " Once the image acquisition is completed and the images are processed through objective-based selected models, the next step is to analyze the models. The term objective-based selected models refer to the analytical models chosen based on the specific goals or objectives such as disease detection and identification, classification, severity, and genetic resistance for the diseases [166], [292], [293]. The analyses are carried out in different levels and arrangements. For instance, to observe",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            1265,
            2710,
            2325,
            2710,
            2325,
            3100,
            1265,
            3100
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        1267.4999999999998,
        1970,
        2320,
        1970,
        2320,
        2510,
        1267.4999999999998,
        2510
      ],
      "ignore": false,
      "order": 8,
      "anno_id": 1,
      "text": " Besides machine learning models, deep learning, a subset of machine learning algorithms, is now applied for hyperspectral image analysis. Over the past decades, deep learning algorithms have improved image classification performance, object detection, and so on. Recently, remote sensing image processing algorithms have also been developed to process complex images such as multispectral and hyperspectral images. Some popular algorithms are CNN [276], deep belief networks [277], stacked autoencoder [278], and so on. Table IV compares different models used in image processing techniques for hyperspectral imaging.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            1267.4999999999998,
            1970,
            2320,
            1970,
            2320,
            2510,
            1267.4999999999998,
            2510
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        1262.5000000000002,
        1480,
        2320,
        1480,
        2320,
        1960,
        1262.5000000000002,
        1960
      ],
      "ignore": false,
      "order": "7",
      "anno_id": 1,
      "text": " expense of high labor costs. On the other hand, unsupervised learning techniques require no prior knowledge and learning through clustering and distribution rules of the spectral features in the images. An example of unsupervised learning would be the K-means clustering algorithm. Rice sheath blight diseases were detected using the K-means clustering algorithm in [274]. A study by Yuan et al. [275] proposed an unsupervised learning technique to identify anthracnose diseases in tea leaves. The study could achieve around 96% of accuracies for disease detection [274].",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            1262.5000000000002,
            1480,
            2320,
            1480,
            2320,
            1960,
            1262.5000000000002,
            1960
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "section",
      "poly": [
        1267.5,
        2592.5,
        2125,
        2592.5,
        2125,
        2680,
        1267.5,
        2680
      ],
      "ignore": false,
      "order": "9",
      "anno_id": 1,
      "text": " ## B. Applications of Hyperspectral Imaging in Plant **Disease Detection**",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            1267.5,
            2592.5,
            2125,
            2592.5,
            2125,
            2680,
            1267.5,
            2680
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "footer",
      "poly": [
        282.5,
        3190,
        2167.5,
        3190,
        2167.5,
        3212.5,
        282.5,
        3212.5
      ],
      "ignore": false,
      "order": 11,
      "anno_id": 1,
      "text": " Authorized licensed use limited to: FUDAN UNIVERSITY. Downloaded on August 28,2025 at 01:49:24 UTC from IEEE Xplore. Restrictions apply.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            282.5,
            3190,
            2167.5,
            3190,
            2167.5,
            3212.5,
            282.5,
            3212.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    }
  ],
  "extra": {
    "relation": []
  },
  "page_info": {
    "page_attribute": {},
    "page_no": 869,
    "height": 3300,
    "width": 2475,
    "image_path": "86_13_png.jpg"
  }
}