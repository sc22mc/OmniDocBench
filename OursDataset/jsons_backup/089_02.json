{
  "layout_dets": [
    {
      "category_type": "header",
      "poly": [
        150,
        132.5,
        1745,
        132.5,
        1745,
        170,
        150,
        170
      ],
      "ignore": false,
      "order": 1,
      "anno_id": 1,
      "text": "BARBISAN et al.: MACHINE LEARNING APPROACH FOR QUEEN BEE DETECTION THROUGH REMOTE AUDIO SENSING",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            150,
            132.5,
            1745,
            132.5,
            1745,
            170,
            150,
            170
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "header",
      "poly": [
        2242.5,
        135,
        2305,
        135,
        2305,
        162.5,
        2242.5,
        162.5
      ],
      "ignore": false,
      "order": 2,
      "anno_id": 1,
      "text": "237",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            2242.5,
            135,
            2305,
            135,
            2305,
            162.5,
            2242.5,
            162.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "figure",
      "poly": [
        315,
        270,
        2132.5,
        270,
        2132.5,
        862.5,
        315,
        862.5
      ],
      "ignore": false,
      "order": 3,
      "anno_id": 1,
      "text": "",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            315,
            270,
            2132.5,
            270,
            2132.5,
            862.5,
            315,
            862.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "figure_caption",
      "poly": [
        152.5,
        897.5,
        2302.5,
        897.5,
        2302.5,
        967.5,
        152.5,
        967.5
      ],
      "ignore": false,
      "order": 4,
      "anno_id": 1,
      "text": "Fig. 1. Data flow diagram of the system used in this work to perform all the experiments, it includes the merge of two datasets. The results of the experiments are trained models and a text file that reports the model statistics and the final test results.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            152.5,
            897.5,
            2302.5,
            897.5,
            2302.5,
            967.5,
            152.5,
            967.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        152.5,
        1065,
        1202.5,
        1065,
        1202.5,
        1355,
        152.5,
        1355
      ],
      "ignore": false,
      "order": 5,
      "anno_id": 1,
      "text": "technique that incorporates environmental sensors and microphones, while remaining energy-efficient and capable of running AI models efficiently [20], considering the various sounds bees produce for communication through vibroacoustic signals [18] and using machine learning techniques to automatically identify the different beehive conditions  $[12]$ .",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            152.5,
            1065,
            1202.5,
            1065,
            1202.5,
            1355,
            152.5,
            1355
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        147.5,
        1367.5,
        1207.5,
        1367.5,
        1207.5,
        1700,
        147.5,
        1700
      ],
      "ignore": false,
      "order": 6,
      "anno_id": 1,
      "text": "Previous solutions have employed convolutional neural networks (NNs) and support vector machines (SVMs) for classifying queen presence from audio recordings and using spectrograms extracted from the audio signals as input for these classifiers [21], [22]. Nevertheless, these networks typically exhibit high complexity, rendering them impractical for batterypowered devices.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            147.5,
            1367.5,
            1207.5,
            1367.5,
            1207.5,
            1700,
            147.5,
            1700
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        155,
        1712.5,
        1212.5,
        1712.5,
        1212.5,
        2197.5,
        155,
        2197.5
      ],
      "ignore": false,
      "order": 7,
      "anno_id": 1,
      "text": " This study extends existing research presented in  $[23]$  by examining the performance of NNs and SVMs classifiers, introducing variations in model complexity to enhance the detection of queen presence and extracting features with a reduced number of values. Notably, the focus is solely on utilizing audio information and features derived from it, a deliberate choice aimed at maintaining algorithmic simplicity. This strategy minimizes network input requirements, ultimately considering the computation resources of potential IoT systems based on a microcontroller unit.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            155,
            1712.5,
            1212.5,
            1712.5,
            1212.5,
            2197.5,
            155,
            2197.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        155,
        2207.5,
        1215,
        2207.5,
        1215,
        2652.5,
        155,
        2652.5
      ],
      "ignore": false,
      "order": 8,
      "anno_id": 1,
      "text": " In addition, this research combines the dataset introduced in  $[24]$  with the dataset from  $[4]$ . This combination results in a more comprehensive understanding of the study. This article not only enriches the capabilities of the framework presented in [25], but also offers the possibility of integrating multiple heterogeneous datasets. This innovative approach enhances the available data, providing a more accurate estimate of the trained models' performance and gives flexibility in the design space exploration for a future deployment of the model in IoT devices.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            155,
            2207.5,
            1215,
            2207.5,
            1215,
            2652.5,
            155,
            2652.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        155,
        2805,
        1212.5,
        2805,
        1212.5,
        3100,
        155,
        3100
      ],
      "ignore": false,
      "order": "10",
      "anno_id": 1,
      "text": "The proposed approach relies on using exclusively audio signals captured within the beehive. This noninvasive solution enables continuous monitoring of the beehive, without disturbing the bees or altering their natural behavior. It can provide valuable information for beekeepers, researchers, or conservationists, helping them make informed decisions about hive ",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            155,
            2805,
            1212.5,
            2805,
            1212.5,
            3100,
            155,
            3100
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        1247.5,
        2612.5,
        2302.5,
        2612.5,
        2302.5,
        3107.5,
        1247.5,
        3107.5
      ],
      "ignore": false,
      "order": "15",
      "anno_id": 1,
      "text": " 2) Dataset 2: This dataset was created as part of the work in [29]. The data made available in [24] is a selection of recordings acquired through the NU-Hive project  $[30]$  whose main objective is to develop a beenive monitoring system capable of identifying and predict certain events and states of the hive that are of interest to the beekeeper. The dataset consists of recordings from two hives, captured in two distinct states: a \"Queen Missing\" hive, where the queen bee is absent, and a \"Normal\" hive, where no abnormal activities are observed. Each hive has a recording for each state, with each audio clip",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            1247.5,
            2612.5,
            2302.5,
            2612.5,
            2302.5,
            3107.5,
            1247.5,
            3107.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        1245,
        2157.5,
        2302.5,
        2157.5,
        2302.5,
        2600,
        1245,
        2600
      ],
      "ignore": false,
      "order": "14",
      "anno_id": 1,
      "text": "1) Dataset 1: This dataset [4] comprises 7100 audio and environmental data recordings from European honey bee hives in California. Each file represents a 60 s audio clip recorded at 22 050 Hz with a 32-bit floating-point depth for a single channel. Besides the audio data, each sample includes information about the internal condition of the beehive and the prevailing weather conditions. For our study, we specifically utilized the recorded audio (after removing saturation artifacts) and the label indicating the presence of the queen.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            1245,
            2157.5,
            2302.5,
            2157.5,
            2302.5,
            2600,
            1245,
            2600
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        1252.5,
        1812.5,
        2302.5,
        1812.5,
        2302.5,
        2147.5,
        1252.5,
        2147.5
      ],
      "ignore": false,
      "order": "13",
      "anno_id": 1,
      "text": " In order to train and compare the different algorithms, the following two datasets are used. This allows to increase the overall amount of available data and provides additional insights into how well the models can adapt to various beehives. Having a larger dataset also has another advantage because it helps prevent the issue of overfitting while training complex machine learning models.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            1252.5,
            1812.5,
            2302.5,
            1812.5,
            2302.5,
            2147.5,
            1252.5,
            2147.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        1247.5,
        1065,
        2307.5,
        1065,
        2307.5,
        1655,
        1247.5,
        1655
      ],
      "ignore": false,
      "order": "11",
      "anno_id": 1,
      "text": " management, health assessments, or interventions if necessary. The sound level amplitude and frequency depend on the colony activity and health state. Flying bees produce a typical sound with an approximate frequency of 250 Hz, worker bees produce a characteristic frequency that lies between 225 and 285 Hz to cool the hive with ventilation, and the frequency can reach up to  $3000 \\text{ Hz}$  as a defensive reaction to potential outside threats to the colony [26], [27]. However, if the queen is missing in the beehive the bees produce a sound that contains harmonics with lower frequencies  $[28]$ . Fig. 1 reports the schematic representation of the methodology adopted in this study, details of all steps will be given in the following sections.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            1247.5,
            1065,
            2307.5,
            1065,
            2307.5,
            1655,
            1247.5,
            1655
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "section",
      "poly": [
        1247.5,
        1742.4999999999998,
        1465,
        1742.4999999999998,
        1465,
        1787.4999999999998,
        1247.5,
        1787.4999999999998
      ],
      "ignore": false,
      "order": "12",
      "anno_id": 1,
      "text": " ## A. Datasets",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            1247.5,
            1742.4999999999998,
            1465,
            1742.4999999999998,
            1465,
            1787.4999999999998,
            1247.5,
            1787.4999999999998
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "section",
      "poly": [
        512.5,
        2732.5,
        850,
        2732.5,
        850,
        2780,
        512.5,
        2780
      ],
      "ignore": false,
      "order": "9",
      "anno_id": 1,
      "text": " # II. METHODOLOGY",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            512.5,
            2732.5,
            850,
            2732.5,
            850,
            2780,
            512.5,
            2780
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    }
  ],
  "extra": {
    "relation": []
  },
  "page_info": {
    "page_attribute": {},
    "page_no": 921,
    "height": 3300,
    "width": 2475,
    "image_path": "89_2_png.jpg"
  }
}