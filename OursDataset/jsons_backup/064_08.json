{
  "layout_dets": [
    {
      "category_type": "figure",
      "poly": [
        242.5,
        237.49500000000012,
        2230,
        237.49500000000012,
        2230,
        2272.3450000000003,
        242.5,
        2272.3450000000003
      ],
      "ignore": false,
      "order": "2",
      "anno_id": 1,
      "text": "",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            242.5,
            237.49500000000012,
            2230,
            237.49500000000012,
            2230,
            2272.3450000000003,
            242.5,
            2272.3450000000003
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "figure_caption",
      "poly": [
        385,
        2319.85,
        2112.5,
        2319.85,
        2112.5,
        2364.85,
        385,
        2364.85
      ],
      "ignore": false,
      "order": "3",
      "anno_id": 1,
      "text": " Figure 3. We show the visualizations of 5 procedures of QR-CLIP. For each process, the reader can refer to Fig. 2",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            385,
            2319.85,
            2112.5,
            2319.85,
            2112.5,
            2364.85,
            385,
            2364.85
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "section",
      "poly": [
        225,
        2442.5,
        827.5,
        2442.5,
        827.5,
        2495,
        225,
        2495
      ],
      "ignore": false,
      "order": "4",
      "anno_id": 1,
      "text": " ## 4.5. Limitation and Future Work",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            225,
            2442.5,
            827.5,
            2442.5,
            827.5,
            2495,
            225,
            2495
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        225,
        2527.5,
        1215,
        2527.5,
        1215,
        2970,
        225,
        2970
      ],
      "ignore": false,
      "order": "5",
      "anno_id": 1,
      "text": " We are still in the early stages of investigating how to best use CLIP and the QR principle to explore open-world knowledge to support location and time reasoning. And the modules and techniques developed are simple but effective. In the future: 1) we will investigate more efficient and elegant implementations; 2) while addressing the limited computational resources, collect a larger OWK dataset as input candidates; 3) using multimodal OWKs to see if images from Instagram, Twitter, etc. could help with this task.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            225,
            2527.5,
            1215,
            2527.5,
            1215,
            2970,
            225,
            2970
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "section",
      "poly": [
        1280,
        2435,
        1577.5,
        2435,
        1577.5,
        2500,
        1280,
        2500
      ],
      "ignore": false,
      "order": "6",
      "anno_id": 1,
      "text": " # 5. Conclusion",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            1280,
            2435,
            1577.5,
            2435,
            1577.5,
            2500,
            1280,
            2500
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        1275,
        2525,
        2267.5,
        2525,
        2267.5,
        2975,
        1275,
        2975
      ],
      "ignore": false,
      "order": "7",
      "anno_id": 1,
      "text": " We designed a novel **QR-CLIP** model. It consists of two modules: 1) the **Quantity** module and 2) the **Relevance** module. Experiments show that it outperforms all previous SOTA on location and time reasoning by a wide margin. To show how our designed components affect the model, we conduct comprehensive ablation studies and verify that open-world knowledge is beneficial for solving our problem. We hope this paper will serve as a technical foundation for this study area and inspire more fascinating research.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            1275,
            2525,
            2267.5,
            2525,
            2267.5,
            2975,
            1275,
            2975
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "header",
      "poly": [
        514,
        189.99999999999997,
        1966,
        189.99999999999997,
        1966,
        231.99999999999997,
        514,
        231.99999999999997
      ],
      "ignore": false,
      "order": "1",
      "anno_id": 1,
      "text": "QR-CLIP: Introducing Explicit Open-World Knowledge for Location and Time Reasoning",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            514,
            189.99999999999997,
            1966,
            189.99999999999997,
            1966,
            231.99999999999997,
            514,
            231.99999999999997
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    }
  ],
  "extra": {
    "relation": []
  },
  "page_info": {
    "page_attribute": {},
    "page_no": 663,
    "height": 3300,
    "width": 2550,
    "image_path": "64_8_png.jpg"
  }
}