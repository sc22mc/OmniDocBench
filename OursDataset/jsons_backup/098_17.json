{
  "layout_dets": [
    {
      "category_type": "header",
      "poly": [
        450,
        114,
        1222,
        114,
        1222,
        154,
        450,
        154
      ],
      "ignore": false,
      "order": 1,
      "anno_id": 1,
      "text": "Published as a conference paper at ICLR 2024",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            450,
            114,
            1222,
            114,
            1222,
            154,
            450,
            154
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        446,
        348,
        1974,
        348,
        1974,
        472,
        446,
        472
      ],
      "ignore": false,
      "order": 2,
      "anno_id": 1,
      "text": "making your decision. KEEP YOUR REASONING BRIEF. Again, don't favor either A or B if they are both acceptable and correct -- judge a tie instead.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            446,
            348,
            1974,
            348,
            1974,
            472,
            446,
            472
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        450,
        522,
        1996,
        522,
        1996,
        732,
        450,
        732
      ],
      "ignore": false,
      "order": 3,
      "anno_id": 1,
      "text": "The prompt that the GPT-4 uses to generate 128-token summary is as follows:  \"Write a summary for the above text. Your summary should not exceed 100 words but should include as much information of the original text as possible.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            450,
            522,
            1996,
            522,
            1996,
            732,
            450,
            732
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        447.9999999999999,
        754,
        2088,
        754,
        2088,
        802,
        447.9999999999999,
        802
      ],
      "ignore": false,
      "order": 4,
      "anno_id": 1,
      "text": "\"We show examples of the GPT-4 evaluation on a pretrained and a non-pretrained ICAE in Table 9.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            447.9999999999999,
            754,
            2088,
            754,
            2088,
            802,
            447.9999999999999,
            802
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "table_caption",
      "poly": [
        445.9999999999999,
        846,
        2100,
        846,
        2100,
        990,
        445.9999999999999,
        990
      ],
      "ignore": false,
      "order": 5,
      "anno_id": 1,
      "text": "Table 9: Examples of outputs by the target LLM (i.e., Llama) conditioning on memory slots ( $k = 128$ ) produced by the pretrained and non-pretrained ICAE. The highlighted parts are not faithful to the context.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            445.9999999999999,
            846,
            2100,
            846,
            2100,
            990,
            445.9999999999999,
            990
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "table",
      "poly": [
        462,
        1012.005,
        2096,
        1012.005,
        2096,
        2935.975,
        462,
        2935.975
      ],
      "ignore": false,
      "order": 6,
      "anno_id": 1,
      "text": "",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            462,
            1012.005,
            2096,
            1012.005,
            2096,
            2935.975,
            462,
            2935.975
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": "",
        "table_layout": "",
        "language": ""
      },
      "html": "\n Passage 1 (514 tokens):\n\nFrench senior civil servant arrested on suspicion of spying for North Korea\n\nNovember 27, 2018 by Joseph Fitsanakis\n\nA senior civil servant in the upper house of the French parliament has been arrested on suspicion of spying for North Korea, according to prosecutors. The news of the suspected spy's arrest was first reported on Monday by Quotidien, a daily politics and culture show on the Monaco-based television channel TMC. The show cited \"a judicial source in Paris\" and said that France's domestic security and counterintelligence agency, the General Directorate for Internal Security (DGSI), was in charge of the espionage case.\n\n (omitted 233 words)\n\nThe senior civil servant faces up to 30 years in prison if found guilty of espionage.\n\n| Prompt: What is the maximum prison sentence Quennedey could face if found guilty?                    |\n|------------------------------------------------------------------------------------------------------|\n| Assistant A (pretrained ICAE): Quennedey could face up to 30 years in prison if found guilty.        |\n| Assistant B (non-pretrained ICAE): Quennedey could face up to three years in prison if found guilty. |\n| Answer (by the GPT-4): Up to 30 years.                                                               |\n\nGPT-4 evaluation: Assistant A correctly states the maximum prison sentence from the text, while Assistant B provides an incorrect number.\n\n Passage 2 (506 tokens):\n\nWith Red Hat, IBM to become the leading hybrid cloud provider Watch Now\n\nAfter IBM acquired Red Hat, I suggested IBM paid \\$34 billion for the Linux power so it could become a hybrid-cloud power. With the news that Red Hat will acquire NooBaa, a hybrid-cloud, data-storage company, it's become clearer than ever that the IBM-Red Hat deal is all about the hybrid cloud.\n\n (omitted 208 words)\n\nAs Ranga Rangachari, Red Hat's vice president of Storage and Hyperconverged Infrastructure, said in a statement:\n\n\"Data portability is a key imperative for organizations building and deploying cloud-native applications across private and multiple clouds. NooBaa's technologies will augment our portfolio and strengthen our ability to meet the needs of developers in today's hybrid and multicloud world. We are thrilled to welcome a technical team of nine to the Red Hat family as we work together to further solidify Red Hat as a leading provider of open hybrid-cloud technologies.\n\n**Prompt:** Discuss the role of Ranga Rangachari in the context of the text\n\nAssistant A (pretrained ICAE): Ranga Rangachari is the vice president of Storage and Hyperconverged Infrastructure at Red Hat. He is responsible for the company's storage and hyperconverged offerings, and he welcomes the nine-member team of technical experts from NoaBaa to join Red Hat as a part of the IBM acquisition.\n\nAssistant B (non-pretrained ICAE): Ranga Rangachari is the CEO of Red Hat, and he is excited about the acquisition of NooBaa as it will help Red Hat become a leader in hybrid cloud management. He believes that NooBaa's technology will enable Red Hat to provide a single, comprehensive platform for managing data across multiple clouds, and that this will be a significant differentiator for Red Hat in the market.\n\nAnswer (by the GPT-4): Ranga Rangachari is the vice president of Storage and Hyperconverged Infrastructure at Red Hat. He made a statement regarding the acquisition of NooBaa, highlighting the importance of data portability in today's hybrid and multicloud world and how NooBaa's technologies would strengthen Red Hat's ability to meet the needs of developers.\n\nGPT-4 evaluation: Assistant A correctly identifies Ranga Rangachari's role as the vice president of Storage and Hyperconverged Infrastructure at Red Hat and accurately describes his statement about the acquisition of NooBaa. Assistant B incorrectly states that Ranga Rangachari is the CEO of Red Hat.",
      "latex": ""
    },
    {
      "category_type": "footer",
      "poly": [
        1236,
        3127.97,
        1294,
        3127.97,
        1294,
        3171.97,
        1236,
        3171.97
      ],
      "ignore": false,
      "order": 7,
      "anno_id": 1,
      "text": "17",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            1236,
            3127.97,
            1294,
            3127.97,
            1294,
            3171.97,
            1236,
            3171.97
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    }
  ],
  "extra": {
    "relation": []
  },
  "page_info": {
    "page_attribute": {},
    "page_no": 1020,
    "height": 3300,
    "width": 2550,
    "image_path": "98_17_png.jpg"
  }
}