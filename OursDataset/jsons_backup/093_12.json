{
  "layout_dets": [
    {
      "category_type": "footer",
      "poly": [
        364,
        1850.0000000000002,
        2128,
        1850.0000000000002,
        2128,
        1888.0000000000002,
        364,
        1888.0000000000002
      ],
      "ignore": false,
      "order": "5",
      "anno_id": 1,
      "text": "Open Access funding provided by 'Università degli Studi di Firenze' within the CRUI CARE Agreement",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            364,
            1850.0000000000002,
            2128,
            1850.0000000000002,
            2128,
            1888.0000000000002,
            364,
            1888.0000000000002
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "header",
      "poly": [
        158,
        132,
        2048,
        132,
        2048,
        168,
        158,
        168
      ],
      "ignore": false,
      "order": "1",
      "anno_id": 1,
      "text": "ALMSTEDT et al.: BEYOND THE NAKED EYE: COMPUTER VISION FOR DETECTING BROWN MARMORATED STINK BUG AND ITS PUNCTURES",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            158,
            132,
            2048,
            132,
            2048,
            168,
            158,
            168
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "header",
      "poly": [
        2270,
        134,
        2304,
        134,
        2304,
        160,
        2270,
        160
      ],
      "ignore": false,
      "order": "2",
      "anno_id": 1,
      "text": "17",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            2270,
            134,
            2304,
            134,
            2304,
            160,
            2270,
            160
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        150,
        270,
        1212,
        270,
        1212,
        1812,
        150,
        1812
      ],
      "ignore": false,
      "order": "3",
      "anno_id": 1,
      "text": " - [27] T. Zamljen et al., \"Apple fruit (Malus domestica Borkh.) metabolic response to infestation by invasive brown marmorated stink bug (Halyomorpha halys Stal.),\" Horticulturae, vol. 7, no. 8, 2021, Art. no. 212. - [28] D. Popescu et al., \"New trends in detection of harmful insects and pests in modern agriculture using artificial neural networks. A review,\" Front. Plant Sci., vol. 14, 2023, Art. no. 1268167. - [29] L. Liu, R. Wang, C. Xie, R. Li, F. Wang, and L. Qi, \"A global activated feature pyramid network for tiny pest detection in the wild,\" Mach. Vis. Appl., vol. 33, no. 5, 2022, Art. no. 76. - [30] K. Simonyan and A. Zisserman, \"Very deep convolutional networks for large-scale image recognition,\" 2014, arXiv:1409.1556. - [31] S.-H. Kang and J.-S. Park, \"Aligned matching: Improving small object detection in SSD,\" Sensors, vol. 23, no. 5, 2023, Art. no. 2589. - [32] N. Carion et al., \"End-to-end object detection with transformers,\" in *Proc.* Eur. Conf. Comput. Vis., 2020, pp. 213-229. - [33] T. Lin et al., \"Microsoft COCO: Common objects in context,\" Comput. Vis. ECCV 2014. Lecture Notes Comput. Sci., D. Fleet, T. Pajdla, B. Schiele, T. Tuytelaars, Eds., Springer, Cham, vol. 8693, 2014. [Online]. Available: https://doi.org/10.1007/978-3-319-10602-1 48 - [34] C.-Y. Wang, I-H. Yeh, and H.-Y. M. Liao, \"YOLOv9: Learning what you want to learn using programmable gradient information,\" 2024, arXiv:2402.13616 - [35] A. Wang et al., \"YOLOv10: Real-time end-to-end object detection,\" 2024, arXiv:2405.14458. - [36] V. Ferrari et al., \"Evaluation of the potential of near infrared hyperspectral imaging for monitoring the invasive brown marmorated stink bug,\" Chemometrics Intell. Lab. Sys., vol. 234, 2023, Art. no. 104751. - [37] R. W. Kennard and L. A. Stone, \"Computer aided design of experiments,\" Technometrics, vol. 11, no. 1, pp. 137-148, 1969. - [38] R. Calvini et al., \"Development of a classification algorithm for efficient handling of multiple classes in sorting systems based on hyperspectral imaging,\" J. Spectral Imag., vol. 7, pp. 1-15, 2018. - [39] S. Liu, J. Cheng, L. Liang, H. Bai, and W. Dang, \"Light-weight semantic segmentation network for UAV remote sensing images,\" IEEE J. Sel. Topics Appl. Earth Observ. Remote Sens., vol. 14, pp. 8287-8296, Aug. 2021. - [40] P. Gonzalez et al., \"An extremely compact and high-speed line-scan hyperspectral imager covering the SWIR range,\" in *Image Sensing Technologies:* Materials, Devices, Systems, and Applications V, vol. 10656. Bellingham, WA, USA: SPIE, 2018, pp. 118-126.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            150,
            270,
            1212,
            270,
            1212,
            1812,
            150,
            1812
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        1250,
        268,
        2306,
        268,
        2306,
        1802,
        1250,
        1802
      ],
      "ignore": false,
      "order": "4",
      "anno_id": 1,
      "text": "- [41] R. Faster, \"Towards real-time object detection with region proposal networks,\" in Proc. Adv. Neural Inf. Process. Syst., 2015, pp. 2969239-2969250. - [42] T.-Y. Ross and G. Dollár, \"Focal loss for dense object detection,\" in *Proc.* IEEE Conf. Comput. Vis. Pattern Recognit., 2017, pp. 2980–2988. - [43] A. Kargar, M. P. Wilk, D. Zorbas, M. T. Gaffney, and B. Q'Flynn, \"A novel resource-constrained insect monitoring system based on machine vision with edge AI,\" in Proc. 5th Int. Conf. Image Process. Appl. Syst. (IPAS), 2022, рр. 1-6. - [44] A. Kargar et al., \"Detecting Halyomorpha halys using a low-power edgebased monitoring system,\" Comput. Electron. Agriculture, vol. 221, 2024, Art. no. 108935. - [45] N. Mamdouh and A. Khattab, \"YOLO-based deep learning frame-work for olive fruit fly detection and counting,\" IEEE Access, vol. 9, pp. 84252-84262, 2021. - [46] Q. Guo, C. Wang, D. Xiao, and Q. Huang, \"Automatic monitoring of flying vegetable insect pests using an RGB camera and YOLO-SIP detector, Precis. Agriculture, vol. 24, no. 2, pp. 436-457, 2023. - [47] M. Grinberg, Flask Web Development: Developing Web Applications With *Python*. Sebastopol, CA, USA: O'Reilly Media, 2018. - [48] S. Imambi, K. B. Prakash, and G. Kanagachidambaresan, \"PyTorch,\" in Programming With TensorFlow: Solution for Edge Computing Applications, Berlin, Germany: Springer, 2021, pp. 87-104. - [49] L. Maistrello et al., \"Monitoring of the invasive Halyomorpha halys, a new key pest of fruit orchards in Northern Italy,\" J. Pest Sci., vol. 90, рр. 1231-1244, 2017. - [50] J. C. Bergh et al., \"Effect of pre-harvest exposures to adult Halyomorpha halys (Hemiptera: Pentatomidae) on feeding injury to apple cultivars at harvest and during post-harvest cold storage,\" Crop Protection, vol. 124, 2019. Art. no. 104872. - [51] R. Calvini, G. Foca, and A. Ulrici, \"Data dimensionality reduction and data fusion for fast characterization of green coffee samples using hyperspectral sensors,\" Anal. Bioanalytical Chem., vol. 408, pp. 7351-7366, 2016. - [52] L. Nørgaard et al., \"Interval partial least-squares regression (i PLS): A comparative chemometric study with an example from near-infrared spectroscopy,\" Appl. Spectrosc., vol. 54, no. 3, pp. 413-419, 2000. - [53] W.-H. Lee et al., \"Hyperspectral near-infrared imaging for the detection of physical damages of pear,\" J. Food Eng., vol. 130, pp. 1-7, 2014. - [54] Y. Li et al., \"Exploring the limit of detection on early implicit bruised 'Korla' fragrant pears using hyperspectral imaging features and spectral variables,\" Posth. Biol. Tech., vol. 208, 2024, Art. no. 112668.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            1250,
            268,
            2306,
            268,
            2306,
            1802,
            1250,
            1802
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    }
  ],
  "extra": {
    "relation": []
  },
  "page_info": {
    "page_attribute": {},
    "page_no": 958,
    "height": 3300,
    "width": 2475,
    "image_path": "93_12_png.jpg"
  }
}