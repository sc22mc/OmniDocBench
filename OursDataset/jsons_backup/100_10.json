{
  "layout_dets": [
    {
      "category_type": "header",
      "poly": [
        444.99999999999994,
        115,
        1222.5,
        115,
        1222.5,
        155,
        444.99999999999994,
        155
      ],
      "ignore": false,
      "order": 1,
      "anno_id": 1,
      "text": "Published as a conference paper at ICLR 2024",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            444.99999999999994,
            115,
            1222.5,
            115,
            1222.5,
            155,
            444.99999999999994,
            155
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        447.5,
        345,
        2112.5,
        345,
        2112.5,
        620,
        447.5,
        620
      ],
      "ignore": false,
      "order": 2,
      "anno_id": 1,
      "text": "with an *experience*-driven iteration process. Iteratively exploring and self-evaluating the generated simplistic trees of thoughts enables a simple initial prompt to be gradually enhanced by an ensemble of trial-and-error reasoning experiences, resulting in accurate solutions. Our extensive experiments demonstrated that BoT is capable of achieving state-of-the-art on multiple benchmark datasets while outperforming the alternative leading approach in Game of 24, which is a challenging mathematical reasoning task.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            447.5,
            345,
            2112.5,
            345,
            2112.5,
            620,
            447.5,
            620
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        437.5,
        762.5000000000002,
        2107.5,
        762.5000000000002,
        2107.5,
        3047.58,
        437.5,
        3047.58
      ],
      "ignore": false,
      "order": "4",
      "anno_id": 1,
      "text": "- Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr Nyczyk, et al. Graph of thoughts: Solving elaborate problems with large language models. arXiv preprint arXiv:2308.09687, 2023.  - Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. *Advances in neural information processing systems*, 33:1877–1901, 2020.  - Tianqi Chen and Carlos Guestrin. Xgboost: A scalable tree boosting system. In *Proc. the 22nd acm* sigkdd international conference on knowledge discovery and data mining, pp. 785–794, 2016.  - Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168, 2021.  - Shizhe Diao, Pengcheng Wang, Yong Lin, and Tong Zhang. Active prompting with chain-of-thought for large language models. *arXiv* preprint arXiv:2302.12246, 2023.  - Yoav Freund, Robert E Schapire, et al. Experiments with a new boosting algorithm. In icml, volume 96, pp. 148-156. Citeseer, 1996.  - Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar Khot. Complexity-based prompting for multi-step reasoning. In *Proc. The Eleventh International Conference on Learning Representations*, 2022.  - Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. Measuring massive multitask language understanding. Proceedings of the International *Conference on Learning Representations (ICLR)*, 2021a.  - Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the math dataset. arXiv *preprint arXiv:2103.03874*, 2021b.  - Bairu Hou, Joe O'connor, Jacob Andreas, Shiyu Chang, and Yang Zhang. Promptboosting: Black-box text classification with ten forward passes. In *International Conference on Machine Learning*, pp. 13309–13324. PMLR, 2023.  - Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, and Tie-Yan Liu. Lightgbm: A highly efficient gradient boosting decision tree. Advances in neural information processing systems, 30, 2017.  - Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. Advances in neural information processing systems, 35: 22199-22213, 2022.  - Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, et al. Solving quantitative reasoning problems with language models. *arXiv* preprint *arXiv*:2206.14858, 2022.  - Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blunsom. Program induction by rationale generation: Learning to solve and explain algebraic word problems. arXiv preprint arXiv:1705.04146, 2017.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            437.5,
            762.5000000000002,
            2107.5,
            762.5000000000002,
            2107.5,
            3047.58,
            437.5,
            3047.58
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "footer",
      "poly": [
        1255,
        3130.08,
        1295,
        3130.08,
        1295,
        3165.08,
        1255,
        3165.08
      ],
      "ignore": false,
      "order": "5",
      "anno_id": 1,
      "text": "10",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            1255,
            3130.08,
            1295,
            3130.08,
            1295,
            3165.08,
            1255,
            3165.08
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "section",
      "poly": [
        447.5,
        690,
        725,
        690,
        725,
        735,
        447.5,
        735
      ],
      "ignore": false,
      "order": "3",
      "anno_id": 1,
      "text": " # REFERENCES",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            447.5,
            690,
            725,
            690,
            725,
            735,
            447.5,
            735
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    }
  ],
  "extra": {
    "relation": []
  },
  "page_info": {
    "page_attribute": {},
    "page_no": 1,
    "height": 3300,
    "width": 2550,
    "image_path": "100_10_png.jpg"
  }
}