{
  "layout_dets": [
    {
      "category_type": "header",
      "poly": [
        169.99999999999997,
        132.5,
        219.99999999999997,
        132.5,
        219.99999999999997,
        167.5,
        169.99999999999997,
        167.5
      ],
      "ignore": false,
      "order": 1,
      "anno_id": 1,
      "text": "108      ",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            169.99999999999997,
            132.5,
            219.99999999999997,
            132.5,
            219.99999999999997,
            167.5,
            169.99999999999997,
            167.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "header",
      "poly": [
        1187.5,
        132.5,
        2320,
        132.5,
        2320,
        167.5,
        1187.5,
        167.5
      ],
      "ignore": false,
      "order": 2,
      "anno_id": 1,
      "text": " IEEE TRANSACTIONS ON AGRIFOOD ELECTRONICS, VOL. 1, NO. 2, DECEMBER 2023",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            1187.5,
            132.5,
            2320,
            132.5,
            2320,
            167.5,
            1187.5,
            167.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "title",
      "poly": [
        357.4999999999999,
        252.5,
        2127.5,
        252.5,
        2127.5,
        462.5,
        357.4999999999999,
        462.5
      ],
      "ignore": false,
      "order": 3,
      "anno_id": 1,
      "text": "# A Review on Plant Disease Detection Using **Hyperspectral Imaging**",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            357.4999999999999,
            252.5,
            2127.5,
            252.5,
            2127.5,
            462.5,
            357.4999999999999,
            462.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        365,
        495,
        2130,
        495,
        2130,
        607.5,
        365,
        607.5
      ],
      "ignore": false,
      "order": 4,
      "anno_id": 1,
      "text": "Rakiba Rayhana<sup>,</sup>, *Student Member, IEEE*, Zhenyu Ma<sup>,</sup>, Zheng Liu<sup>,</sup>, *Senior Member, IEEE*, Gaozhi Xiao<sup>,</sup> *Fellow, IEEE*, Yuefeng Ruan<sup>,</sup> and Jatinder S. Sangha<sup>,</sup>",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            365,
            495,
            2130,
            495,
            2130,
            607.5,
            365,
            607.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        170,
        737.5,
        1225,
        737.5,
        1225,
        1602.5,
        170,
        1602.5
      ],
      "ignore": false,
      "order": 5,
      "anno_id": 1,
      "text": "Abstract-Agriculture production is one of the fundamental contributors to a nation's economic development. Every year, plant diseases result in significant crop losses that threaten the global food supply chain. Early estimation of plant diseases could play an essential role in safeguarding crops and fostering economic growth. Recently, hyperspectral imaging techniques have emerged as powerful tools for early disease detection, as they have demonstrated capabilities to detect plant diseases from tissue to canopy levels. This article provides an extensive overview of the principles, types, and operating platforms of hyperspectral image sensors. Furthermore, this article delves into the specifics of these sensors' application in plant disease detection, including disease identification, classification, severity analysis, and understanding genetic resistance. In addition, this article addresses the current challenges in the field and suggests potential solutions to mitigate these pressing issues. Finally, this article outlines the promising future trends and directions of hyperspectral imaging in plant disease detection and analysis. With continuous improvement and application, these imaging techniques have great potential to revolutionize plant disease management, thereby enhancing agricultural productivity and ensuring food security.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            170,
            737.5,
            1225,
            737.5,
            1225,
            1602.5,
            170,
            1602.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        167.4999999999999,
        1637.5,
        1222.5,
        1637.5,
        1222.5,
        1717.5,
        167.4999999999999,
        1717.5
      ],
      "ignore": false,
      "order": 6,
      "anno_id": 1,
      "text": " Index Terms—Data analytics, hyperspectral imaging, sensors, smart agriculture, plant disease.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            167.4999999999999,
            1637.5,
            1222.5,
            1637.5,
            1222.5,
            1717.5,
            167.4999999999999,
            1717.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        177.5,
        1840,
        1222.5,
        1840,
        1222.5,
        2277.5,
        177.5,
        2277.5
      ],
      "ignore": false,
      "order": "8",
      "anno_id": 1,
      "text": " **P**LANT disease is one of the important factors for the reduction of global food supply [\\[1\\]](#page-1-0). An estimation shows that around  $10-16%$  [\\[2\\]](#page-1-1), [\\[3\\]](#page-1-2) of crops are lost due to plant disease and pathogens, which can cost 220 billion USD [\\[3\\]](#page-1-3). A recent report by the Food and Agricultural Organization shows that by the year  $2050$ , the global population will increase to  $9.73$  billion [\\[4\\]](#page-1-4), [\\[5\\]](#page-1-5), [\\[6\\]](#page-1-6). The traditional and existing disease detection methods often depend on visual inspection of signs and symptoms associated with the disease. However, this visual checking",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            177.5,
            1840,
            1222.5,
            1840,
            1222.5,
            2277.5,
            177.5,
            2277.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        167.5,
        2330,
        1227.5,
        2330,
        1227.5,
        2550,
        167.5,
        2550
      ],
      "ignore": false,
      "order": "9",
      "anno_id": 1,
      "text": " Manuscript received 15 March 2023; revised 25 September 2023 and 26 October 2023; accepted 31 October 2023. Date of publication 29 November 2023; date of current version 19 December 2023. This work was supported in part by the National Research Council (NRC) Canada, Ottawa. This article was recommended by Associate Editor P. Motto Ros. (Corresponding author: Zheng Liu.)",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            167.5,
            2330,
            1227.5,
            2330,
            1227.5,
            2550,
            167.5,
            2550
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        170,
        2560,
        1225,
        2560,
        1225,
        2670,
        170,
        2670
      ],
      "ignore": false,
      "order": "10",
      "anno_id": 1,
      "text": " Rakiba Rayhana, Zhenyu Ma, and Zheng Liu are with the School of Engineering, University of British Columbia, Kelowna, BC V1V 1V7, Canada (e-mail: rakibarayhana@ubc.ca; zhenyu.ma@ubc.ca; zheng.liu@ubc.ca).",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            170,
            2560,
            1225,
            2560,
            1225,
            2670,
            170,
            2670
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        167.5,
        2675,
        1227.5,
        2675,
        1227.5,
        2780,
        167.5,
        2780
      ],
      "ignore": false,
      "order": "11",
      "anno_id": 1,
      "text": " Gaozhi Xiao is with the Advanced Electronics and Photonics Research Center, National Research Council Canada, Ottawa, ON K1A 0R6, Canada (e-mail: george.xiao@nrc-cnrc.gc.ca).",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            167.5,
            2675,
            1227.5,
            2675,
            1227.5,
            2780,
            167.5,
            2780
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        170,
        2790,
        1227.5,
        2790,
        1227.5,
        2927.5,
        170,
        2927.5
      ],
      "ignore": false,
      "order": "12",
      "anno_id": 1,
      "text": " Yuefeng Ruan and Jatinder S. Sangha are with the Swift Current Research and Development Centre, Agriculture and Agri-Food Canada, Swift Current, SK S9H 3X2, Canada (e-mail: Yuefeng.Ruan@agr.gc.ca; jatinder.sangha2@agr.gc.ca).",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            170,
            2790,
            1227.5,
            2790,
            1227.5,
            2927.5,
            170,
            2927.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        202.5,
        2930,
        932.5,
        2930,
        932.5,
        2965,
        202.5,
        2965
      ],
      "ignore": false,
      "order": "13",
      "anno_id": 1,
      "text": " Digital Object Identifier 10.1109/TAFE.2023.3329849",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            202.5,
            2930,
            932.5,
            2930,
            932.5,
            2965,
            202.5,
            2965
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        1265,
        2132.5,
        2320,
        2132.5,
        2320,
        2970,
        1265,
        2970
      ],
      "ignore": false,
      "order": "16",
      "anno_id": 1,
      "text": " A digital camera captures digital images using a sophisticated lens, higher quality sensors, and a digital image processor. The digital cameras offer the option to change lenses and manual control to adjust the aperture/shutter speed to generate highresolution images. Digital cameras are generally larger and heavier, making them inconvenient to carry and quick image capturing [8]. Red-green-blue (RGB) cameras employ specific sensors that operate only at red, green, and blue spectrum regions to generate an image. For blue light, the wavelength is approximately between 400 and 499 nm; for green light, it is between 500 and 549 nm; and for red light, it is between 550 and 750 nm [7]. RGB cameras are smaller in size, portable, easy to use, and affordable. However, the resolution of RGB cameras depends upon illumination level, time of the day, and environmental conditions [10]. Nowadays, RGB cameras are integrated with smartphones, which aids in quick image capturing. The smartphone provides optical zoom, wide-angle lens view, and",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            1265,
            2132.5,
            2320,
            2132.5,
            2320,
            2970,
            1265,
            2970
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        1264.9999999999998,
        1732.5,
        2322.5,
        1732.5,
        2322.5,
        2120,
        1264.9999999999998,
        2120
      ],
      "ignore": false,
      "order": "15",
      "anno_id": 1,
      "text": " Over the past few years, image analysis techniques have become popular as they are noninvasive and can identify the adverse stresses in plants. The image analysis involves automatic processing of the captured plant images and generating desired measurements of the image dataset. The plant images/dataset can be collected by digital cameras [8], RGB, smartphone [7], hyperspectral, multispectral, fluorescence, and thermography cameras [9].",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            1264.9999999999998,
            1732.5,
            2322.5,
            1732.5,
            2322.5,
            2120,
            1264.9999999999998,
            2120
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        1267.5,
        737.5,
        2322.5,
        737.5,
        2322.5,
        1727.5,
        1267.5,
        1727.5
      ],
      "ignore": false,
      "order": "14",
      "anno_id": 1,
      "text": " of plant health for disease identification is quite a tedious and time-consuming activity for commercial crops and large crop areas. Visual detection of plant disease also depends upon the expertise to identify the clear visibility/symptoms of the plants, which indicates that the plant has already been infected. Often plant diseases or infections usually outsets in a small region of leaves. The visual inspection process by farmers or plant pathologists is not sufficient as it is very hard to identify those smaller infected regions with the naked eye. Hence, identifying plant diseases at an early stage is crucial as it allows for early intercession to control and impede the spread of the infection to other parts/plants before the entire harvest is damaged. Early plant disease detection could also aid agronomists in using the specific application of chemicals, reducing excessive abuse of chemicals such as pesticides, herbicides, fungicides, and so on. This can directly benefit the plant ecosystem and environment and manage the expenditures for the plant pathologists [7]. Therefore, there is a growing demand in the agriculture industry for automating the manual inspection process with a sophisticated, efficient, and robust approach.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            1267.5,
            737.5,
            2322.5,
            737.5,
            2322.5,
            1727.5,
            1267.5,
            1727.5
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "section",
      "poly": [
        545,
        1770.0000000000002,
        852.5,
        1770.0000000000002,
        852.5,
        1810.0000000000002,
        545,
        1810.0000000000002
      ],
      "ignore": false,
      "order": "7",
      "anno_id": 1,
      "text": " # I. INTRODUCTION",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            545,
            1770.0000000000002,
            852.5,
            1770.0000000000002,
            852.5,
            1810.0000000000002,
            545,
            1810.0000000000002
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "footer",
      "poly": [
        290,
        3182.5,
        2170,
        3182.5,
        2170,
        3215,
        290,
        3215
      ],
      "ignore": false,
      "order": "18",
      "anno_id": 1,
      "text": "Authorized licensed use limited to: FUDAN UNIVERSITY. Downloaded on August 28,2025 at 01:49:24 UTC from IEEE Xplore. Restrictions apply",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            290,
            3182.5,
            2170,
            3182.5,
            2170,
            3215,
            290,
            3215
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "footer",
      "poly": [
        507.9999999999999,
        3026,
        1980,
        3026,
        1980,
        3100,
        507.9999999999999,
        3100
      ],
      "ignore": false,
      "order": "17",
      "anno_id": 1,
      "text": " <sup>2771-9529 © 2023</sup> IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.  See https://www.ieee.org/publications/rights/index.html for more information.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            507.9999999999999,
            3026,
            1980,
            3026,
            1980,
            3100,
            507.9999999999999,
            3100
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    }
  ],
  "extra": {
    "relation": []
  },
  "page_info": {
    "page_attribute": {},
    "page_no": 876,
    "height": 3300,
    "width": 2475,
    "image_path": "86_1_png.jpg"
  }
}