{
  "layout_dets": [
    {
      "category_type": "header",
      "poly": [
        170,
        128,
        210,
        128,
        210,
        166,
        170,
        166
      ],
      "ignore": false,
      "order": 1,
      "anno_id": 1,
      "text": "16 ",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            170,
            128,
            210,
            128,
            210,
            166,
            170,
            166
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "header",
      "poly": [
        1148,
        132,
        2322,
        132,
        2322,
        168,
        1148,
        168
      ],
      "ignore": false,
      "order": 2,
      "anno_id": 1,
      "text": "IEEE TRANSACTIONS ON AGRIFOOD ELECTRONICS, VOL. 3, NO. 1, MARCH/APRIL 2025",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            1148,
            132,
            2322,
            132,
            2322,
            168,
            1148,
            168
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        165.9999999999999,
        270,
        1222,
        270,
        1222,
        514,
        165.9999999999999,
        514
      ],
      "ignore": false,
      "order": 3,
      "anno_id": 1,
      "text": "$\\frac{2}{3}$  of the sound and punctured fruits to the training set, while the rest  $\\frac{1}{2}$  used for external validation. We calculated the imagelevel iPLS-DA models considering different interval sizes, and we performed an image reconstruction by evaluating the most frequently selected variables.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            165.9999999999999,
            270,
            1222,
            270,
            1222,
            514,
            165.9999999999999,
            514
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        170,
        523.9999999999999,
        1224,
        523.9999999999999,
        1224,
        1216,
        170,
        1216
      ],
      "ignore": false,
      "order": 4,
      "anno_id": 1,
      "text": "Finally, we applied the automated annotation procedure developed considering year images from 2022 to the hyperspectral images acquired in 2023 as an additional external validation. The proposed approach allowed to correctly select the pixels ascribable to BMSB related damages on 212 out of 322 images of punctured cv. Abate Fétel pears (65%) and on 273 out of 352 images of punctured cv. Williams pears (77%). Concerning the detection of different kind of damages, such as bruises, Lee et al. [53] reached 92% accuracy while Li et al. [54] reached 95% accuracy using near-infrared hyperspectral imaging on pear fruits. A similar annotation procedure was proposed on apples in Ferrari et al. [22], in which 92% and 94% efficiency values were obtained for \"Golden Delicious\" and \"Pink Lady\" apple varieties, respectively.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            170,
            523.9999999999999,
            1224,
            523.9999999999999,
            1224,
            1216,
            170,
            1216
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        166,
        1222,
        1226,
        1222,
        1226,
        1716,
        166,
        1716
      ],
      "ignore": false,
      "order": 5,
      "anno_id": 1,
      "text": "Starting from the ROIs of the annotated punctured areas, it will be possible to build a dataset of representative spectra belonging to both punctured and sound regions, which represents a crucial step for the development of more effective pixel-level classification models and the selection of relevant spectral regions ascribable to BMSB punctures. Indeed, the selection of spectral variables able to identify BMSB punctures is a key step in the implementation of MSI systems, which are more suitable for postharvest sorting lines in terms of computational time and lower costs of optical components.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            166,
            1222,
            1226,
            1222,
            1226,
            1716,
            166,
            1716
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        165.9999999999999,
        1892,
        1224,
        1892,
        1224,
        2678,
        165.9999999999999,
        2678
      ],
      "ignore": false,
      "order": "7",
      "anno_id": 1,
      "text": "In this article, we highlighted the main steps taken in the HALY.ID project to implement a system aimed at automating the monitoring of BMSB pests in orchards. Specifically, we detailed computer vision techniques for effectively detecting the BMSB, primarily on RGB images captured by UAVs, as well as utilizing spectral imaging as a complementary strategy. We also proposed an edge-based smart IoT sticky trap with integrated cameras and running resource efficient algorithms to be used in conjunction with the entire monitoring system to estimate population of specific invasive insect species. Finally, we successfully applied computer vision algorithms to spectral imaging to detect punctures on harvested pears, which can be integrated into a fruit sorting system to optimize food quality on the shelves of supply to customers. In addition, we developed a client-server application to enrich the dataset and enhance the trained models within this system.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            165.9999999999999,
            1892,
            1224,
            1892,
            1224,
            2678,
            165.9999999999999,
            2678
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        165.9999999999999,
        2694,
        1222,
        2694,
        1222,
        2928,
        165.9999999999999,
        2928
      ],
      "ignore": false,
      "order": "8",
      "anno_id": 1,
      "text": "As next steps, it will be necessary to effectively counteract BMSB by leveraging the aforementioned techniques to monitor and control their population. A comprehensive monitoring system, coupled with a decision-process model to actively combat this pest, is essential for successful pest management.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            165.9999999999999,
            2694,
            1222,
            2694,
            1222,
            2928,
            165.9999999999999,
            2928
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        185.9999999999999,
        3078,
        1202,
        3078,
        1202,
        3124,
        185.9999999999999,
        3124
      ],
      "ignore": false,
      "order": "10",
      "anno_id": 1,
      "text": "[1] HALY.ID, \"Project,\" 2022. [Online]. Available: https://www.haly-id.eu",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            185.9999999999999,
            3078,
            1202,
            3078,
            1202,
            3124,
            185.9999999999999,
            3124
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "plain_text",
      "poly": [
        1260,
        271.9999999999998,
        2326,
        271.9999999999998,
        2326,
        3109.96,
        1260,
        3109.96
      ],
      "ignore": false,
      "order": "11",
      "anno_id": 1,
      "text": " - [2] A. L. Nielsen et al., \"Life history of the invasive species Halyomorpha halys (Hemiptera: Pentatomidae) in northeastern United States,\" Ann. Ent. Soc. America, vol. 102, no. 4, pp. 608–616, 2009. - [3] M. Bariselli et al., \"Distribution and damage caused by Halyomorpha halys in Italy,\" *Eppo Bull.*, vol. 46, no. 2, pp. 332-334, 2016. - [4] L. Almstedt et al., \"Technological innovations in agriculture for scouting Halyomorpha halys in orchards,\" in Proc. Int. Conf. Distrib. Comput. Smart Syst. Internet Things, 2023, pp. 702–709. - [5] K. Espinoza et al., \"Combination of image processing and artificial neural networks as a novel approach for the identification of Bemisia tabaci and Frankliniella occidentalis on sticky traps in greenhouse agriculture,\" Comput. Electron. Agriculture, vol. 127, pp. 495-505, 2016. - [6] M. Valan et al., \"Automated taxonomic identification of insects with expert-level accuracy using effective feature transfer from convolutional networks,\" Systematic Biol., vol. 68, no. 6, pp. 876-895, 2019. - [7] C. Wen and D. Guyer, \"Image-based orchard insect automated identification and classification method,\" Comput. Electron. Agriculture, vol. 89, рр. 110–115, 2012. - [8] C.-J. Chen, Y.-Y. Huang, Y.-S. Li, C.-Y. Chang, and Y.-M. Huang, \"An IoT based smart agricultural system for pests detection,\" IEEE Access, vol. 8, pp. 180750–180761, 2020. - [9] Y. He, Z. Zhou, L. Tian, Y. Liu, and X. Luo, \"Brown rice planthopper (Nilaparvata lugens (Stål)) detection based on deep learning,\" Precis. Agriculture, vol. 21, no. 6, pp. 1385-1402, 2020. - [10] W. Li et al., \"Field detection of tiny pests from sticky trap images using deep learning in agricultural greenhouse,\" Comput. Electron. Agriculture, vol. 183, 2021, Art. no. 106048. - [11] A. Albanese, M. Nardello, and D. Brunelli, \"Automated pest detection with DNN on the edge for precision agriculture,\" IEEE Trans. Emerg. Sel. Topics Circuits Syst., vol. 11, no. 3, pp. 458-467, Sep. 2021. - [12] R. Trufelea, M. Dimoiu, L. Ichim, and D. Popescu, \"Detection of harmful insects for orchard using convolutional neural networks,\" UPB Sci. Bull. Ser. C, vol. 83, no. 4, pp. 85–96, 2021. - [13] L. Ichim, R. Ciciu, and D. Popescu, \"Using drones and deep neural networks to detect Halyomorpha halys in ecological orchards,\" in *Proc.* IEEE Int. Geosci. Remote Sens. Symp., 2022, pp. 437-440. - [14] A. Sava, L. Ichim, and D. Popescu, \"Detection of Halyomorpha halys using neural networks,\" in Proc. 2022 8th Int. Conf. Control Decis. Inf. Technol. (CoDIT), 2022, pp. 437-442. - [15] DJI, \"Maryland biodiversity dataset,\" 2022. [Online]. Available: https: //www.marylandbiodiversity.com/ - [16] G. Jocher et al., \"ultralytics/yolov5: V7.0 YOLOv5 sota realtime instance segmentation,\" 2022. - [17] D. Giannetti, N. Patelli, L. Palazzetti, F. Betti Sorbelli, C. M. Pinotti, and L. Maistrello, \"First use of unmanned aerial vehicles to monitor Halyomorpha halys and recognize it using artificial intelligence,\" Pest Manage. Sci., vol. 80, pp. 4074-4084, 2024. - [18] F. Betti Sorbelli, L. Palazzetti, and C. M. Pinotti, \"YOLO-based detection of Halyomorpha halys in orchards using RGB cameras and drones,\" Comput. Electron. Agriculture, vol. 213, 2023, Art. no. 108228. - [19] F. Betti Sorbelli, L. Palazzetti, and C. M. Pinotti, \"Preliminary results for Halyomorpha halys monitoring relying on a custom dataset,\" in Proc. Int. Workshop Metrol. Agr. For., 2023, pp. 363-368. - [20] F. Betti Sorbelli, L. Palazzetti, and C. M. Pinotti, \"A drone-based automated Halyomorpha halys scouting: A case study on orchard monitoring,\" in Proc. IEEE Int. Workshop Metrol. Agr. For., 2023, pp. 380–385. - [21] J. Li et al., \"Multispectral detection of skin defects of bi-colored peaches based on vis-NIR hyperspectral imaging,\" Postharvest Biol. Technol., vol. 112, pp. 121-133, 2016. - [22] C. Ferrari, G. Foca, R. Calvini, and A. Ulrici, \"Fast exploration and classification of large hyperspectral image datasets for early bruise detection on apples,\" Chemometrics Intell. Lab. Syst., vol. 146, pp. 108-119, 2015. - [23] J. F. I. Nturambirwe, W. J. Perold, and U. L. Opara, \"Classification learning of latent bruise damage to apples using shortwave infrared hyperspectral imaging,\" Sensors, vol. 21, no. 15, 2021, Art. no. 4990. - [24] P. Baranowski et al., \"Supervised classification of bruised apples with respect to the time after bruising on the basis of hyperspectral imaging data,\" Posth. Biol. Tech., vol. 86, pp. 249-258, 2013. - [25] Y. Lu, Y. Huang, and R. Lu, \"Innovative hyperspectral imaging-based techniques for quality evaluation of fruits and vegetables: A review,\" Appl. Sci., vol. 7, no. 2, 2017, Art. no. 189. - [26] M. Alamar et al., \"Hyperspectral imaging techniques for quality assessment in fresh horticultural produce and prospects for measurement of mechanical damage,\" in Mechanical Damage in Fresh Horticultural Produce: Measurement, Analysis and Control, Berlin, Germany: Springer, 2024, pp. 69–90.",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            1260,
            271.9999999999998,
            2326,
            271.9999999999998,
            2326,
            3109.96,
            1260,
            3109.96
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "section",
      "poly": [
        624.0000000000001,
        3011.96,
        848.0000000000001,
        3011.96,
        848.0000000000001,
        3049.96,
        624.0000000000001,
        3049.96
      ],
      "ignore": false,
      "order": "9",
      "anno_id": 1,
      "text": "# REFERENCES",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            624.0000000000001,
            3011.96,
            848.0000000000001,
            3011.96,
            848.0000000000001,
            3049.96,
            624.0000000000001,
            3049.96
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    },
    {
      "category_type": "section",
      "poly": [
        540,
        1817.9600000000003,
        860,
        1817.9600000000003,
        860,
        1855.9600000000003,
        540,
        1855.9600000000003
      ],
      "ignore": false,
      "order": "6",
      "anno_id": 1,
      "text": "# VIII. CONCLUSION",
      "line_with_spans": [
        {
          "category_type": "text_span",
          "poly": [
            540,
            1817.9600000000003,
            860,
            1817.9600000000003,
            860,
            1855.9600000000003,
            540,
            1855.9600000000003
          ],
          "text": ""
        }
      ],
      "attribute": {
        "text_language": "",
        "text_background": "",
        "text_rotate": ""
      }
    }
  ],
  "extra": {
    "relation": []
  },
  "page_info": {
    "page_attribute": {},
    "page_no": 957,
    "height": 3300,
    "width": 2475,
    "image_path": "93_11_png.jpg"
  }
}